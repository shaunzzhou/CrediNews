{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Statistical functions\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# For concurrency (running functions in parallel)\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# For caching (to speed up repeated function calls)\n",
    "from functools import lru_cache\n",
    "\n",
    "# For progress tracking\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Plotting and Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Language Detection packages\n",
    "# `langdetect` for detecting language\n",
    "from langdetect import detect as langdetect_detect, DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "# `langid` for an alternative language detection method\n",
    "from langid import classify as langid_classify\n",
    "\n",
    "# Text Preprocessing and NLP\n",
    "# Stopwords (common words to ignore) from NLTK\n",
    "from nltk.corpus import stopwords\n",
    "# Tokenizing sentences/words\n",
    "from nltk.tokenize import word_tokenize\n",
    "# Part-of-speech tagging\n",
    "from nltk import pos_tag\n",
    "# Lemmatization (converting words to their base form)\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "# Regular expressions for text pattern matching\n",
    "import re\n",
    "\n",
    "# Word Cloud generation\n",
    "from wordcloud import WordCloud\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation (Loading CSV)\n",
    "\n",
    "Load the processed_data `csv` file into pandas DataFrames\n",
    "- `processed_data.csv` is loaded into `data` DataFrame (stemming has been performed to reduce processing time.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                       full_content  \\\n",
      "0      1  No comment is expected from Barack Obama Membe...   \n",
      "1      1     Did they post their votes for Hillary already?   \n",
      "2      1  Now, most of the demonstrators gathered last n...   \n",
      "3      0  A dozen politically active pastors came here f...   \n",
      "4      1  The RS-28 Sarmat missile, dubbed Satan 2, will...   \n",
      "\n",
      "                              processed_full_content  \n",
      "0  no comment expect barack obama member fyf911 f...  \n",
      "1                          post vote hillari alreadi  \n",
      "2  demonstr gather last night exercis constitut p...  \n",
      "3  dozen polit activ pastor came privat dinner fr...  \n",
      "4  rs-28 sarmat missil dub satan 2 replac ss-18 f...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('../processed_data.csv')\n",
    "print(data.head())  # Shows the first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with countvectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[6705  299]\n",
      " [ 303 5465]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9568    0.9573    0.9570      7004\n",
      "           1     0.9481    0.9475    0.9478      5768\n",
      "\n",
      "    accuracy                         0.9529     12772\n",
      "   macro avg     0.9524    0.9524    0.9524     12772\n",
      "weighted avg     0.9529    0.9529    0.9529     12772\n",
      "\n",
      "\n",
      "Macro Average F1-Score: 0.9524171294036754\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Vectorization using CountVectorizer\n",
    "MAX_FEATURES = 5000  # Number of features to consider\n",
    "vectorizer = CountVectorizer(max_features=MAX_FEATURES)\n",
    "\n",
    "# Convert text to feature vectors\n",
    "X = vectorizer.fit_transform(data['processed_full_content']).toarray()\n",
    "y = data['label']  # Target labels (binary classification: 0 or 1)\n",
    "\n",
    "# Step 2: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Train the SVM Model\n",
    "# svm = SVC(kernel='linear', random_state=42)\n",
    "svm = SGDClassifier(loss='hinge', random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Make Predictions and Evaluate\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(\"\\nMacro Average F1-Score:\", macro_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with tf-idf instead of CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[6784  220]\n",
      " [ 403 5365]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9439    0.9686    0.9561      7004\n",
      "           1     0.9606    0.9301    0.9451      5768\n",
      "\n",
      "    accuracy                         0.9512     12772\n",
      "   macro avg     0.9523    0.9494    0.9506     12772\n",
      "weighted avg     0.9515    0.9512    0.9511     12772\n",
      "\n",
      "\n",
      "Macro Average F1-Score: 0.9506117863026156\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Use TF-IDF instead of CountVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=MAX_FEATURES)\n",
    "X = tfidf_vectorizer.fit_transform(data['processed_full_content']).toarray()\n",
    "y = data['label']  # Target labels (binary classification: 0 or 1)\n",
    "\n",
    "# Step 2: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Train the SVM Model\n",
    "# svm = SVC(kernel='linear', random_state=42)\n",
    "svm = SGDClassifier(loss='hinge', random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Make Predictions and Evaluate\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(\"\\nMacro Average F1-Score:\", macro_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[6522  482]\n",
      " [1357 4411]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8278    0.9312    0.8764      7004\n",
      "           1     0.9015    0.7647    0.8275      5768\n",
      "\n",
      "    accuracy                         0.8560     12772\n",
      "   macro avg     0.8646    0.8480    0.8520     12772\n",
      "weighted avg     0.8611    0.8560    0.8543     12772\n",
      "\n",
      "\n",
      "Macro Average F1-Score: 0.8519691564373769\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_glove(file_path):\n",
    "    embeddings_index = {}\n",
    "    with open(file_path, encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    return embeddings_index\n",
    "\n",
    "# Load pre-trained GloVe vectors\n",
    "def get_embedding_matrix(data, embeddings_index, embed_dim=100):\n",
    "    embedding_matrix = []\n",
    "    for text in data:\n",
    "        words = text.split()\n",
    "        embeddings = [embeddings_index[word] for word in words if word in embeddings_index]\n",
    "        if embeddings:\n",
    "            document_embedding = np.mean(embeddings, axis=0)  # Average embeddings for the document\n",
    "        else:\n",
    "            document_embedding = np.zeros(embed_dim)  # Zero vector if no embeddings found\n",
    "        embedding_matrix.append(document_embedding)\n",
    "    return np.array(embedding_matrix)\n",
    "\n",
    "# Load GloVe vectors\n",
    "glove_path = \"glove.6B.100d.txt\"\n",
    "embeddings_index = load_glove(glove_path)\n",
    "\n",
    "# Convert text data to GloVe embeddings\n",
    "X_train = get_embedding_matrix(data['processed_full_content'], embeddings_index)\n",
    "y = data['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y, test_size=0.2, random_state=42)\n",
    "\n",
    "svm = SGDClassifier(loss='hinge', random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(\"\\nMacro Average F1-Score:\", macro_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with TF-IDF and glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[6669  335]\n",
      " [ 346 5422]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9507    0.9522    0.9514      7004\n",
      "           1     0.9418    0.9400    0.9409      5768\n",
      "\n",
      "    accuracy                         0.9467     12772\n",
      "   macro avg     0.9462    0.9461    0.9462     12772\n",
      "weighted avg     0.9467    0.9467    0.9467     12772\n",
      "\n",
      "\n",
      "Macro Average F1-Score: 0.9461670657996066\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Get TF-IDF features\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_tfidf = tfidf.fit_transform(data['processed_full_content'])\n",
    "\n",
    "# Get GloVe embeddings\n",
    "X_glove = get_embedding_matrix(data['processed_full_content'], embeddings_index)\n",
    "\n",
    "# Combine GloVe and TF-IDF features\n",
    "X_combined = hstack((X_tfidf, StandardScaler().fit_transform(X_glove))).toarray()\n",
    "\n",
    "# Split and train model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "svm = SGDClassifier(loss='hinge', random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(\"\\nMacro Average F1-Score:\", macro_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Step 1: Load pre-trained Word2Vec embeddings\n",
    "def load_word2vec(file_path):\n",
    "    return KeyedVectors.load_word2vec_format(file_path, binary=True)\n",
    "\n",
    "# Load Word2Vec vectors\n",
    "word2vec_path = r\"c:\\Users\\Admin\\Downloads\\GoogleNews-vectors-negative300.bin\"  # Example path\n",
    "word2vec = load_word2vec(word2vec_path)\n",
    "\n",
    "# Step 2: Convert each document to Word2Vec embeddings by averaging word vectors\n",
    "def get_word2vec_embedding(text, word2vec, embed_dim=300):\n",
    "    words = text.split()\n",
    "    embeddings = [word2vec[word] for word in words if word in word2vec.key_to_index]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros(embed_dim)\n",
    "\n",
    "# Generate Word2Vec embeddings for the entire dataset\n",
    "X_word2vec = np.array([get_word2vec_embedding(text, word2vec) for text in data['processed_full_content']])\n",
    "\n",
    "# Step 3: Generate CountVectorizer features\n",
    "vectorizer = CountVectorizer(max_features=5000)\n",
    "X_count = vectorizer.fit_transform(data['processed_full_content'])\n",
    "\n",
    "# Step 4: Combine Word2Vec embeddings and CountVectorizer features\n",
    "X_combined = hstack((X_count, X_word2vec))\n",
    "\n",
    "# Step 5: Train-test split\n",
    "y = data['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Train a classifier (e.g., SVM) on the combined features\n",
    "svm = SGDClassifier(loss='hinge', random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(\"\\nMacro Average F1-Score:\", macro_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with glove + countVectoriser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[6734  270]\n",
      " [ 306 5462]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9565    0.9615    0.9590      7004\n",
      "           1     0.9529    0.9469    0.9499      5768\n",
      "\n",
      "    accuracy                         0.9549     12772\n",
      "   macro avg     0.9547    0.9542    0.9544     12772\n",
      "weighted avg     0.9549    0.9549    0.9549     12772\n",
      "\n",
      "\n",
      "Macro Average F1-Score: 0.9544495436702043\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Step 1: Load pre-trained GloVe embeddings\n",
    "def load_glove(file_path):\n",
    "    embeddings_index = {}\n",
    "    with open(file_path, encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    return embeddings_index\n",
    "\n",
    "# Load GloVe vectors\n",
    "glove_path = \"glove.6B.100d.txt\"\n",
    "embeddings_index = load_glove(glove_path)\n",
    "\n",
    "# Step 2: Convert each document to GloVe embeddings by averaging word vectors\n",
    "def get_glove_embedding(text, embeddings_index, embed_dim=100):\n",
    "    words = text.split()\n",
    "    embeddings = [embeddings_index[word] for word in words if word in embeddings_index]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros(embed_dim)\n",
    "\n",
    "# Generate GloVe embeddings for the entire dataset\n",
    "X_glove = np.array([get_glove_embedding(text, embeddings_index) for text in data['processed_full_content']])\n",
    "\n",
    "# Step 3: Generate CountVectorizer features\n",
    "vectorizer = CountVectorizer(max_features=5000)\n",
    "X_count = vectorizer.fit_transform(data['processed_full_content'])\n",
    "\n",
    "# Step 4: Combine GloVe embeddings and CountVectorizer features\n",
    "# Use hstack to combine sparse CountVectorizer matrix with dense GloVe embeddings\n",
    "X_combined = hstack((X_count, X_glove))\n",
    "\n",
    "# Step 5: Train-test split\n",
    "y = data['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Train a classifier (e.g., SVM) on the combined features\n",
    "svm = SGDClassifier(loss='hinge', random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(\"\\nMacro Average F1-Score:\", macro_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with glove, count vectoriser and Stratified K-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - F1 Score (weighted): 0.9540576271559605\n",
      "Fold 1 - Confusion Matrix:\n",
      " [[11101   492]\n",
      " [  486  9208]]\n",
      "Fold 1 - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9581    0.9576    0.9578     11593\n",
      "           1     0.9493    0.9499    0.9496      9694\n",
      "\n",
      "    accuracy                         0.9541     21287\n",
      "   macro avg     0.9537    0.9537    0.9537     21287\n",
      "weighted avg     0.9541    0.9541    0.9541     21287\n",
      "\n",
      "Fold 2 - F1 Score (weighted): 0.9518794502764808\n",
      "Fold 2 - Confusion Matrix:\n",
      " [[11119   474]\n",
      " [  550  9144]]\n",
      "Fold 2 - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9529    0.9591    0.9560     11593\n",
      "           1     0.9507    0.9433    0.9470      9694\n",
      "\n",
      "    accuracy                         0.9519     21287\n",
      "   macro avg     0.9518    0.9512    0.9515     21287\n",
      "weighted avg     0.9519    0.9519    0.9519     21287\n",
      "\n",
      "Fold 3 - F1 Score (weighted): 0.9522081012321895\n",
      "Fold 3 - Confusion Matrix:\n",
      " [[11118   475]\n",
      " [  542  9151]]\n",
      "Fold 3 - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9535    0.9590    0.9563     11593\n",
      "           1     0.9507    0.9441    0.9474      9693\n",
      "\n",
      "    accuracy                         0.9522     21286\n",
      "   macro avg     0.9521    0.9516    0.9518     21286\n",
      "weighted avg     0.9522    0.9522    0.9522     21286\n",
      "\n",
      "\n",
      "Average F1 Score (weighted) across all folds: 0.952715059554877\n",
      "\n",
      "Average Classification Report across all folds:\n",
      "0:\n",
      "  precision: 0.9548\n",
      "  recall: 0.9586\n",
      "  f1-score: 0.9567\n",
      "  support: 11593.0000\n",
      "1:\n",
      "  precision: 0.9502\n",
      "  recall: 0.9457\n",
      "  f1-score: 0.9480\n",
      "  support: 9693.6667\n",
      "accuracy: 0.9527\n",
      "macro avg:\n",
      "  precision: 0.9525\n",
      "  recall: 0.9522\n",
      "  f1-score: 0.9523\n",
      "  support: 21286.6667\n",
      "weighted avg:\n",
      "  precision: 0.9527\n",
      "  recall: 0.9527\n",
      "  f1-score: 0.9527\n",
      "  support: 21286.6667\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "# Step 1: Load pre-trained GloVe embeddings\n",
    "def load_glove(file_path):\n",
    "    embeddings_index = {}\n",
    "    with open(file_path, encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    return embeddings_index\n",
    "\n",
    "# Load GloVe vectors\n",
    "glove_path = \"glove.6B.100d.txt\"\n",
    "embeddings_index = load_glove(glove_path)\n",
    "\n",
    "# Step 2: Convert each document to GloVe embeddings by averaging word vectors\n",
    "def get_glove_embedding(text, embeddings_index, embed_dim=100):\n",
    "    words = text.split()\n",
    "    embeddings = [embeddings_index[word] for word in words if word in embeddings_index]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros(embed_dim)\n",
    "\n",
    "# Generate GloVe embeddings for the entire dataset\n",
    "X_glove = np.array([get_glove_embedding(text, embeddings_index) for text in data['processed_full_content']])\n",
    "\n",
    "# Step 3: Generate CountVectorizer features\n",
    "vectorizer = CountVectorizer(max_features=5000)\n",
    "X_count = vectorizer.fit_transform(data['processed_full_content'])\n",
    "\n",
    "# Step 4: Combine GloVe embeddings and CountVectorizer features\n",
    "# Use hstack to combine sparse CountVectorizer matrix with dense GloVe embeddings\n",
    "X_combined = hstack((X_count, X_glove))\n",
    "X_combined = csr_matrix(X_combined)  # Convert to csr_matrix for subscriptable indexing\n",
    "\n",
    "# Define labels\n",
    "y = data['label']\n",
    "\n",
    "# Step 5: Set up Stratified K-Fold Cross-Validation\n",
    "kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "fold = 1\n",
    "f1_scores = []\n",
    "all_classification_reports = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_combined, y):\n",
    "    # Split the data into training and testing sets for the current fold\n",
    "    X_train, X_test = X_combined[train_index], X_combined[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Train the SVM model on the current fold\n",
    "    svm = SGDClassifier(loss='hinge', random_state=42)\n",
    "    svm.fit(X_train, y_train)\n",
    "    y_pred = svm.predict(X_test)\n",
    "    \n",
    "    # Calculate F1-score for the current fold\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    f1_scores.append(f1)\n",
    "    classification_rep = classification_report(y_test, y_pred, digits=4, output_dict=True)\n",
    "    all_classification_reports.append(classification_rep)\n",
    "    \n",
    "    # Print F1-score and classification report for the current fold\n",
    "    print(f\"Fold {fold} - F1 Score (weighted): {f1}\")\n",
    "    print(f\"Fold {fold} - Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(f\"Fold {fold} - Classification Report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "    fold += 1\n",
    "\n",
    "# Step 6: Calculate and display average F1-score across all folds\n",
    "avg_f1_score = np.mean(f1_scores)\n",
    "print(\"\\nAverage F1 Score (weighted) across all folds:\", avg_f1_score)\n",
    "\n",
    "# Calculate the average classification report across folds\n",
    "avg_classification_report = {}\n",
    "for key in all_classification_reports[0].keys():\n",
    "    if isinstance(all_classification_reports[0][key], dict):\n",
    "        avg_classification_report[key] = {metric: np.mean([report[key][metric] for report in all_classification_reports]) \n",
    "                                          for metric in all_classification_reports[0][key]}\n",
    "    else:\n",
    "        avg_classification_report[key] = np.mean([report[key] for report in all_classification_reports])\n",
    "\n",
    "print(\"\\nAverage Classification Report across all folds:\")\n",
    "for label, metrics in avg_classification_report.items():\n",
    "    if isinstance(metrics, dict):\n",
    "        print(f\"{label}:\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"  {metric}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"{label}: {metrics:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - F1 Score (weighted): 0.954830207313335\n",
      "Fold 1 - Confusion Matrix:\n",
      " [[6655  300]\n",
      " [ 277 5540]]\n",
      "Fold 1 - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9600    0.9569    0.9585      6955\n",
      "           1     0.9486    0.9524    0.9505      5817\n",
      "\n",
      "    accuracy                         0.9548     12772\n",
      "   macro avg     0.9543    0.9546    0.9545     12772\n",
      "weighted avg     0.9548    0.9548    0.9548     12772\n",
      "\n",
      "Fold 2 - F1 Score (weighted): 0.9519500861173588\n",
      "Fold 2 - Confusion Matrix:\n",
      " [[6611  345]\n",
      " [ 269 5547]]\n",
      "Fold 2 - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9609    0.9504    0.9556      6956\n",
      "           1     0.9414    0.9537    0.9476      5816\n",
      "\n",
      "    accuracy                         0.9519     12772\n",
      "   macro avg     0.9512    0.9521    0.9516     12772\n",
      "weighted avg     0.9520    0.9519    0.9520     12772\n",
      "\n",
      "Fold 3 - F1 Score (weighted): 0.9556160302718006\n",
      "Fold 3 - Confusion Matrix:\n",
      " [[6656  300]\n",
      " [ 267 5549]]\n",
      "Fold 3 - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9614    0.9569    0.9591      6956\n",
      "           1     0.9487    0.9541    0.9514      5816\n",
      "\n",
      "    accuracy                         0.9556     12772\n",
      "   macro avg     0.9551    0.9555    0.9553     12772\n",
      "weighted avg     0.9556    0.9556    0.9556     12772\n",
      "\n",
      "Fold 4 - F1 Score (weighted): 0.9539084684721251\n",
      "Fold 4 - Confusion Matrix:\n",
      " [[6620  336]\n",
      " [ 253 5563]]\n",
      "Fold 4 - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9632    0.9517    0.9574      6956\n",
      "           1     0.9430    0.9565    0.9497      5816\n",
      "\n",
      "    accuracy                         0.9539     12772\n",
      "   macro avg     0.9531    0.9541    0.9536     12772\n",
      "weighted avg     0.9540    0.9539    0.9539     12772\n",
      "\n",
      "Fold 5 - F1 Score (weighted): 0.9566182761560942\n",
      "Fold 5 - Confusion Matrix:\n",
      " [[6688  268]\n",
      " [ 286 5530]]\n",
      "Fold 5 - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9590    0.9615    0.9602      6956\n",
      "           1     0.9538    0.9508    0.9523      5816\n",
      "\n",
      "    accuracy                         0.9566     12772\n",
      "   macro avg     0.9564    0.9561    0.9563     12772\n",
      "weighted avg     0.9566    0.9566    0.9566     12772\n",
      "\n",
      "\n",
      "Average F1 Score (weighted) across all folds: 0.9545846136661428\n",
      "\n",
      "Average Classification Report across all folds:\n",
      "0:\n",
      "  precision: 0.9609\n",
      "  recall: 0.9555\n",
      "  f1-score: 0.9582\n",
      "  support: 6955.8000\n",
      "1:\n",
      "  precision: 0.9471\n",
      "  recall: 0.9535\n",
      "  f1-score: 0.9503\n",
      "  support: 5816.2000\n",
      "accuracy: 0.9546\n",
      "macro avg:\n",
      "  precision: 0.9540\n",
      "  recall: 0.9545\n",
      "  f1-score: 0.9542\n",
      "  support: 12772.0000\n",
      "weighted avg:\n",
      "  precision: 0.9546\n",
      "  recall: 0.9546\n",
      "  f1-score: 0.9546\n",
      "  support: 12772.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 1: Load pre-trained GloVe embeddings\n",
    "def load_glove(file_path):\n",
    "    embeddings_index = {}\n",
    "    with open(file_path, encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    return embeddings_index\n",
    "\n",
    "# Load GloVe vectors\n",
    "glove_path = r\"c:\\Users\\Admin\\Downloads\\glove.6B\\glove.6B.300d.txt\"\n",
    "embeddings_index = load_glove(glove_path)\n",
    "\n",
    "# Step 2: Convert each document to GloVe embeddings by averaging word vectors\n",
    "def get_glove_embedding(text, embeddings_index, embed_dim=300):\n",
    "    words = text.split()\n",
    "    embeddings = [embeddings_index[word] for word in words if word in embeddings_index]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros(embed_dim)\n",
    "\n",
    "# Generate GloVe embeddings for the entire dataset\n",
    "X_glove = np.array([get_glove_embedding(text, embeddings_index) for text in data['processed_full_content']])\n",
    "\n",
    "# Step 3: Generate CountVectorizer features\n",
    "vectorizer = CountVectorizer(max_features=5000)\n",
    "X_count = vectorizer.fit_transform(data['processed_full_content'])\n",
    "\n",
    "# Step 4: Standardize GloVe embeddings and combine with CountVectorizer features\n",
    "scaler = StandardScaler()\n",
    "X_glove_scaled = scaler.fit_transform(X_glove)\n",
    "\n",
    "# Use hstack to combine sparse CountVectorizer matrix with dense (scaled) GloVe embeddings\n",
    "X_combined = hstack((X_count, X_glove_scaled))\n",
    "X_combined = csr_matrix(X_combined)  # Convert to csr_matrix for subscriptable indexing\n",
    "\n",
    "# Define labels\n",
    "y = data['label']\n",
    "\n",
    "# Step 5: Set up Stratified K-Fold Cross-Validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold = 1\n",
    "f1_scores = []\n",
    "all_classification_reports = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_combined, y):\n",
    "    # Split the data into training and testing sets for the current fold\n",
    "    X_train, X_test = X_combined[train_index], X_combined[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Train the SVM model with L2 regularization (penalty='l2')\n",
    "    svm = SGDClassifier(loss='hinge', penalty='l2', alpha=0.0001, random_state=42)\n",
    "    svm.fit(X_train, y_train)\n",
    "    y_pred = svm.predict(X_test)\n",
    "    \n",
    "    # Calculate F1-score for the current fold\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    f1_scores.append(f1)\n",
    "    classification_rep = classification_report(y_test, y_pred, digits=4, output_dict=True)\n",
    "    all_classification_reports.append(classification_rep)\n",
    "    \n",
    "    # Print F1-score and classification report for the current fold\n",
    "    print(f\"Fold {fold} - F1 Score (weighted): {f1}\")\n",
    "    print(f\"Fold {fold} - Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(f\"Fold {fold} - Classification Report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "    fold += 1\n",
    "\n",
    "# Step 6: Calculate and display average F1-score across all folds\n",
    "avg_f1_score = np.mean(f1_scores)\n",
    "print(\"\\nAverage F1 Score (weighted) across all folds:\", avg_f1_score)\n",
    "\n",
    "# Calculate the average classification report across folds\n",
    "avg_classification_report = {}\n",
    "for key in all_classification_reports[0].keys():\n",
    "    if isinstance(all_classification_reports[0][key], dict):\n",
    "        avg_classification_report[key] = {metric: np.mean([report[key][metric] for report in all_classification_reports]) \n",
    "                                          for metric in all_classification_reports[0][key]}\n",
    "    else:\n",
    "        avg_classification_report[key] = np.mean([report[key] for report in all_classification_reports])\n",
    "\n",
    "print(\"\\nAverage Classification Report across all folds:\")\n",
    "for label, metrics in avg_classification_report.items():\n",
    "    if isinstance(metrics, dict):\n",
    "        print(f\"{label}:\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"  {metric}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"{label}: {metrics:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with Count Vectoriser, Glove, Stratified K-fold Cross-validation, L2 Regularisation, Gridsearch hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "18 fits failed out of a total of 36.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'hinge', 'squared_epsilon_insensitive', 'squared_hinge', 'log_loss', 'huber', 'modified_huber', 'squared_error', 'perceptron'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'modified_huber', 'log_loss', 'epsilon_insensitive', 'huber', 'squared_error', 'squared_epsilon_insensitive', 'hinge', 'squared_hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'log_loss', 'squared_hinge', 'huber', 'squared_error', 'hinge', 'epsilon_insensitive', 'perceptron', 'squared_epsilon_insensitive', 'modified_huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'modified_huber', 'epsilon_insensitive', 'squared_hinge', 'squared_epsilon_insensitive', 'log_loss', 'huber', 'perceptron', 'squared_error', 'hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'hinge', 'perceptron', 'squared_error', 'log_loss', 'modified_huber', 'epsilon_insensitive', 'squared_epsilon_insensitive', 'squared_hinge', 'huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'epsilon_insensitive', 'squared_error', 'hinge', 'modified_huber', 'log_loss', 'huber', 'squared_hinge', 'squared_epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'log_loss', 'modified_huber', 'epsilon_insensitive', 'squared_hinge', 'squared_epsilon_insensitive', 'squared_error', 'hinge', 'perceptron', 'huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'squared_epsilon_insensitive', 'perceptron', 'huber', 'hinge', 'log_loss', 'squared_hinge', 'squared_error', 'modified_huber'}. Got 'log' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\ma\\core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.94973748 0.94973748        nan        nan 0.95581232 0.95581232\n",
      "        nan        nan 0.95841334 0.95841334        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - F1 Score (weighted): 0.9615324260866738\n",
      "Best Parameters for Fold 1: {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l2'}\n",
      "Fold 1 - Confusion Matrix:\n",
      " [[6751  204]\n",
      " [ 287 5530]]\n",
      "Fold 1 - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9592    0.9707    0.9649      6955\n",
      "           1     0.9644    0.9507    0.9575      5817\n",
      "\n",
      "    accuracy                         0.9616     12772\n",
      "   macro avg     0.9618    0.9607    0.9612     12772\n",
      "weighted avg     0.9616    0.9616    0.9615     12772\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "18 fits failed out of a total of 36.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_hinge', 'squared_epsilon_insensitive', 'huber', 'modified_huber', 'squared_error', 'hinge', 'perceptron', 'epsilon_insensitive', 'log_loss'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'hinge', 'squared_epsilon_insensitive', 'squared_hinge', 'log_loss', 'huber', 'modified_huber', 'squared_error', 'perceptron'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'hinge', 'perceptron', 'squared_error', 'log_loss', 'modified_huber', 'epsilon_insensitive', 'squared_epsilon_insensitive', 'squared_hinge', 'huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'log_loss', 'squared_hinge', 'huber', 'squared_error', 'hinge', 'epsilon_insensitive', 'perceptron', 'squared_epsilon_insensitive', 'modified_huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'modified_huber', 'epsilon_insensitive', 'squared_hinge', 'squared_epsilon_insensitive', 'log_loss', 'huber', 'perceptron', 'squared_error', 'hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'epsilon_insensitive', 'squared_error', 'hinge', 'modified_huber', 'log_loss', 'huber', 'squared_hinge', 'squared_epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'modified_huber', 'log_loss', 'epsilon_insensitive', 'huber', 'squared_error', 'squared_epsilon_insensitive', 'hinge', 'squared_hinge'}. Got 'log' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\ma\\core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.94682911 0.94682911        nan        nan 0.95577264 0.95577264\n",
      "        nan        nan 0.95819998 0.95819998        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - F1 Score (weighted): 0.9580712079690743\n",
      "Best Parameters for Fold 2: {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l2'}\n",
      "Fold 2 - Confusion Matrix:\n",
      " [[6750  206]\n",
      " [ 329 5487]]\n",
      "Fold 2 - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9535    0.9704    0.9619      6956\n",
      "           1     0.9638    0.9434    0.9535      5816\n",
      "\n",
      "    accuracy                         0.9581     12772\n",
      "   macro avg     0.9587    0.9569    0.9577     12772\n",
      "weighted avg     0.9582    0.9581    0.9581     12772\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "18 fits failed out of a total of 36.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'hinge', 'squared_epsilon_insensitive', 'squared_hinge', 'log_loss', 'huber', 'modified_huber', 'squared_error', 'perceptron'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'squared_epsilon_insensitive', 'hinge', 'perceptron', 'modified_huber', 'squared_hinge', 'squared_error', 'huber', 'log_loss'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'squared_epsilon_insensitive', 'perceptron', 'huber', 'hinge', 'log_loss', 'squared_hinge', 'squared_error', 'modified_huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_hinge', 'squared_epsilon_insensitive', 'huber', 'modified_huber', 'squared_error', 'hinge', 'perceptron', 'epsilon_insensitive', 'log_loss'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'log_loss', 'modified_huber', 'epsilon_insensitive', 'squared_hinge', 'squared_epsilon_insensitive', 'squared_error', 'hinge', 'perceptron', 'huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'hinge', 'epsilon_insensitive', 'squared_epsilon_insensitive', 'modified_huber', 'huber', 'squared_hinge', 'log_loss', 'perceptron', 'squared_error'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'modified_huber', 'log_loss', 'epsilon_insensitive', 'huber', 'squared_error', 'squared_epsilon_insensitive', 'hinge', 'squared_hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'hinge', 'perceptron', 'squared_error', 'log_loss', 'modified_huber', 'epsilon_insensitive', 'squared_epsilon_insensitive', 'squared_hinge', 'huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'log_loss', 'squared_hinge', 'huber', 'squared_error', 'hinge', 'epsilon_insensitive', 'perceptron', 'squared_epsilon_insensitive', 'modified_huber'}. Got 'log' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.94479563 0.94479563        nan        nan 0.954067   0.954067\n",
      "        nan        nan 0.95743592 0.95743592        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - F1 Score (weighted): 0.9619548195119899\n",
      "Best Parameters for Fold 3: {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l2'}\n",
      "Fold 3 - Confusion Matrix:\n",
      " [[6700  256]\n",
      " [ 230 5586]]\n",
      "Fold 3 - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9668    0.9632    0.9650      6956\n",
      "           1     0.9562    0.9605    0.9583      5816\n",
      "\n",
      "    accuracy                         0.9619     12772\n",
      "   macro avg     0.9615    0.9618    0.9617     12772\n",
      "weighted avg     0.9620    0.9619    0.9620     12772\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "18 fits failed out of a total of 36.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'hinge', 'squared_epsilon_insensitive', 'squared_hinge', 'log_loss', 'huber', 'modified_huber', 'squared_error', 'perceptron'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'squared_epsilon_insensitive', 'perceptron', 'huber', 'hinge', 'log_loss', 'squared_hinge', 'squared_error', 'modified_huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'hinge', 'epsilon_insensitive', 'squared_epsilon_insensitive', 'modified_huber', 'huber', 'squared_hinge', 'log_loss', 'perceptron', 'squared_error'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'log_loss', 'modified_huber', 'epsilon_insensitive', 'squared_hinge', 'squared_epsilon_insensitive', 'squared_error', 'hinge', 'perceptron', 'huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'squared_error', 'modified_huber', 'squared_hinge', 'squared_epsilon_insensitive', 'hinge', 'huber', 'epsilon_insensitive', 'log_loss'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'epsilon_insensitive', 'squared_error', 'hinge', 'modified_huber', 'log_loss', 'huber', 'squared_hinge', 'squared_epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'squared_epsilon_insensitive', 'hinge', 'perceptron', 'modified_huber', 'squared_hinge', 'squared_error', 'huber', 'log_loss'}. Got 'log' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.94779749 0.94779749        nan        nan 0.95620265 0.95620265\n",
      "        nan        nan 0.95770353 0.95770353        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - F1 Score (weighted): 0.9614710143364869\n",
      "Best Parameters for Fold 4: {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l2'}\n",
      "Fold 4 - Confusion Matrix:\n",
      " [[6723  233]\n",
      " [ 259 5557]]\n",
      "Fold 4 - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9629    0.9665    0.9647      6956\n",
      "           1     0.9598    0.9555    0.9576      5816\n",
      "\n",
      "    accuracy                         0.9615     12772\n",
      "   macro avg     0.9613    0.9610    0.9612     12772\n",
      "weighted avg     0.9615    0.9615    0.9615     12772\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "18 fits failed out of a total of 36.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'squared_error', 'modified_huber', 'squared_hinge', 'squared_epsilon_insensitive', 'hinge', 'huber', 'epsilon_insensitive', 'log_loss'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'log_loss', 'squared_hinge', 'huber', 'squared_error', 'hinge', 'epsilon_insensitive', 'perceptron', 'squared_epsilon_insensitive', 'modified_huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'modified_huber', 'log_loss', 'epsilon_insensitive', 'huber', 'squared_error', 'squared_epsilon_insensitive', 'hinge', 'squared_hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'hinge', 'epsilon_insensitive', 'squared_epsilon_insensitive', 'modified_huber', 'huber', 'squared_hinge', 'log_loss', 'perceptron', 'squared_error'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'modified_huber', 'epsilon_insensitive', 'squared_hinge', 'squared_epsilon_insensitive', 'log_loss', 'huber', 'perceptron', 'squared_error', 'hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_hinge', 'squared_epsilon_insensitive', 'huber', 'modified_huber', 'squared_error', 'hinge', 'perceptron', 'epsilon_insensitive', 'log_loss'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'log_loss', 'modified_huber', 'epsilon_insensitive', 'squared_hinge', 'squared_epsilon_insensitive', 'squared_error', 'hinge', 'perceptron', 'huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'squared_epsilon_insensitive', 'perceptron', 'huber', 'hinge', 'log_loss', 'squared_hinge', 'squared_error', 'modified_huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'epsilon_insensitive', 'squared_error', 'hinge', 'modified_huber', 'log_loss', 'huber', 'squared_hinge', 'squared_epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'squared_epsilon_insensitive', 'hinge', 'perceptron', 'modified_huber', 'squared_hinge', 'squared_error', 'huber', 'log_loss'}. Got 'log' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.94879796 0.94879796        nan        nan 0.95697986 0.95697986\n",
      "        nan        nan 0.95828522 0.95828522        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 - F1 Score (weighted): 0.9617039597687295\n",
      "Best Parameters for Fold 5: {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l2'}\n",
      "Fold 5 - Confusion Matrix:\n",
      " [[6728  228]\n",
      " [ 261 5555]]\n",
      "Fold 5 - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9627    0.9672    0.9649      6956\n",
      "           1     0.9606    0.9551    0.9578      5816\n",
      "\n",
      "    accuracy                         0.9617     12772\n",
      "   macro avg     0.9616    0.9612    0.9614     12772\n",
      "weighted avg     0.9617    0.9617    0.9617     12772\n",
      "\n",
      "\n",
      "Average F1 Score (weighted) across all folds: 0.960946685534591\n",
      "\n",
      "Average Classification Report across all folds:\n",
      "0:\n",
      "  precision: 0.9610\n",
      "  recall: 0.9676\n",
      "  f1-score: 0.9643\n",
      "  support: 6955.8000\n",
      "1:\n",
      "  precision: 0.9609\n",
      "  recall: 0.9530\n",
      "  f1-score: 0.9570\n",
      "  support: 5816.2000\n",
      "accuracy: 0.9610\n",
      "macro avg:\n",
      "  precision: 0.9610\n",
      "  recall: 0.9603\n",
      "  f1-score: 0.9606\n",
      "  support: 12772.0000\n",
      "weighted avg:\n",
      "  precision: 0.9610\n",
      "  recall: 0.9610\n",
      "  f1-score: 0.9609\n",
      "  support: 12772.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 1: Load pre-trained GloVe embeddings\n",
    "def load_glove(file_path):\n",
    "    embeddings_index = {}\n",
    "    with open(file_path, encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    return embeddings_index\n",
    "\n",
    "# Load GloVe vectors\n",
    "glove_path = \"glove.6B.100d.txt\"\n",
    "embeddings_index = load_glove(glove_path)\n",
    "\n",
    "# Step 2: Convert each document to GloVe embeddings by averaging word vectors\n",
    "def get_glove_embedding(text, embeddings_index, embed_dim=100):\n",
    "    words = text.split()\n",
    "    embeddings = [embeddings_index[word] for word in words if word in embeddings_index]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros(embed_dim)\n",
    "\n",
    "# Generate GloVe embeddings for the entire dataset\n",
    "X_glove = np.array([get_glove_embedding(text, embeddings_index) for text in data['processed_full_content']])\n",
    "\n",
    "# Step 3: Generate CountVectorizer features\n",
    "vectorizer = CountVectorizer(max_features=5000)\n",
    "X_count = vectorizer.fit_transform(data['processed_full_content'])\n",
    "\n",
    "# Step 4: Standardize GloVe embeddings and combine with CountVectorizer features\n",
    "scaler = StandardScaler()\n",
    "X_glove_scaled = scaler.fit_transform(X_glove)\n",
    "\n",
    "# Use hstack to combine sparse CountVectorizer matrix with dense (scaled) GloVe embeddings\n",
    "X_combined = hstack((X_count, X_glove_scaled))\n",
    "X_combined = csr_matrix(X_combined)  # Convert to csr_matrix for subscriptable indexing\n",
    "\n",
    "# Define labels\n",
    "y = data['label']\n",
    "\n",
    "# Step 5: Set up Stratified K-Fold Cross-Validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold = 1\n",
    "f1_scores = []\n",
    "all_classification_reports = []\n",
    "\n",
    "# Step 6: Define parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'penalty': ['l2'],\n",
    "    'loss': ['hinge', 'log'],  # 'hinge' for SVM, 'log' for logistic regression\n",
    "    'max_iter': [1000, 2000]\n",
    "}\n",
    "\n",
    "# Step 7: Iterate over each fold in cross-validation\n",
    "for train_index, test_index in kf.split(X_combined, y):\n",
    "    # Split the data into training and testing sets for the current fold\n",
    "    X_train, X_test = X_combined[train_index], X_combined[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Set up GridSearchCV with the SGDClassifier and parameter grid\n",
    "    svm = SGDClassifier(random_state=42)\n",
    "    grid_search = GridSearchCV(svm, param_grid, scoring='f1_weighted', cv=3, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best model from GridSearchCV\n",
    "    best_svm = grid_search.best_estimator_\n",
    "    y_pred = best_svm.predict(X_test)\n",
    "    \n",
    "    # Calculate F1-score for the current fold\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    f1_scores.append(f1)\n",
    "    classification_rep = classification_report(y_test, y_pred, digits=4, output_dict=True)\n",
    "    all_classification_reports.append(classification_rep)\n",
    "    \n",
    "    # Print F1-score, best parameters, and classification report for the current fold\n",
    "    print(f\"Fold {fold} - F1 Score (weighted): {f1}\")\n",
    "    print(f\"Best Parameters for Fold {fold}: {grid_search.best_params_}\")\n",
    "    print(f\"Fold {fold} - Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(f\"Fold {fold} - Classification Report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "    fold += 1\n",
    "\n",
    "# Step 8: Calculate and display average F1-score across all folds\n",
    "avg_f1_score = np.mean(f1_scores)\n",
    "print(\"\\nAverage F1 Score (weighted) across all folds:\", avg_f1_score)\n",
    "\n",
    "# Calculate the average classification report across folds\n",
    "avg_classification_report = {}\n",
    "for key in all_classification_reports[0].keys():\n",
    "    if isinstance(all_classification_reports[0][key], dict):\n",
    "        avg_classification_report[key] = {metric: np.mean([report[key][metric] for report in all_classification_reports]) \n",
    "                                          for metric in all_classification_reports[0][key]}\n",
    "    else:\n",
    "        avg_classification_report[key] = np.mean([report[key] for report in all_classification_reports])\n",
    "\n",
    "print(\"\\nAverage Classification Report across all folds:\")\n",
    "for label, metrics in avg_classification_report.items():\n",
    "    if isinstance(metrics, dict):\n",
    "        print(f\"{label}:\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"  {metric}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"{label}: {metrics:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
