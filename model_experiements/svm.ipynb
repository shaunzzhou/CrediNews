{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Statistical functions\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# For concurrency (running functions in parallel)\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# For caching (to speed up repeated function calls)\n",
    "from functools import lru_cache\n",
    "\n",
    "# For progress tracking\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Plotting and Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Language Detection packages\n",
    "# `langdetect` for detecting language\n",
    "from langdetect import detect as langdetect_detect, DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "# `langid` for an alternative language detection method\n",
    "from langid import classify as langid_classify\n",
    "\n",
    "# Text Preprocessing and NLP\n",
    "# Stopwords (common words to ignore) from NLTK\n",
    "from nltk.corpus import stopwords\n",
    "# Tokenizing sentences/words\n",
    "from nltk.tokenize import word_tokenize\n",
    "# Part-of-speech tagging\n",
    "from nltk import pos_tag\n",
    "# Lemmatization (converting words to their base form)\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "# Regular expressions for text pattern matching\n",
    "import re\n",
    "\n",
    "# Word Cloud generation\n",
    "from wordcloud import WordCloud\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation (Loading CSV)\n",
    "\n",
    "Load the processed_data `csv` file into pandas DataFrames\n",
    "- `processed_data.csv` is loaded into `data` DataFrame (stemming has been performed to reduce processing time.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                       full_content  \\\n",
      "0      1  No comment is expected from Barack Obama Membe...   \n",
      "1      1     Did they post their votes for Hillary already?   \n",
      "2      1  Now, most of the demonstrators gathered last n...   \n",
      "3      0  A dozen politically active pastors came here f...   \n",
      "4      1  The RS-28 Sarmat missile, dubbed Satan 2, will...   \n",
      "\n",
      "                              processed_full_content  \n",
      "0  no comment expect barack obama member fyf911 f...  \n",
      "1                          post vote hillari alreadi  \n",
      "2  demonstr gather last night exercis constitut p...  \n",
      "3  dozen polit activ pastor came privat dinner fr...  \n",
      "4  rs-28 sarmat missil dub satan 2 replac ss-18 f...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('../processed_data.csv')\n",
    "print(data.head())  # Shows the first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with countvectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified 5-Fold Cross-Validation Performance Metrics:\n",
      "\n",
      "Average Accuracy: 0.9559\n",
      "Average Precision: 0.9551\n",
      "Average Recall: 0.9564\n",
      "Average Macro F1-Score: 0.9557\n",
      "\n",
      "Fold 1 - Confusion Matrix:\n",
      " [[6594  361]\n",
      " [ 222 5595]]\n",
      "\n",
      "Fold 1 - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9674    0.9481    0.9577      6955\n",
      "           1     0.9394    0.9618    0.9505      5817\n",
      "\n",
      "    accuracy                         0.9544     12772\n",
      "   macro avg     0.9534    0.9550    0.9541     12772\n",
      "weighted avg     0.9547    0.9544    0.9544     12772\n",
      "\n",
      "\n",
      "Fold 2 - Confusion Matrix:\n",
      " [[6622  334]\n",
      " [ 236 5580]]\n",
      "\n",
      "Fold 2 - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9656    0.9520    0.9587      6956\n",
      "           1     0.9435    0.9594    0.9514      5816\n",
      "\n",
      "    accuracy                         0.9554     12772\n",
      "   macro avg     0.9546    0.9557    0.9551     12772\n",
      "weighted avg     0.9555    0.9554    0.9554     12772\n",
      "\n",
      "\n",
      "Fold 3 - Confusion Matrix:\n",
      " [[6623  333]\n",
      " [ 192 5624]]\n",
      "\n",
      "Fold 3 - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9718    0.9521    0.9619      6956\n",
      "           1     0.9441    0.9670    0.9554      5816\n",
      "\n",
      "    accuracy                         0.9589     12772\n",
      "   macro avg     0.9580    0.9596    0.9586     12772\n",
      "weighted avg     0.9592    0.9589    0.9589     12772\n",
      "\n",
      "\n",
      "Fold 4 - Confusion Matrix:\n",
      " [[6589  367]\n",
      " [ 193 5623]]\n",
      "\n",
      "Fold 4 - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9715    0.9472    0.9592      6956\n",
      "           1     0.9387    0.9668    0.9526      5816\n",
      "\n",
      "    accuracy                         0.9562     12772\n",
      "   macro avg     0.9551    0.9570    0.9559     12772\n",
      "weighted avg     0.9566    0.9562    0.9562     12772\n",
      "\n",
      "\n",
      "Fold 5 - Confusion Matrix:\n",
      " [[6638  318]\n",
      " [ 258 5558]]\n",
      "\n",
      "Fold 5 - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9626    0.9543    0.9584      6956\n",
      "           1     0.9459    0.9556    0.9507      5816\n",
      "\n",
      "    accuracy                         0.9549     12772\n",
      "   macro avg     0.9542    0.9550    0.9546     12772\n",
      "weighted avg     0.9550    0.9549    0.9549     12772\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, accuracy_score, precision_score, recall_score\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Step 1: Vectorization using CountVectorizer\n",
    "MAX_FEATURES = 5000  # Number of features to consider\n",
    "vectorizer = CountVectorizer(max_features=MAX_FEATURES)\n",
    "\n",
    "# Convert text to feature vectors\n",
    "X = vectorizer.fit_transform(data['processed_full_content']).toarray()\n",
    "y = data['label']  # Target labels (binary classification: 0 or 1)\n",
    "\n",
    "# Step 2: Stratified K-Fold Cross-Validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "macro_f1_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "accuracy_scores = []\n",
    "confusion_matrices = []\n",
    "classification_reports = []\n",
    "\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Step 3: Train the SVM Model with L2 Regularization\n",
    "    svm = SGDClassifier(loss='hinge', penalty='l2', alpha=0.01, random_state=42)\n",
    "    svm.fit(X_train, y_train)\n",
    "    \n",
    "    # Step 4: Make Predictions and Evaluate\n",
    "    y_pred = svm.predict(X_test)\n",
    "    \n",
    "    # Collect evaluation metrics for each fold\n",
    "    macro_f1_scores.append(f1_score(y_test, y_pred, average='macro'))\n",
    "    precision_scores.append(precision_score(y_test, y_pred, average='macro'))\n",
    "    recall_scores.append(recall_score(y_test, y_pred, average='macro'))\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    confusion_matrices.append(confusion_matrix(y_test, y_pred))\n",
    "    classification_reports.append(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "# Calculate and print average metrics\n",
    "print(\"Stratified 5-Fold Cross-Validation Performance Metrics:\")\n",
    "print(f\"\\nAverage Accuracy: {np.mean(accuracy_scores):.4f}\")\n",
    "print(f\"Average Precision: {np.mean(precision_scores):.4f}\")\n",
    "print(f\"Average Recall: {np.mean(recall_scores):.4f}\")\n",
    "print(f\"Average Macro F1-Score: {np.mean(macro_f1_scores):.4f}\")\n",
    "\n",
    "for i, (conf_matrix, class_report) in enumerate(zip(confusion_matrices, classification_reports), 1):\n",
    "    print(f\"\\nFold {i} - Confusion Matrix:\\n\", conf_matrix)\n",
    "    print(f\"\\nFold {i} - Classification Report:\\n\", class_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with tf-idf instead of CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[6784  220]\n",
      " [ 403 5365]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9439    0.9686    0.9561      7004\n",
      "           1     0.9606    0.9301    0.9451      5768\n",
      "\n",
      "    accuracy                         0.9512     12772\n",
      "   macro avg     0.9523    0.9494    0.9506     12772\n",
      "weighted avg     0.9515    0.9512    0.9511     12772\n",
      "\n",
      "\n",
      "Macro Average F1-Score: 0.9506117863026156\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Use TF-IDF instead of CountVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=MAX_FEATURES)\n",
    "X = tfidf_vectorizer.fit_transform(data['processed_full_content']).toarray()\n",
    "y = data['label']  # Target labels (binary classification: 0 or 1)\n",
    "\n",
    "# Step 2: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Train the SVM Model\n",
    "# svm = SVC(kernel='linear', random_state=42)\n",
    "svm = SGDClassifier(loss='hinge', random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Make Predictions and Evaluate\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(\"\\nMacro Average F1-Score:\", macro_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-Validation Progress:  40%|████      | 2/5 [00:00<00:00,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[6035  920]\n",
      " [1503 4314]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8006    0.8677    0.8328      6955\n",
      "           1     0.8242    0.7416    0.7807      5817\n",
      "\n",
      "    accuracy                         0.8103     12772\n",
      "   macro avg     0.8124    0.8047    0.8068     12772\n",
      "weighted avg     0.8114    0.8103    0.8091     12772\n",
      "\n",
      "\n",
      "Accuracy: 0.8102881302849985\n",
      "Precision: 0.8124182273322997\n",
      "Recall: 0.8046702277108161\n",
      "Macro Average F1-Score: 0.8067798331095009\n",
      "Confusion Matrix:\n",
      " [[6153  803]\n",
      " [1593 4223]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7943    0.8846    0.8370      6956\n",
      "           1     0.8402    0.7261    0.7790      5816\n",
      "\n",
      "    accuracy                         0.8124     12772\n",
      "   macro avg     0.8173    0.8053    0.8080     12772\n",
      "weighted avg     0.8152    0.8124    0.8106     12772\n",
      "\n",
      "\n",
      "Accuracy: 0.8124021296586282\n",
      "Precision: 0.8172881342348988\n",
      "Recall: 0.805330252330823\n",
      "Macro Average F1-Score: 0.8080182694148983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-Validation Progress:  60%|██████    | 3/5 [00:00<00:00,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[6039  917]\n",
      " [1395 4421]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8123    0.8682    0.8393      6956\n",
      "           1     0.8282    0.7601    0.7927      5816\n",
      "\n",
      "    accuracy                         0.8190     12772\n",
      "   macro avg     0.8203    0.8142    0.8160     12772\n",
      "weighted avg     0.8196    0.8190    0.8181     12772\n",
      "\n",
      "\n",
      "Accuracy: 0.8189790165988099\n",
      "Precision: 0.8202807410344036\n",
      "Recall: 0.8141578960065747\n",
      "Macro Average F1-Score: 0.8160264852305266\n",
      "Confusion Matrix:\n",
      " [[6125  831]\n",
      " [1372 4444]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8170    0.8805    0.8476      6956\n",
      "           1     0.8425    0.7641    0.8014      5816\n",
      "\n",
      "    accuracy                         0.8275     12772\n",
      "   macro avg     0.8297    0.8223    0.8245     12772\n",
      "weighted avg     0.8286    0.8275    0.8265     12772\n",
      "\n",
      "\n",
      "Accuracy: 0.8275133103664266\n",
      "Precision: 0.8297289595142954\n",
      "Recall: 0.8223169136240926\n",
      "Macro Average F1-Score: 0.8244726892574474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-Validation Progress: 100%|██████████| 5/5 [00:00<00:00,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[6110  846]\n",
      " [1334 4482]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8208    0.8784    0.8486      6956\n",
      "           1     0.8412    0.7706    0.8044      5816\n",
      "\n",
      "    accuracy                         0.8293     12772\n",
      "   macro avg     0.8310    0.8245    0.8265     12772\n",
      "weighted avg     0.8301    0.8293    0.8285     12772\n",
      "\n",
      "\n",
      "Accuracy: 0.8293141246476667\n",
      "Precision: 0.8310057437878502\n",
      "Recall: 0.8245055578274285\n",
      "Macro Average F1-Score: 0.8264950745792454\n",
      "\n",
      "Average Metrics across 5 folds:\n",
      "Average Accuracy: 0.819699342311306\n",
      "Average Precision: 0.8221443611807494\n",
      "Average Recall: 0.814196169499947\n",
      "Average Macro F1-Score: 0.8163584703183238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load GloVe vectors\n",
    "def load_glove(file_path):\n",
    "    embeddings_index = {}\n",
    "    with open(file_path, encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    return embeddings_index\n",
    "\n",
    "# Convert text data to GloVe embeddings\n",
    "def get_embedding_matrix(data, embeddings_index, embed_dim=100):\n",
    "    embedding_matrix = []\n",
    "    for text in data:\n",
    "        words = text.split()\n",
    "        embeddings = [embeddings_index[word] for word in words if word in embeddings_index]\n",
    "        if embeddings:\n",
    "            document_embedding = np.mean(embeddings, axis=0)  # Average embeddings for the document\n",
    "        else:\n",
    "            document_embedding = np.zeros(embed_dim)  # Zero vector if no embeddings found\n",
    "        embedding_matrix.append(document_embedding)\n",
    "    return np.array(embedding_matrix)\n",
    "\n",
    "# Assume `data` is a DataFrame with `processed_full_content` and `label` columns\n",
    "glove_path = \"glove.6B.100d.txt\"\n",
    "embeddings_index = load_glove(glove_path)\n",
    "X = get_embedding_matrix(data['processed_full_content'], embeddings_index)\n",
    "y = data['label']\n",
    "\n",
    "# Initialize classifier and StratifiedKFold\n",
    "svm = SGDClassifier(loss='hinge', penalty='l2', alpha=0.01, random_state=42)\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Cross-validation loop with tqdm progress bar\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "macro_f1_scores = []\n",
    "\n",
    "for train_index, test_index in tqdm(skf.split(X, y), total=skf.get_n_splits(), desc=\"Cross-Validation Progress\"):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Train and predict\n",
    "    svm.fit(X_train, y_train)\n",
    "    y_pred = svm.predict(X_test)\n",
    "    \n",
    "    # Evaluate metrics for each fold\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    # Append each metric\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    macro_f1_scores.append(macro_f1)\n",
    "    \n",
    "    # Print metrics for each fold\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "    print(\"\\nAccuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"Macro Average F1-Score:\", macro_f1)\n",
    "\n",
    "# Calculate average metrics across all folds\n",
    "print(\"\\nAverage Metrics across 5 folds:\")\n",
    "print(\"Average Accuracy:\", np.mean(accuracy_scores))\n",
    "print(\"Average Precision:\", np.mean(precision_scores))\n",
    "print(\"Average Recall:\", np.mean(recall_scores))\n",
    "print(\"Average Macro F1-Score:\", np.mean(macro_f1_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with TF-IDF and glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[6669  335]\n",
      " [ 346 5422]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9507    0.9522    0.9514      7004\n",
      "           1     0.9418    0.9400    0.9409      5768\n",
      "\n",
      "    accuracy                         0.9467     12772\n",
      "   macro avg     0.9462    0.9461    0.9462     12772\n",
      "weighted avg     0.9467    0.9467    0.9467     12772\n",
      "\n",
      "\n",
      "Macro Average F1-Score: 0.9461670657996066\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Get TF-IDF features\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_tfidf = tfidf.fit_transform(data['processed_full_content'])\n",
    "\n",
    "# Get GloVe embeddings\n",
    "X_glove = get_embedding_matrix(data['processed_full_content'], embeddings_index)\n",
    "\n",
    "# Combine GloVe and TF-IDF features\n",
    "X_combined = hstack((X_tfidf, StandardScaler().fit_transform(X_glove))).toarray()\n",
    "\n",
    "# Split and train model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "svm = SGDClassifier(loss='hinge', random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(\"\\nMacro Average F1-Score:\", macro_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM + Pre-trained Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Step 1: Load pre-trained Word2Vec embeddings\n",
    "def load_word2vec(file_path):\n",
    "    return KeyedVectors.load_word2vec_format(file_path, binary=True)\n",
    "\n",
    "# Load Word2Vec vectors\n",
    "word2vec_path = r\"c:\\Users\\Admin\\Downloads\\GoogleNews-vectors-negative300.bin\"  # Example path\n",
    "word2vec = load_word2vec(word2vec_path)\n",
    "\n",
    "# Step 2: Convert each document to Word2Vec embeddings by averaging word vectors\n",
    "def get_word2vec_embedding(text, word2vec, embed_dim=300):\n",
    "    words = text.split()\n",
    "    embeddings = [word2vec[word] for word in words if word in word2vec.key_to_index]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros(embed_dim)\n",
    "\n",
    "# Generate Word2Vec embeddings for the entire dataset\n",
    "X_word2vec = np.array([get_word2vec_embedding(text, word2vec) for text in data['processed_full_content']])\n",
    "\n",
    "# Step 3: Generate CountVectorizer features\n",
    "vectorizer = CountVectorizer(max_features=5000)\n",
    "X_count = vectorizer.fit_transform(data['processed_full_content'])\n",
    "\n",
    "# Step 4: Combine Word2Vec embeddings and CountVectorizer features\n",
    "X_combined = hstack((X_count, X_word2vec))\n",
    "\n",
    "# Step 5: Train-test split\n",
    "y = data['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Train a classifier (e.g., SVM) on the combined features\n",
    "svm = SGDClassifier(loss='hinge', random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(\"\\nMacro Average F1-Score:\", macro_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM + Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-Validation Progress:  20%|██        | 1/5 [00:00<00:00,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[6351  604]\n",
      " [ 606 5211]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9129    0.9132    0.9130      6955\n",
      "           1     0.8961    0.8958    0.8960      5817\n",
      "\n",
      "    accuracy                         0.9053     12772\n",
      "   macro avg     0.9045    0.9045    0.9045     12772\n",
      "weighted avg     0.9053    0.9053    0.9053     12772\n",
      "\n",
      "\n",
      "Accuracy: 0.9052615095521453\n",
      "Precision: 0.9045120925236476\n",
      "Recall: 0.9044892959195061\n",
      "Macro Average F1-Score: 0.9045006715428003\n",
      "Confusion Matrix:\n",
      " [[6399  557]\n",
      " [ 562 5254]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9193    0.9199    0.9196      6956\n",
      "           1     0.9041    0.9034    0.9038      5816\n",
      "\n",
      "    accuracy                         0.9124     12772\n",
      "   macro avg     0.9117    0.9116    0.9117     12772\n",
      "weighted avg     0.9124    0.9124    0.9124     12772\n",
      "\n",
      "\n",
      "Accuracy: 0.9123864704040088\n",
      "Precision: 0.9117058901635291\n",
      "Recall: 0.9116476290742438\n",
      "Macro Average F1-Score: 0.9116766167041046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-Validation Progress:  80%|████████  | 4/5 [00:00<00:00,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[6336  620]\n",
      " [ 542 5274]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9212    0.9109    0.9160      6956\n",
      "           1     0.8948    0.9068    0.9008      5816\n",
      "\n",
      "    accuracy                         0.9090     12772\n",
      "   macro avg     0.9080    0.9088    0.9084     12772\n",
      "weighted avg     0.9092    0.9090    0.9091     12772\n",
      "\n",
      "\n",
      "Accuracy: 0.9090197306608205\n",
      "Precision: 0.9080031511436957\n",
      "Recall: 0.9088385592124362\n",
      "Macro Average F1-Score: 0.9083863109330876\n",
      "Confusion Matrix:\n",
      " [[6349  607]\n",
      " [ 537 5279]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9220    0.9127    0.9174      6956\n",
      "           1     0.8969    0.9077    0.9022      5816\n",
      "\n",
      "    accuracy                         0.9104     12772\n",
      "   macro avg     0.9094    0.9102    0.9098     12772\n",
      "weighted avg     0.9106    0.9104    0.9105     12772\n",
      "\n",
      "\n",
      "Accuracy: 0.9104290635765737\n",
      "Precision: 0.9094448110774283\n",
      "Recall: 0.9102028529890773\n",
      "Macro Average F1-Score: 0.909795958594259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cross-Validation Progress: 100%|██████████| 5/5 [00:00<00:00,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[6373  583]\n",
      " [ 534 5282]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9227    0.9162    0.9194      6956\n",
      "           1     0.9006    0.9082    0.9044      5816\n",
      "\n",
      "    accuracy                         0.9125     12772\n",
      "   macro avg     0.9116    0.9122    0.9119     12772\n",
      "weighted avg     0.9126    0.9125    0.9126     12772\n",
      "\n",
      "\n",
      "Accuracy: 0.9125430629502036\n",
      "Precision: 0.9116419447214367\n",
      "Recall: 0.9121858915897372\n",
      "Macro Average F1-Score: 0.9119002175847235\n",
      "\n",
      "Average Metrics across 5 folds:\n",
      "Average Accuracy: 0.9099279674287504\n",
      "Average Precision: 0.9090615779259474\n",
      "Average Recall: 0.9094728457570002\n",
      "Average Macro F1-Score: 0.909251955071795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Train or load Word2Vec model (assuming `data` is available and each entry is a list of words)\n",
    "def train_word2vec_model(data, embed_dim=100):\n",
    "    # Tokenize each document into a list of words if not already tokenized\n",
    "    tokenized_data = [text.split() for text in data]  # Split each text into words\n",
    "    # Train Word2Vec model\n",
    "    model = Word2Vec(sentences=tokenized_data, vector_size=embed_dim, window=5, min_count=1, workers=4)\n",
    "    return model\n",
    "\n",
    "# Convert text data to Word2Vec embeddings\n",
    "def get_embedding_matrix(data, model, embed_dim=100):\n",
    "    embedding_matrix = []\n",
    "    for text in data:\n",
    "        words = text.split()\n",
    "        embeddings = [model.wv[word] for word in words if word in model.wv]\n",
    "        if embeddings:\n",
    "            document_embedding = np.mean(embeddings, axis=0)  # Average embeddings for the document\n",
    "        else:\n",
    "            document_embedding = np.zeros(embed_dim)  # Zero vector if no embeddings found\n",
    "        embedding_matrix.append(document_embedding)\n",
    "    return np.array(embedding_matrix)\n",
    "\n",
    "# Assume `data` is a DataFrame with `processed_full_content` and `label` columns\n",
    "word2vec_model = train_word2vec_model(data['processed_full_content'])  # Train Word2Vec model on text data\n",
    "X = get_embedding_matrix(data['processed_full_content'], word2vec_model)\n",
    "y = data['label']\n",
    "\n",
    "# Initialize classifier and StratifiedKFold\n",
    "svm = SGDClassifier(loss='hinge', penalty='l2', alpha=0.01, random_state=42)\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Cross-validation loop with tqdm progress bar\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "macro_f1_scores = []\n",
    "\n",
    "for train_index, test_index in tqdm(skf.split(X, y), total=skf.get_n_splits(), desc=\"Cross-Validation Progress\"):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Train and predict\n",
    "    svm.fit(X_train, y_train)\n",
    "    y_pred = svm.predict(X_test)\n",
    "    \n",
    "    # Evaluate metrics for each fold\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    # Append each metric\n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    macro_f1_scores.append(macro_f1)\n",
    "    \n",
    "    # Print metrics for each fold\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "    print(\"\\nAccuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"Macro Average F1-Score:\", macro_f1)\n",
    "\n",
    "# Calculate average metrics across all folds\n",
    "print(\"\\nAverage Metrics across 5 folds:\")\n",
    "print(\"Average Accuracy:\", np.mean(accuracy_scores))\n",
    "print(\"Average Precision:\", np.mean(precision_scores))\n",
    "print(\"Average Recall:\", np.mean(recall_scores))\n",
    "print(\"Average Macro F1-Score:\", np.mean(macro_f1_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with glove + countVectoriser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[6734  270]\n",
      " [ 306 5462]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9565    0.9615    0.9590      7004\n",
      "           1     0.9529    0.9469    0.9499      5768\n",
      "\n",
      "    accuracy                         0.9549     12772\n",
      "   macro avg     0.9547    0.9542    0.9544     12772\n",
      "weighted avg     0.9549    0.9549    0.9549     12772\n",
      "\n",
      "\n",
      "Macro Average F1-Score: 0.9544495436702043\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Step 1: Load pre-trained GloVe embeddings\n",
    "def load_glove(file_path):\n",
    "    embeddings_index = {}\n",
    "    with open(file_path, encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    return embeddings_index\n",
    "\n",
    "# Load GloVe vectors\n",
    "glove_path = \"glove.6B.100d.txt\"\n",
    "embeddings_index = load_glove(glove_path)\n",
    "\n",
    "# Step 2: Convert each document to GloVe embeddings by averaging word vectors\n",
    "def get_glove_embedding(text, embeddings_index, embed_dim=100):\n",
    "    words = text.split()\n",
    "    embeddings = [embeddings_index[word] for word in words if word in embeddings_index]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros(embed_dim)\n",
    "\n",
    "# Generate GloVe embeddings for the entire dataset\n",
    "X_glove = np.array([get_glove_embedding(text, embeddings_index) for text in data['processed_full_content']])\n",
    "\n",
    "# Step 3: Generate CountVectorizer features\n",
    "vectorizer = CountVectorizer(max_features=5000)\n",
    "X_count = vectorizer.fit_transform(data['processed_full_content'])\n",
    "\n",
    "# Step 4: Combine GloVe embeddings and CountVectorizer features\n",
    "# Use hstack to combine sparse CountVectorizer matrix with dense GloVe embeddings\n",
    "X_combined = hstack((X_count, X_glove))\n",
    "\n",
    "# Step 5: Train-test split\n",
    "y = data['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Train a classifier (e.g., SVM) on the combined features\n",
    "svm = SGDClassifier(loss='hinge', random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "\n",
    "# Step 7: Evaluate the model\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(\"\\nMacro Average F1-Score:\", macro_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with glove, count vectoriser and Stratified K-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - F1 Score (weighted): 0.9540576271559605\n",
      "Fold 1 - Confusion Matrix:\n",
      " [[11101   492]\n",
      " [  486  9208]]\n",
      "Fold 1 - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9581    0.9576    0.9578     11593\n",
      "           1     0.9493    0.9499    0.9496      9694\n",
      "\n",
      "    accuracy                         0.9541     21287\n",
      "   macro avg     0.9537    0.9537    0.9537     21287\n",
      "weighted avg     0.9541    0.9541    0.9541     21287\n",
      "\n",
      "Fold 2 - F1 Score (weighted): 0.9518794502764808\n",
      "Fold 2 - Confusion Matrix:\n",
      " [[11119   474]\n",
      " [  550  9144]]\n",
      "Fold 2 - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9529    0.9591    0.9560     11593\n",
      "           1     0.9507    0.9433    0.9470      9694\n",
      "\n",
      "    accuracy                         0.9519     21287\n",
      "   macro avg     0.9518    0.9512    0.9515     21287\n",
      "weighted avg     0.9519    0.9519    0.9519     21287\n",
      "\n",
      "Fold 3 - F1 Score (weighted): 0.9522081012321895\n",
      "Fold 3 - Confusion Matrix:\n",
      " [[11118   475]\n",
      " [  542  9151]]\n",
      "Fold 3 - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9535    0.9590    0.9563     11593\n",
      "           1     0.9507    0.9441    0.9474      9693\n",
      "\n",
      "    accuracy                         0.9522     21286\n",
      "   macro avg     0.9521    0.9516    0.9518     21286\n",
      "weighted avg     0.9522    0.9522    0.9522     21286\n",
      "\n",
      "\n",
      "Average F1 Score (weighted) across all folds: 0.952715059554877\n",
      "\n",
      "Average Classification Report across all folds:\n",
      "0:\n",
      "  precision: 0.9548\n",
      "  recall: 0.9586\n",
      "  f1-score: 0.9567\n",
      "  support: 11593.0000\n",
      "1:\n",
      "  precision: 0.9502\n",
      "  recall: 0.9457\n",
      "  f1-score: 0.9480\n",
      "  support: 9693.6667\n",
      "accuracy: 0.9527\n",
      "macro avg:\n",
      "  precision: 0.9525\n",
      "  recall: 0.9522\n",
      "  f1-score: 0.9523\n",
      "  support: 21286.6667\n",
      "weighted avg:\n",
      "  precision: 0.9527\n",
      "  recall: 0.9527\n",
      "  f1-score: 0.9527\n",
      "  support: 21286.6667\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "# Step 1: Load pre-trained GloVe embeddings\n",
    "def load_glove(file_path):\n",
    "    embeddings_index = {}\n",
    "    with open(file_path, encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    return embeddings_index\n",
    "\n",
    "# Load GloVe vectors\n",
    "glove_path = \"glove.6B.100d.txt\"\n",
    "embeddings_index = load_glove(glove_path)\n",
    "\n",
    "# Step 2: Convert each document to GloVe embeddings by averaging word vectors\n",
    "def get_glove_embedding(text, embeddings_index, embed_dim=100):\n",
    "    words = text.split()\n",
    "    embeddings = [embeddings_index[word] for word in words if word in embeddings_index]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros(embed_dim)\n",
    "\n",
    "# Generate GloVe embeddings for the entire dataset\n",
    "X_glove = np.array([get_glove_embedding(text, embeddings_index) for text in data['processed_full_content']])\n",
    "\n",
    "# Step 3: Generate CountVectorizer features\n",
    "vectorizer = CountVectorizer(max_features=5000)\n",
    "X_count = vectorizer.fit_transform(data['processed_full_content'])\n",
    "\n",
    "# Step 4: Combine GloVe embeddings and CountVectorizer features\n",
    "# Use hstack to combine sparse CountVectorizer matrix with dense GloVe embeddings\n",
    "X_combined = hstack((X_count, X_glove))\n",
    "X_combined = csr_matrix(X_combined)  # Convert to csr_matrix for subscriptable indexing\n",
    "\n",
    "# Define labels\n",
    "y = data['label']\n",
    "\n",
    "# Step 5: Set up Stratified K-Fold Cross-Validation\n",
    "kf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "fold = 1\n",
    "f1_scores = []\n",
    "all_classification_reports = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_combined, y):\n",
    "    # Split the data into training and testing sets for the current fold\n",
    "    X_train, X_test = X_combined[train_index], X_combined[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Train the SVM model on the current fold\n",
    "    svm = SGDClassifier(loss='hinge', random_state=42)\n",
    "    svm.fit(X_train, y_train)\n",
    "    y_pred = svm.predict(X_test)\n",
    "    \n",
    "    # Calculate F1-score for the current fold\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    f1_scores.append(f1)\n",
    "    classification_rep = classification_report(y_test, y_pred, digits=4, output_dict=True)\n",
    "    all_classification_reports.append(classification_rep)\n",
    "    \n",
    "    # Print F1-score and classification report for the current fold\n",
    "    print(f\"Fold {fold} - F1 Score (weighted): {f1}\")\n",
    "    print(f\"Fold {fold} - Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(f\"Fold {fold} - Classification Report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "    fold += 1\n",
    "\n",
    "# Step 6: Calculate and display average F1-score across all folds\n",
    "avg_f1_score = np.mean(f1_scores)\n",
    "print(\"\\nAverage F1 Score (weighted) across all folds:\", avg_f1_score)\n",
    "\n",
    "# Calculate the average classification report across folds\n",
    "avg_classification_report = {}\n",
    "for key in all_classification_reports[0].keys():\n",
    "    if isinstance(all_classification_reports[0][key], dict):\n",
    "        avg_classification_report[key] = {metric: np.mean([report[key][metric] for report in all_classification_reports]) \n",
    "                                          for metric in all_classification_reports[0][key]}\n",
    "    else:\n",
    "        avg_classification_report[key] = np.mean([report[key] for report in all_classification_reports])\n",
    "\n",
    "print(\"\\nAverage Classification Report across all folds:\")\n",
    "for label, metrics in avg_classification_report.items():\n",
    "    if isinstance(metrics, dict):\n",
    "        print(f\"{label}:\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"  {metric}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"{label}: {metrics:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - F1 Score (weighted): 0.954830207313335\n",
      "Fold 1 - Confusion Matrix:\n",
      " [[6655  300]\n",
      " [ 277 5540]]\n",
      "Fold 1 - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9600    0.9569    0.9585      6955\n",
      "           1     0.9486    0.9524    0.9505      5817\n",
      "\n",
      "    accuracy                         0.9548     12772\n",
      "   macro avg     0.9543    0.9546    0.9545     12772\n",
      "weighted avg     0.9548    0.9548    0.9548     12772\n",
      "\n",
      "Fold 2 - F1 Score (weighted): 0.9519500861173588\n",
      "Fold 2 - Confusion Matrix:\n",
      " [[6611  345]\n",
      " [ 269 5547]]\n",
      "Fold 2 - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9609    0.9504    0.9556      6956\n",
      "           1     0.9414    0.9537    0.9476      5816\n",
      "\n",
      "    accuracy                         0.9519     12772\n",
      "   macro avg     0.9512    0.9521    0.9516     12772\n",
      "weighted avg     0.9520    0.9519    0.9520     12772\n",
      "\n",
      "Fold 3 - F1 Score (weighted): 0.9556160302718006\n",
      "Fold 3 - Confusion Matrix:\n",
      " [[6656  300]\n",
      " [ 267 5549]]\n",
      "Fold 3 - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9614    0.9569    0.9591      6956\n",
      "           1     0.9487    0.9541    0.9514      5816\n",
      "\n",
      "    accuracy                         0.9556     12772\n",
      "   macro avg     0.9551    0.9555    0.9553     12772\n",
      "weighted avg     0.9556    0.9556    0.9556     12772\n",
      "\n",
      "Fold 4 - F1 Score (weighted): 0.9539084684721251\n",
      "Fold 4 - Confusion Matrix:\n",
      " [[6620  336]\n",
      " [ 253 5563]]\n",
      "Fold 4 - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9632    0.9517    0.9574      6956\n",
      "           1     0.9430    0.9565    0.9497      5816\n",
      "\n",
      "    accuracy                         0.9539     12772\n",
      "   macro avg     0.9531    0.9541    0.9536     12772\n",
      "weighted avg     0.9540    0.9539    0.9539     12772\n",
      "\n",
      "Fold 5 - F1 Score (weighted): 0.9566182761560942\n",
      "Fold 5 - Confusion Matrix:\n",
      " [[6688  268]\n",
      " [ 286 5530]]\n",
      "Fold 5 - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9590    0.9615    0.9602      6956\n",
      "           1     0.9538    0.9508    0.9523      5816\n",
      "\n",
      "    accuracy                         0.9566     12772\n",
      "   macro avg     0.9564    0.9561    0.9563     12772\n",
      "weighted avg     0.9566    0.9566    0.9566     12772\n",
      "\n",
      "\n",
      "Average F1 Score (weighted) across all folds: 0.9545846136661428\n",
      "\n",
      "Average Classification Report across all folds:\n",
      "0:\n",
      "  precision: 0.9609\n",
      "  recall: 0.9555\n",
      "  f1-score: 0.9582\n",
      "  support: 6955.8000\n",
      "1:\n",
      "  precision: 0.9471\n",
      "  recall: 0.9535\n",
      "  f1-score: 0.9503\n",
      "  support: 5816.2000\n",
      "accuracy: 0.9546\n",
      "macro avg:\n",
      "  precision: 0.9540\n",
      "  recall: 0.9545\n",
      "  f1-score: 0.9542\n",
      "  support: 12772.0000\n",
      "weighted avg:\n",
      "  precision: 0.9546\n",
      "  recall: 0.9546\n",
      "  f1-score: 0.9546\n",
      "  support: 12772.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 1: Load pre-trained GloVe embeddings\n",
    "def load_glove(file_path):\n",
    "    embeddings_index = {}\n",
    "    with open(file_path, encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    return embeddings_index\n",
    "\n",
    "# Load GloVe vectors\n",
    "glove_path = r\"c:\\Users\\Admin\\Downloads\\glove.6B\\glove.6B.300d.txt\"\n",
    "embeddings_index = load_glove(glove_path)\n",
    "\n",
    "# Step 2: Convert each document to GloVe embeddings by averaging word vectors\n",
    "def get_glove_embedding(text, embeddings_index, embed_dim=300):\n",
    "    words = text.split()\n",
    "    embeddings = [embeddings_index[word] for word in words if word in embeddings_index]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros(embed_dim)\n",
    "\n",
    "# Generate GloVe embeddings for the entire dataset\n",
    "X_glove = np.array([get_glove_embedding(text, embeddings_index) for text in data['processed_full_content']])\n",
    "\n",
    "# Step 3: Generate CountVectorizer features\n",
    "vectorizer = CountVectorizer(max_features=5000)\n",
    "X_count = vectorizer.fit_transform(data['processed_full_content'])\n",
    "\n",
    "# Step 4: Standardize GloVe embeddings and combine with CountVectorizer features\n",
    "scaler = StandardScaler()\n",
    "X_glove_scaled = scaler.fit_transform(X_glove)\n",
    "\n",
    "# Use hstack to combine sparse CountVectorizer matrix with dense (scaled) GloVe embeddings\n",
    "X_combined = hstack((X_count, X_glove_scaled))\n",
    "X_combined = csr_matrix(X_combined)  # Convert to csr_matrix for subscriptable indexing\n",
    "\n",
    "# Define labels\n",
    "y = data['label']\n",
    "\n",
    "# Step 5: Set up Stratified K-Fold Cross-Validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold = 1\n",
    "f1_scores = []\n",
    "all_classification_reports = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_combined, y):\n",
    "    # Split the data into training and testing sets for the current fold\n",
    "    X_train, X_test = X_combined[train_index], X_combined[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Train the SVM model with L2 regularization (penalty='l2')\n",
    "    svm = SGDClassifier(loss='hinge', penalty='l2', alpha=0.0001, random_state=42)\n",
    "    svm.fit(X_train, y_train)\n",
    "    y_pred = svm.predict(X_test)\n",
    "    \n",
    "    # Calculate F1-score for the current fold\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    f1_scores.append(f1)\n",
    "    classification_rep = classification_report(y_test, y_pred, digits=4, output_dict=True)\n",
    "    all_classification_reports.append(classification_rep)\n",
    "    \n",
    "    # Print F1-score and classification report for the current fold\n",
    "    print(f\"Fold {fold} - F1 Score (weighted): {f1}\")\n",
    "    print(f\"Fold {fold} - Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(f\"Fold {fold} - Classification Report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "    fold += 1\n",
    "\n",
    "# Step 6: Calculate and display average F1-score across all folds\n",
    "avg_f1_score = np.mean(f1_scores)\n",
    "print(\"\\nAverage F1 Score (weighted) across all folds:\", avg_f1_score)\n",
    "\n",
    "# Calculate the average classification report across folds\n",
    "avg_classification_report = {}\n",
    "for key in all_classification_reports[0].keys():\n",
    "    if isinstance(all_classification_reports[0][key], dict):\n",
    "        avg_classification_report[key] = {metric: np.mean([report[key][metric] for report in all_classification_reports]) \n",
    "                                          for metric in all_classification_reports[0][key]}\n",
    "    else:\n",
    "        avg_classification_report[key] = np.mean([report[key] for report in all_classification_reports])\n",
    "\n",
    "print(\"\\nAverage Classification Report across all folds:\")\n",
    "for label, metrics in avg_classification_report.items():\n",
    "    if isinstance(metrics, dict):\n",
    "        print(f\"{label}:\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"  {metric}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"{label}: {metrics:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with Count Vectoriser, Glove, Stratified K-fold Cross-validation, L2 Regularisation, Gridsearch hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "18 fits failed out of a total of 36.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'hinge', 'squared_epsilon_insensitive', 'squared_hinge', 'log_loss', 'huber', 'modified_huber', 'squared_error', 'perceptron'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'modified_huber', 'log_loss', 'epsilon_insensitive', 'huber', 'squared_error', 'squared_epsilon_insensitive', 'hinge', 'squared_hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'log_loss', 'squared_hinge', 'huber', 'squared_error', 'hinge', 'epsilon_insensitive', 'perceptron', 'squared_epsilon_insensitive', 'modified_huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'modified_huber', 'epsilon_insensitive', 'squared_hinge', 'squared_epsilon_insensitive', 'log_loss', 'huber', 'perceptron', 'squared_error', 'hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'hinge', 'perceptron', 'squared_error', 'log_loss', 'modified_huber', 'epsilon_insensitive', 'squared_epsilon_insensitive', 'squared_hinge', 'huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'epsilon_insensitive', 'squared_error', 'hinge', 'modified_huber', 'log_loss', 'huber', 'squared_hinge', 'squared_epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'log_loss', 'modified_huber', 'epsilon_insensitive', 'squared_hinge', 'squared_epsilon_insensitive', 'squared_error', 'hinge', 'perceptron', 'huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'squared_epsilon_insensitive', 'perceptron', 'huber', 'hinge', 'log_loss', 'squared_hinge', 'squared_error', 'modified_huber'}. Got 'log' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\ma\\core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.94973748 0.94973748        nan        nan 0.95581232 0.95581232\n",
      "        nan        nan 0.95841334 0.95841334        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - F1 Score (weighted): 0.9615324260866738\n",
      "Best Parameters for Fold 1: {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l2'}\n",
      "Fold 1 - Confusion Matrix:\n",
      " [[6751  204]\n",
      " [ 287 5530]]\n",
      "Fold 1 - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9592    0.9707    0.9649      6955\n",
      "           1     0.9644    0.9507    0.9575      5817\n",
      "\n",
      "    accuracy                         0.9616     12772\n",
      "   macro avg     0.9618    0.9607    0.9612     12772\n",
      "weighted avg     0.9616    0.9616    0.9615     12772\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "18 fits failed out of a total of 36.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_hinge', 'squared_epsilon_insensitive', 'huber', 'modified_huber', 'squared_error', 'hinge', 'perceptron', 'epsilon_insensitive', 'log_loss'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'hinge', 'squared_epsilon_insensitive', 'squared_hinge', 'log_loss', 'huber', 'modified_huber', 'squared_error', 'perceptron'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'hinge', 'perceptron', 'squared_error', 'log_loss', 'modified_huber', 'epsilon_insensitive', 'squared_epsilon_insensitive', 'squared_hinge', 'huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'log_loss', 'squared_hinge', 'huber', 'squared_error', 'hinge', 'epsilon_insensitive', 'perceptron', 'squared_epsilon_insensitive', 'modified_huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'modified_huber', 'epsilon_insensitive', 'squared_hinge', 'squared_epsilon_insensitive', 'log_loss', 'huber', 'perceptron', 'squared_error', 'hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'epsilon_insensitive', 'squared_error', 'hinge', 'modified_huber', 'log_loss', 'huber', 'squared_hinge', 'squared_epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'modified_huber', 'log_loss', 'epsilon_insensitive', 'huber', 'squared_error', 'squared_epsilon_insensitive', 'hinge', 'squared_hinge'}. Got 'log' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\ma\\core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.94682911 0.94682911        nan        nan 0.95577264 0.95577264\n",
      "        nan        nan 0.95819998 0.95819998        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - F1 Score (weighted): 0.9580712079690743\n",
      "Best Parameters for Fold 2: {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l2'}\n",
      "Fold 2 - Confusion Matrix:\n",
      " [[6750  206]\n",
      " [ 329 5487]]\n",
      "Fold 2 - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9535    0.9704    0.9619      6956\n",
      "           1     0.9638    0.9434    0.9535      5816\n",
      "\n",
      "    accuracy                         0.9581     12772\n",
      "   macro avg     0.9587    0.9569    0.9577     12772\n",
      "weighted avg     0.9582    0.9581    0.9581     12772\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "18 fits failed out of a total of 36.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'hinge', 'squared_epsilon_insensitive', 'squared_hinge', 'log_loss', 'huber', 'modified_huber', 'squared_error', 'perceptron'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'squared_epsilon_insensitive', 'hinge', 'perceptron', 'modified_huber', 'squared_hinge', 'squared_error', 'huber', 'log_loss'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'squared_epsilon_insensitive', 'perceptron', 'huber', 'hinge', 'log_loss', 'squared_hinge', 'squared_error', 'modified_huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_hinge', 'squared_epsilon_insensitive', 'huber', 'modified_huber', 'squared_error', 'hinge', 'perceptron', 'epsilon_insensitive', 'log_loss'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'log_loss', 'modified_huber', 'epsilon_insensitive', 'squared_hinge', 'squared_epsilon_insensitive', 'squared_error', 'hinge', 'perceptron', 'huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'hinge', 'epsilon_insensitive', 'squared_epsilon_insensitive', 'modified_huber', 'huber', 'squared_hinge', 'log_loss', 'perceptron', 'squared_error'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'modified_huber', 'log_loss', 'epsilon_insensitive', 'huber', 'squared_error', 'squared_epsilon_insensitive', 'hinge', 'squared_hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'hinge', 'perceptron', 'squared_error', 'log_loss', 'modified_huber', 'epsilon_insensitive', 'squared_epsilon_insensitive', 'squared_hinge', 'huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'log_loss', 'squared_hinge', 'huber', 'squared_error', 'hinge', 'epsilon_insensitive', 'perceptron', 'squared_epsilon_insensitive', 'modified_huber'}. Got 'log' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.94479563 0.94479563        nan        nan 0.954067   0.954067\n",
      "        nan        nan 0.95743592 0.95743592        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - F1 Score (weighted): 0.9619548195119899\n",
      "Best Parameters for Fold 3: {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l2'}\n",
      "Fold 3 - Confusion Matrix:\n",
      " [[6700  256]\n",
      " [ 230 5586]]\n",
      "Fold 3 - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9668    0.9632    0.9650      6956\n",
      "           1     0.9562    0.9605    0.9583      5816\n",
      "\n",
      "    accuracy                         0.9619     12772\n",
      "   macro avg     0.9615    0.9618    0.9617     12772\n",
      "weighted avg     0.9620    0.9619    0.9620     12772\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "18 fits failed out of a total of 36.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'hinge', 'squared_epsilon_insensitive', 'squared_hinge', 'log_loss', 'huber', 'modified_huber', 'squared_error', 'perceptron'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'squared_epsilon_insensitive', 'perceptron', 'huber', 'hinge', 'log_loss', 'squared_hinge', 'squared_error', 'modified_huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'hinge', 'epsilon_insensitive', 'squared_epsilon_insensitive', 'modified_huber', 'huber', 'squared_hinge', 'log_loss', 'perceptron', 'squared_error'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'log_loss', 'modified_huber', 'epsilon_insensitive', 'squared_hinge', 'squared_epsilon_insensitive', 'squared_error', 'hinge', 'perceptron', 'huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'squared_error', 'modified_huber', 'squared_hinge', 'squared_epsilon_insensitive', 'hinge', 'huber', 'epsilon_insensitive', 'log_loss'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'epsilon_insensitive', 'squared_error', 'hinge', 'modified_huber', 'log_loss', 'huber', 'squared_hinge', 'squared_epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'squared_epsilon_insensitive', 'hinge', 'perceptron', 'modified_huber', 'squared_hinge', 'squared_error', 'huber', 'log_loss'}. Got 'log' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.94779749 0.94779749        nan        nan 0.95620265 0.95620265\n",
      "        nan        nan 0.95770353 0.95770353        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 - F1 Score (weighted): 0.9614710143364869\n",
      "Best Parameters for Fold 4: {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l2'}\n",
      "Fold 4 - Confusion Matrix:\n",
      " [[6723  233]\n",
      " [ 259 5557]]\n",
      "Fold 4 - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9629    0.9665    0.9647      6956\n",
      "           1     0.9598    0.9555    0.9576      5816\n",
      "\n",
      "    accuracy                         0.9615     12772\n",
      "   macro avg     0.9613    0.9610    0.9612     12772\n",
      "weighted avg     0.9615    0.9615    0.9615     12772\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "18 fits failed out of a total of 36.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'squared_error', 'modified_huber', 'squared_hinge', 'squared_epsilon_insensitive', 'hinge', 'huber', 'epsilon_insensitive', 'log_loss'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'log_loss', 'squared_hinge', 'huber', 'squared_error', 'hinge', 'epsilon_insensitive', 'perceptron', 'squared_epsilon_insensitive', 'modified_huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'modified_huber', 'log_loss', 'epsilon_insensitive', 'huber', 'squared_error', 'squared_epsilon_insensitive', 'hinge', 'squared_hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'hinge', 'epsilon_insensitive', 'squared_epsilon_insensitive', 'modified_huber', 'huber', 'squared_hinge', 'log_loss', 'perceptron', 'squared_error'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'modified_huber', 'epsilon_insensitive', 'squared_hinge', 'squared_epsilon_insensitive', 'log_loss', 'huber', 'perceptron', 'squared_error', 'hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_hinge', 'squared_epsilon_insensitive', 'huber', 'modified_huber', 'squared_error', 'hinge', 'perceptron', 'epsilon_insensitive', 'log_loss'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'log_loss', 'modified_huber', 'epsilon_insensitive', 'squared_hinge', 'squared_epsilon_insensitive', 'squared_error', 'hinge', 'perceptron', 'huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'squared_epsilon_insensitive', 'perceptron', 'huber', 'hinge', 'log_loss', 'squared_hinge', 'squared_error', 'modified_huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'epsilon_insensitive', 'squared_error', 'hinge', 'modified_huber', 'log_loss', 'huber', 'squared_hinge', 'squared_epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'squared_epsilon_insensitive', 'hinge', 'perceptron', 'modified_huber', 'squared_hinge', 'squared_error', 'huber', 'log_loss'}. Got 'log' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.94879796 0.94879796        nan        nan 0.95697986 0.95697986\n",
      "        nan        nan 0.95828522 0.95828522        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 - F1 Score (weighted): 0.9617039597687295\n",
      "Best Parameters for Fold 5: {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l2'}\n",
      "Fold 5 - Confusion Matrix:\n",
      " [[6728  228]\n",
      " [ 261 5555]]\n",
      "Fold 5 - Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9627    0.9672    0.9649      6956\n",
      "           1     0.9606    0.9551    0.9578      5816\n",
      "\n",
      "    accuracy                         0.9617     12772\n",
      "   macro avg     0.9616    0.9612    0.9614     12772\n",
      "weighted avg     0.9617    0.9617    0.9617     12772\n",
      "\n",
      "\n",
      "Average F1 Score (weighted) across all folds: 0.960946685534591\n",
      "\n",
      "Average Classification Report across all folds:\n",
      "0:\n",
      "  precision: 0.9610\n",
      "  recall: 0.9676\n",
      "  f1-score: 0.9643\n",
      "  support: 6955.8000\n",
      "1:\n",
      "  precision: 0.9609\n",
      "  recall: 0.9530\n",
      "  f1-score: 0.9570\n",
      "  support: 5816.2000\n",
      "accuracy: 0.9610\n",
      "macro avg:\n",
      "  precision: 0.9610\n",
      "  recall: 0.9603\n",
      "  f1-score: 0.9606\n",
      "  support: 12772.0000\n",
      "weighted avg:\n",
      "  precision: 0.9610\n",
      "  recall: 0.9610\n",
      "  f1-score: 0.9609\n",
      "  support: 12772.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 1: Load pre-trained GloVe embeddings\n",
    "def load_glove(file_path):\n",
    "    embeddings_index = {}\n",
    "    with open(file_path, encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    return embeddings_index\n",
    "\n",
    "# Load GloVe vectors\n",
    "glove_path = \"glove.6B.100d.txt\"\n",
    "embeddings_index = load_glove(glove_path)\n",
    "\n",
    "# Step 2: Convert each document to GloVe embeddings by averaging word vectors\n",
    "def get_glove_embedding(text, embeddings_index, embed_dim=100):\n",
    "    words = text.split()\n",
    "    embeddings = [embeddings_index[word] for word in words if word in embeddings_index]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros(embed_dim)\n",
    "\n",
    "# Generate GloVe embeddings for the entire dataset\n",
    "X_glove = np.array([get_glove_embedding(text, embeddings_index) for text in data['processed_full_content']])\n",
    "\n",
    "# Step 3: Generate CountVectorizer features\n",
    "vectorizer = CountVectorizer(max_features=5000)\n",
    "X_count = vectorizer.fit_transform(data['processed_full_content'])\n",
    "\n",
    "# Step 4: Standardize GloVe embeddings and combine with CountVectorizer features\n",
    "scaler = StandardScaler()\n",
    "X_glove_scaled = scaler.fit_transform(X_glove)\n",
    "\n",
    "# Use hstack to combine sparse CountVectorizer matrix with dense (scaled) GloVe embeddings\n",
    "X_combined = hstack((X_count, X_glove_scaled))\n",
    "X_combined = csr_matrix(X_combined)  # Convert to csr_matrix for subscriptable indexing\n",
    "\n",
    "# Define labels\n",
    "y = data['label']\n",
    "\n",
    "# Step 5: Set up Stratified K-Fold Cross-Validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold = 1\n",
    "f1_scores = []\n",
    "all_classification_reports = []\n",
    "\n",
    "# Step 6: Define parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'alpha': [0.0001, 0.001, 0.01],\n",
    "    'penalty': ['l2'],\n",
    "    'loss': ['hinge', 'log'],  # 'hinge' for SVM, 'log' for logistic regression\n",
    "    'max_iter': [1000, 2000]\n",
    "}\n",
    "\n",
    "# Step 7: Iterate over each fold in cross-validation\n",
    "for train_index, test_index in kf.split(X_combined, y):\n",
    "    # Split the data into training and testing sets for the current fold\n",
    "    X_train, X_test = X_combined[train_index], X_combined[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Set up GridSearchCV with the SGDClassifier and parameter grid\n",
    "    svm = SGDClassifier(random_state=42)\n",
    "    grid_search = GridSearchCV(svm, param_grid, scoring='f1_weighted', cv=3, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best model from GridSearchCV\n",
    "    best_svm = grid_search.best_estimator_\n",
    "    y_pred = best_svm.predict(X_test)\n",
    "    \n",
    "    # Calculate F1-score for the current fold\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    f1_scores.append(f1)\n",
    "    classification_rep = classification_report(y_test, y_pred, digits=4, output_dict=True)\n",
    "    all_classification_reports.append(classification_rep)\n",
    "    \n",
    "    # Print F1-score, best parameters, and classification report for the current fold\n",
    "    print(f\"Fold {fold} - F1 Score (weighted): {f1}\")\n",
    "    print(f\"Best Parameters for Fold {fold}: {grid_search.best_params_}\")\n",
    "    print(f\"Fold {fold} - Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(f\"Fold {fold} - Classification Report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
    "    fold += 1\n",
    "\n",
    "# Step 8: Calculate and display average F1-score across all folds\n",
    "avg_f1_score = np.mean(f1_scores)\n",
    "print(\"\\nAverage F1 Score (weighted) across all folds:\", avg_f1_score)\n",
    "\n",
    "# Calculate the average classification report across folds\n",
    "avg_classification_report = {}\n",
    "for key in all_classification_reports[0].keys():\n",
    "    if isinstance(all_classification_reports[0][key], dict):\n",
    "        avg_classification_report[key] = {metric: np.mean([report[key][metric] for report in all_classification_reports]) \n",
    "                                          for metric in all_classification_reports[0][key]}\n",
    "    else:\n",
    "        avg_classification_report[key] = np.mean([report[key] for report in all_classification_reports])\n",
    "\n",
    "print(\"\\nAverage Classification Report across all folds:\")\n",
    "for label, metrics in avg_classification_report.items():\n",
    "    if isinstance(metrics, dict):\n",
    "        print(f\"{label}:\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"  {metric}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"{label}: {metrics:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
