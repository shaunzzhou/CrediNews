{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working dir: /Users/inflaton/code/engd/papers/DM-Fake-News-Detection\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "if \"workding_dir\" not in locals():\n",
    "    workding_dir = str(Path.cwd().parent)\n",
    "os.chdir(workding_dir)\n",
    "sys.path.append(workding_dir)\n",
    "print(\"working dir:\", workding_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying our best model (CNN + Word2Vec) on the scraped data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Statistical functions\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# For concurrency (running functions in parallel)\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# For caching (to speed up repeated function calls)\n",
    "from functools import lru_cache\n",
    "\n",
    "# For progress tracking\n",
    "from tqdm import tqdm\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Define function to process text\n",
    "import string\n",
    "from nltk.stem import *\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "# Import necessary libraries\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Statistical functions\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# For concurrency (running functions in parallel)\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# For caching (to speed up repeated function calls)\n",
    "from functools import lru_cache\n",
    "\n",
    "# For progress tracking\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Plotting and Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Language Detection packages\n",
    "# `langdetect` for detecting language\n",
    "from langdetect import detect as langdetect_detect, DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "\n",
    "# `langid` for an alternative language detection method\n",
    "from langid import classify as langid_classify\n",
    "\n",
    "# Text Preprocessing and NLP\n",
    "# Stopwords (common words to ignore) from NLTK\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Tokenizing sentences/words\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Part-of-speech tagging\n",
    "from nltk import pos_tag\n",
    "\n",
    "# Lemmatization (converting words to their base form)\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "# Regular expressions for text pattern matching\n",
    "import re\n",
    "\n",
    "\n",
    "def process_full_review(text):\n",
    "    # Convert to lowercase and tokenize\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in string.punctuation]\n",
    "    stemmer = PorterStemmer()\n",
    "    # List of stopwords\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    allowed_words = [\n",
    "        \"no\",\n",
    "        \"not\",\n",
    "        \"don't\",\n",
    "        \"dont\",\n",
    "        \"don\",\n",
    "        \"but\",\n",
    "        \"however\",\n",
    "        \"never\",\n",
    "        \"wasn't\",\n",
    "        \"wasnt\",\n",
    "        \"shouldn't\",\n",
    "        \"shouldnt\",\n",
    "        \"mustn't\",\n",
    "        \"musnt\",\n",
    "    ]\n",
    "\n",
    "    stemmed = [\n",
    "        stemmer.stem(word)\n",
    "        for word in tokens\n",
    "        if word not in stop_words or word in allowed_words\n",
    "    ]\n",
    "    return \" \".join(stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'full_content', 'processed_full_content'],\n",
       "        num_rows: 54441\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, concatenate_datasets, Dataset\n",
    "\n",
    "datasets = load_dataset(\n",
    "    \"csv\",\n",
    "    data_files={\n",
    "        \"train\": [\n",
    "            \"dataset/train_data_1.csv\",\n",
    "            \"dataset/train_data_2.csv\",\n",
    "            \"dataset/train_data_3.csv\",\n",
    "            \"dataset/train_data_4.csv\",\n",
    "        ],\n",
    "    },\n",
    ")\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inflaton/anaconda3/envs/fake-news/lib/python3.11/site-packages/keras/src/saving/saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 9 variables whereas the saved optimizer has 16 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,000,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">296</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,064</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_6          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding_6 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m100\u001b[0m)       │     \u001b[38;5;34m1,000,000\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_6 (\u001b[38;5;33mConv1D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m296\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m32,064\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_6          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,072,580</span> (7.91 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,072,580\u001b[0m (7.91 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,036,289</span> (3.95 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,036,289\u001b[0m (3.95 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,036,291</span> (3.95 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,036,291\u001b[0m (3.95 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model(\"results/CNN_model.keras\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_model(model, train_data, val_data, force_reprocess=False):\n",
    "    # Apply process_full_review function with tqdm progress bar and expand the results into separate columns.\n",
    "    processed_columns = \"processed_full_content\"\n",
    "    if force_reprocess or processed_columns not in train_data.columns:\n",
    "        # Enable tqdm for pandas (progress bar)\n",
    "        tqdm.pandas(desc=\"Processing Train Data\")\n",
    "        \n",
    "        train_data[processed_columns] = train_data[\"full_content\"].progress_apply(\n",
    "            lambda x: pd.Series(process_full_review(x))\n",
    "        )\n",
    "\n",
    "    if force_reprocess or processed_columns not in val_data.columns:\n",
    "        # Enable tqdm for pandas (progress bar)\n",
    "        tqdm.pandas(desc=\"Processing Val Data\")\n",
    "\n",
    "        # Apply process_full_review function with tqdm progress bar and expand the results into separate columns.\n",
    "        val_data[processed_columns] = val_data[\"full_content\"].progress_apply(\n",
    "            lambda x: pd.Series(process_full_review(x))\n",
    "        )\n",
    "\n",
    "    print(\"Evaluating Model\")\n",
    "    \n",
    "    max_words = 10000\n",
    "    max_sequence_length = 300\n",
    "\n",
    "    train_texts = train_data[\"processed_full_content\"]\n",
    "    tokenizer = Tokenizer(num_words=max_words)\n",
    "    tokenizer.fit_on_texts(train_texts)\n",
    "\n",
    "    val_texts = val_data[\"processed_full_content\"]\n",
    "\n",
    "    X_val = pad_sequences(\n",
    "        tokenizer.texts_to_sequences(val_texts), maxlen=max_sequence_length\n",
    "    )\n",
    "    y_pred = (model.predict(X_val) > 0.5).astype(int)\n",
    "\n",
    "    if \"label\" not in val_data.columns:\n",
    "        return y_pred\n",
    "\n",
    "    y_val = val_data[\"label\"]\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision = precision_score(y_val, y_pred)\n",
    "    recall = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1313 entries, 0 to 1312\n",
      "Data columns (total 3 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   source                  1313 non-null   object\n",
      " 1   full_content            1313 non-null   object\n",
      " 2   processed_full_content  1313 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 30.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train = datasets[\"train\"].to_pandas()\n",
    "df_test = pd.read_csv(\"dataset/scrapped_news.csv\")\n",
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Model\n",
      "\u001b[1m42/42\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "\n",
      "Prediction Results:\n",
      "Total articles: 1313\n",
      "Predicted Real: [611]\n",
      "Predicted Fake: [702]\n"
     ]
    }
   ],
   "source": [
    "predictions = evaluate_model(model, df_train, df_test)\n",
    "\n",
    "# Print results\n",
    "print(\"\\nPrediction Results:\")\n",
    "print(f\"Total articles: {len(predictions)}\")\n",
    "print(f\"Predicted Real: {sum(predictions == 1)}\")\n",
    "print(f\"Predicted Fake: {sum(predictions == 0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(\"dataset/scrapped_news.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions by Source:\n",
      "                  Predicted Real  Predicted Fake\n",
      "source                                          \n",
      "AP                           124              20\n",
      "BBC                           51              20\n",
      "Breitbart                    137              39\n",
      "CNN                           68              40\n",
      "Guardian                      49              50\n",
      "NPR                           61              18\n",
      "Natural News                  57              71\n",
      "News Max                      84             105\n",
      "The Daily Caller              14             147\n",
      "Zerohedge                     57             101\n",
      "\n",
      "Percentage of Fake News by Source:\n",
      "source\n",
      "The Daily Caller    91.304348\n",
      "Zerohedge           63.924051\n",
      "News Max            55.555556\n",
      "Natural News        55.468750\n",
      "Guardian            50.505051\n",
      "CNN                 37.037037\n",
      "BBC                 28.169014\n",
      "NPR                 22.784810\n",
      "Breitbart           22.159091\n",
      "AP                  13.888889\n",
      "Name: predicted_label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data_copy = df_test.copy()\n",
    "\n",
    "# Add predictions to scraped data\n",
    "data_copy['predicted_label'] = predictions\n",
    "\n",
    "# Print predictions by source\n",
    "print(\"\\nPredictions by Source:\")\n",
    "source_predictions = data_copy.groupby('source')['predicted_label'].value_counts().unstack()\n",
    "source_predictions.columns = ['Predicted Real', 'Predicted Fake']\n",
    "print(source_predictions)\n",
    "\n",
    "# Calculate percentage of fake news by source\n",
    "fake_percentages = data_copy.groupby('source')['predicted_label'].mean() * 100\n",
    "print(\"\\nPercentage of Fake News by Source:\")\n",
    "print(fake_percentages.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source:  Breitbart\n",
      "House Republicans say the Biden-Harris White House might have broken the law when they altered President Joe Biden’s remarks in the official transcript to imply he did not call Trump supporters “garbage.”\n",
      "Biden on Tuesday during a video call with Voto Latino in support of Vice President Kamala Harris’s presidential campaign said, “The only garbage I see floating out there is his supporters.”\n",
      "However, after facing immediate backlash from Republicans and even some Democrats, the White House claimed that Biden did not call Trump supporters “garbage,” but was instead referring to one Trump supporter — namely, comedian Tony Hinchliffe.\n",
      "The White House released a transcript that reinforced that argument, adding an apostrophe to “supporters” to read “supporter’s,” and then adding an em-dash to make it seem like Biden had not completed his sentence.\n",
      "The transcript said (emphasis added):\n",
      "The only garbage I see floating out there is his supporter’s — his — his demonization of Latinos is unconscionable, and it’s un-American.\n",
      "Hinchliffe, known for his off-color jokes, had performed at Trump’s Madison Square Garden rally on Sunday and had joked that Puerto Rico was a “floating island of garbage.”\n",
      "Biden also later posted on X that he was referring to Hinchliffe’s “demonization of Latinos.”\n",
      "According to House Republican Conference Chair Elise Stefanik (R-NY) and House Oversight Committee Chairman James Comer (R-KY), the White House’s addition of an apostrophe may have violated the Presidential Records Act.\n",
      "In a letter to White House Counsel Edward Siskel, they demanded that the White House retain and preserve all documents and internal communications related to Biden’s statement and the release of the inaccurate transcript.\n",
      "They also called on the White House to correct the transcript to reflect what Biden said. They said:\n",
      "President Biden’s vindictive words were unsurprising, given his previous statements regarding people who choose not to vote for his preferred candidate. Unsurprising too were the White House’s actions after he said them. Instead of apologizing or clarifying President Biden’s words, the White House instead sought to change them (despite them being recorded on video) by releasing a false transcript of his remarks. The move is not only craven, but it also appears to be in violation of federal law, including the Presidential Records Act of 1978.\n",
      "“White House staff cannot rewrite the words of the President of the United States to be more politically on message. Though President Biden’s relevance continues to diminish, his words continue to matter, even as they become increasingly divisive and erratic,” they added.\n",
      "Follow Breitbart News’s Kristina Wong on ”X”, Truth Social, or on Facebook. GOP: WH May Have Illegally Altered Biden's 'Garbage' Remark\n"
     ]
    }
   ],
   "source": [
    "print(\"source: \", data_copy[data_copy[\"predicted_label\"] == 0].iloc[0][\"source\"])\n",
    "print(data_copy[data_copy[\"predicted_label\"] == 0].iloc[0][\"full_content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source:  Breitbart\n",
      "CLAIM: Vice President Kamala Harris’s campaign implied former President Donald Trump called for Liz Cheney to be put before a firing squad.\n",
      "FACT CHECK: False. Trump’s comments on “guns trained on her face” were about Cheney stoking foreign wars without being willing to fight in their front lines.\n",
      "Vice President Kamala Harris’s campaign took former President Donald Trump’s words out of context, to suggest that he was calling for Liz Cheney to be put before a firing squad.\n",
      "Her campaign posted a video of Trump speaking to Tucker Carlson on X/Twitter, with a caption that paraphrased him:\n",
      "Let’s put Liz Cheney with a rifle standing there with nine barrels shooting at her. Let’s see how she feels about it when the guns are trained on her face\n",
      "Rather than suggesting she be executed, Trump was speaking about how neoconservatives are quick to send young Americans to fight overseas in war — which Trump has long opposed, particularly the Iraq and Afghanistan Wars championed by Cheney and her father, former Vice President Dick Cheney.\n",
      "Trump had also said: “They’re all war hawks when they’re sitting in Washington in a nice building saying Oh gee, let’s send 10,000 troops into the mouths of the enemy.”\n",
      "Karoline Leavitt, Trump Campaign National Press Secretary, blasted the Harris-Walz campaign:\n",
      "President Trump is 100% correct that warmongers like Liz Cheney are very quick to start wars and send other Americans to fight them, rather than go into combat themselves. This is the continuation of the latest fake media outrage days before the election in a blatant attempt to interfere on behalf of Kamala Harris.\n",
      "Cheney herself tried to spread the lie, posting on X:\n",
      "This is how dictators destroy free nations. They threaten those who speak against them with death. We cannot entrust our country and our freedom to a petty, vindictive, cruel, unstable man who wants to be a tyrant. #Womenwillnotbesilenced #VoteKamala\n",
      "As Democrat operatives tired to spread the false claim, even Trump critic former Rep. Joe Walsh said Trump did not call for her to be put before a firing squad.\n",
      "He posted on X:\n",
      "Trump did NOT call for Liz Cheney to be executed.\n",
      "This is what’s so wrong with our politics today. Look, you know how I feel about Trump, and I’ve been out there every day for 2-3 months campaigning my ass off to help get @KamalaHarris elected, but this short clip is so deceptive. Trump is NOT calling for Liz Cheney to be executed in front of a firing line. He’s not. Listen to the entirety of what he said. In Trump’s typically stupid, ugly fashion, he’s trying to make a point about Cheney’s stance on war. But Aaron (who I like & respect), by posting ONLY this 11 second clip, makes it look like he’s calling for her to be executed. He’s not. He’s an utterly horrible human being who’s utterly unfit for office, but the truth should always matter. And the truth is that Trump is not calling for Liz Cheney to be executed. But…this 11 second clip will have a gazillion views, and the truth will have just a handful of views.\n",
      "Both former Vice President Cheney and former Wyoming Republican Rep. Cheney has endorsed Harris, with the younger Cheney even campaigning on the trail for her. Fact Check: Harris Campaign Twists Trump Comment on Liz Cheney to Claim He Called for Her Execution\n"
     ]
    }
   ],
   "source": [
    "print(\"source: \", data_copy[data_copy[\"predicted_label\"] == 1].iloc[0][\"source\"])\n",
    "print(data_copy[data_copy[\"predicted_label\"] == 1].iloc[0][\"full_content\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fake-news",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
