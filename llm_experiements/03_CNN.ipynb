{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working dir: /Users/inflaton/code/engd/papers/DM-Fake-News-Detection\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "if \"workding_dir\" not in locals():\n",
    "    workding_dir = str(Path.cwd().parent)\n",
    "os.chdir(workding_dir)\n",
    "sys.path.append(workding_dir)\n",
    "print(\"working dir:\", workding_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Detection to Credibility: A Machine Learning Framework for Assessing News Source Reliability\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip3 install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Statistical functions\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# For concurrency (running functions in parallel)\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# For caching (to speed up repeated function calls)\n",
    "from functools import lru_cache\n",
    "\n",
    "# For progress tracking\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Text Preprocessing and NLP\n",
    "import nltk\n",
    "# Stopwords (common words to ignore) from NLTK\n",
    "from nltk.corpus import stopwords\n",
    "# Tokenizing sentences/words\n",
    "from nltk.tokenize import word_tokenize\n",
    "# Part-of-speech tagging\n",
    "from nltk import pos_tag\n",
    "# Lemmatization (converting words to their base form)\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation (Loading CSV)\n",
    "\n",
    "Load the processed_data `csv` file into pandas DataFrames\n",
    "- `processed_data.csv` is loaded into `data` DataFrame (stemming has been performed to reduce processing time.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./processed_data_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    34030\n",
       "1    26461\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60491 entries, 0 to 60490\n",
      "Data columns (total 4 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   label                   60491 non-null  int64 \n",
      " 1   full_content            60491 non-null  object\n",
      " 2   processed_full_content  60491 non-null  object\n",
      " 3   word_count              60491 non-null  int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 1.8+ MB\n",
      "Dataframe Shape: (60491, 4)\n"
     ]
    }
   ],
   "source": [
    "data.info()\n",
    "print(\"Dataframe Shape:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ensure required NLTK data is downloaded\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Convolutional Neural Network (Tokenizer + Embedding Layer) + 5 Fold Cross-Validation + L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training fold 1...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inflaton/anaconda3/envs/fake-news/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - accuracy: 0.8405 - loss: 0.7487 - val_accuracy: 0.9555 - val_loss: 0.2279\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.9619 - loss: 0.2136 - val_accuracy: 0.9564 - val_loss: 0.2090\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.9740 - loss: 0.1784 - val_accuracy: 0.9579 - val_loss: 0.2013\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 22ms/step - accuracy: 0.9815 - loss: 0.1587 - val_accuracy: 0.9559 - val_loss: 0.1995\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.9851 - loss: 0.1452 - val_accuracy: 0.9553 - val_loss: 0.1979\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.9881 - loss: 0.1352 - val_accuracy: 0.9582 - val_loss: 0.1904\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.9905 - loss: 0.1260 - val_accuracy: 0.9595 - val_loss: 0.1837\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9923 - loss: 0.1197 - val_accuracy: 0.9616 - val_loss: 0.1756\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 26ms/step - accuracy: 0.9934 - loss: 0.1134 - val_accuracy: 0.9608 - val_loss: 0.1762\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 29ms/step - accuracy: 0.9945 - loss: 0.1082 - val_accuracy: 0.9638 - val_loss: 0.1678\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
      "Fold 1 - Accuracy: 0.9638, Precision: 0.9444, Recall: 0.9747, F1 Score: 0.9593\n",
      "\n",
      "Training fold 2...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inflaton/anaconda3/envs/fake-news/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.8293 - loss: 0.7502 - val_accuracy: 0.9604 - val_loss: 0.2178\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 33ms/step - accuracy: 0.9596 - loss: 0.2150 - val_accuracy: 0.9651 - val_loss: 0.1953\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 37ms/step - accuracy: 0.9717 - loss: 0.1823 - val_accuracy: 0.9655 - val_loss: 0.1859\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 44ms/step - accuracy: 0.9788 - loss: 0.1643 - val_accuracy: 0.9675 - val_loss: 0.1776\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 42ms/step - accuracy: 0.9834 - loss: 0.1498 - val_accuracy: 0.9669 - val_loss: 0.1737\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 39ms/step - accuracy: 0.9866 - loss: 0.1391 - val_accuracy: 0.9680 - val_loss: 0.1694\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 36ms/step - accuracy: 0.9893 - loss: 0.1303 - val_accuracy: 0.9682 - val_loss: 0.1669\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 35ms/step - accuracy: 0.9911 - loss: 0.1230 - val_accuracy: 0.9688 - val_loss: 0.1636\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 33ms/step - accuracy: 0.9920 - loss: 0.1176 - val_accuracy: 0.9691 - val_loss: 0.1617\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 33ms/step - accuracy: 0.9936 - loss: 0.1115 - val_accuracy: 0.9688 - val_loss: 0.1601\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "Fold 2 - Accuracy: 0.9688, Precision: 0.9707, Recall: 0.9575, F1 Score: 0.9640\n",
      "\n",
      "Training fold 3...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inflaton/anaconda3/envs/fake-news/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 31ms/step - accuracy: 0.8344 - loss: 0.7535 - val_accuracy: 0.9536 - val_loss: 0.2321\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 31ms/step - accuracy: 0.9616 - loss: 0.2109 - val_accuracy: 0.9612 - val_loss: 0.2077\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 31ms/step - accuracy: 0.9742 - loss: 0.1778 - val_accuracy: 0.9635 - val_loss: 0.1938\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 30ms/step - accuracy: 0.9813 - loss: 0.1578 - val_accuracy: 0.9666 - val_loss: 0.1812\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 30ms/step - accuracy: 0.9865 - loss: 0.1427 - val_accuracy: 0.9643 - val_loss: 0.1814\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 29ms/step - accuracy: 0.9898 - loss: 0.1316 - val_accuracy: 0.9632 - val_loss: 0.1795\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 30ms/step - accuracy: 0.9919 - loss: 0.1229 - val_accuracy: 0.9627 - val_loss: 0.1744\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 29ms/step - accuracy: 0.9940 - loss: 0.1157 - val_accuracy: 0.9627 - val_loss: 0.1727\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 29ms/step - accuracy: 0.9945 - loss: 0.1101 - val_accuracy: 0.9634 - val_loss: 0.1696\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.9956 - loss: 0.1051 - val_accuracy: 0.9628 - val_loss: 0.1662\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
      "Fold 3 - Accuracy: 0.9628, Precision: 0.9741, Recall: 0.9399, F1 Score: 0.9567\n",
      "\n",
      "Training fold 4...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inflaton/anaconda3/envs/fake-news/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.8359 - loss: 0.7566 - val_accuracy: 0.9611 - val_loss: 0.2232\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 27ms/step - accuracy: 0.9642 - loss: 0.2113 - val_accuracy: 0.9649 - val_loss: 0.2007\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 27ms/step - accuracy: 0.9750 - loss: 0.1776 - val_accuracy: 0.9661 - val_loss: 0.1885\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 29ms/step - accuracy: 0.9821 - loss: 0.1565 - val_accuracy: 0.9678 - val_loss: 0.1822\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.9857 - loss: 0.1422 - val_accuracy: 0.9677 - val_loss: 0.1777\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.9888 - loss: 0.1319 - val_accuracy: 0.9677 - val_loss: 0.1736\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.9909 - loss: 0.1240 - val_accuracy: 0.9675 - val_loss: 0.1704\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.9924 - loss: 0.1170 - val_accuracy: 0.9679 - val_loss: 0.1682\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.9938 - loss: 0.1110 - val_accuracy: 0.9674 - val_loss: 0.1672\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.9946 - loss: 0.1056 - val_accuracy: 0.9680 - val_loss: 0.1644\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "Fold 4 - Accuracy: 0.9680, Precision: 0.9585, Recall: 0.9688, F1 Score: 0.9636\n",
      "\n",
      "Training fold 5...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inflaton/anaconda3/envs/fake-news/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 29ms/step - accuracy: 0.8436 - loss: 0.7631 - val_accuracy: 0.9564 - val_loss: 0.2260\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 28ms/step - accuracy: 0.9621 - loss: 0.2155 - val_accuracy: 0.9629 - val_loss: 0.1993\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 29ms/step - accuracy: 0.9735 - loss: 0.1794 - val_accuracy: 0.9609 - val_loss: 0.1946\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 29ms/step - accuracy: 0.9803 - loss: 0.1601 - val_accuracy: 0.9621 - val_loss: 0.1841\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 30ms/step - accuracy: 0.9847 - loss: 0.1460 - val_accuracy: 0.9630 - val_loss: 0.1788\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 30ms/step - accuracy: 0.9878 - loss: 0.1352 - val_accuracy: 0.9658 - val_loss: 0.1711\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 29ms/step - accuracy: 0.9900 - loss: 0.1267 - val_accuracy: 0.9640 - val_loss: 0.1705\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 30ms/step - accuracy: 0.9910 - loss: 0.1194 - val_accuracy: 0.9650 - val_loss: 0.1661\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 30ms/step - accuracy: 0.9928 - loss: 0.1132 - val_accuracy: 0.9666 - val_loss: 0.1623\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 30ms/step - accuracy: 0.9938 - loss: 0.1082 - val_accuracy: 0.9669 - val_loss: 0.1594\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "Fold 5 - Accuracy: 0.9669, Precision: 0.9731, Recall: 0.9505, F1 Score: 0.9617\n",
      "\n",
      "Average Evaluation Metrics across 5 folds:\n",
      "Average Accuracy: 0.9660\n",
      "Average Precision: 0.9642\n",
      "Average Recall: 0.9583\n",
      "Average F1 Score: 0.9611\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "# Tokenization and Padding Parameters\n",
    "max_words = 10000  # Max vocabulary size\n",
    "max_sequence_length = 300  # Max length of sequences\n",
    "\n",
    "# Tokenize and Pad Sequences\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(data['processed_full_content'])\n",
    "sequences = tokenizer.texts_to_sequences(data['processed_full_content'])\n",
    "X = pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "y = data['label'].values  # Target labels\n",
    "\n",
    "# Define the CNN Model with L2 Regularization\n",
    "def create_basic_cnn():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_sequence_length))\n",
    "    model.add(Conv1D(filters=128, kernel_size=5, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.2))  # Add dropout for regularization\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.01)))  # Binary classification\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 5-Fold Cross-Validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold = 1\n",
    "all_fold_metrics = {'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
    "\n",
    "for train_index, val_index in kf.split(X, y):\n",
    "    print(f\"\\nTraining fold {fold}...\")\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "    \n",
    "    model = create_basic_cnn()\n",
    "    history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_val, y_val), verbose=1)\n",
    "    \n",
    "    # Predict and evaluate\n",
    "    y_pred = (model.predict(X_val) > 0.5).astype(int)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_val, y_pred, average='binary')\n",
    "    \n",
    "    # Store metrics for this fold\n",
    "    all_fold_metrics['accuracy'].append(accuracy)\n",
    "    all_fold_metrics['precision'].append(precision)\n",
    "    all_fold_metrics['recall'].append(recall)\n",
    "    all_fold_metrics['f1'].append(f1)\n",
    "    \n",
    "    print(f\"Fold {fold} - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "    fold += 1\n",
    "\n",
    "# Calculate and print average metrics across all folds\n",
    "avg_accuracy = np.mean(all_fold_metrics['accuracy'])\n",
    "avg_precision = np.mean(all_fold_metrics['precision'])\n",
    "avg_recall = np.mean(all_fold_metrics['recall'])\n",
    "avg_f1 = np.mean(all_fold_metrics['f1'])\n",
    "\n",
    "print(\"\\nAverage Evaluation Metrics across 5 folds:\")\n",
    "print(f\"Average Accuracy: {avg_accuracy:.4f}\")\n",
    "print(f\"Average Precision: {avg_precision:.4f}\")\n",
    "print(f\"Average Recall: {avg_recall:.4f}\")\n",
    "print(f\"Average F1 Score: {avg_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network + TF-IDF Vectorizer\n",
    "\n",
    "Using TF-IDF vectorizer along with CNN led to a drastic fall in performance. Below are some reasons why we should not use TF-IDF vectorizer along with a CNN or other neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lack of Spatial Structure:\n",
    "\n",
    "TF-IDF vectors are sparse and non-sequential representations where each position in the vector represents a word, not a spatial pattern.\n",
    "CNNs are designed to detect patterns in sequential or spatially structured data (e.g., images or sentences), so they might struggle to find meaningful patterns in TF-IDF vectors.\n",
    "\n",
    "#### High-Dimensional Sparse Data:\n",
    "\n",
    "TF-IDF vectors, especially with a high max_features value (like 10,000), result in a high-dimensional but sparse input.\n",
    "CNNs are generally not well-suited for such high-dimensional sparse data; they perform better with dense embeddings where words have contextually meaningful dimensions.\n",
    "\n",
    "#### Mismatch Between Input Type and CNN Architecture:\n",
    "\n",
    "CNNs are typically effective when applied to word embeddings (like GloVe or Word2Vec) because embeddings maintain semantic relationships and neighborhood structures.\n",
    "TF-IDF, however, does not capture word order or semantic relationships, which means the convolution operation might not yield meaningful feature maps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 97ms/step - accuracy: 0.5619 - loss: 0.6843 - val_accuracy: 0.5679 - val_loss: 0.6789\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 97ms/step - accuracy: 0.5699 - loss: 0.6806 - val_accuracy: 0.5834 - val_loss: 0.6755\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 94ms/step - accuracy: 0.5749 - loss: 0.6774 - val_accuracy: 0.5825 - val_loss: 0.6727\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 92ms/step - accuracy: 0.5747 - loss: 0.6764 - val_accuracy: 0.5837 - val_loss: 0.6717\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 91ms/step - accuracy: 0.5759 - loss: 0.6756 - val_accuracy: 0.5817 - val_loss: 0.6713\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 92ms/step - accuracy: 0.5750 - loss: 0.6753 - val_accuracy: 0.5810 - val_loss: 0.6712\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 94ms/step - accuracy: 0.5757 - loss: 0.6750 - val_accuracy: 0.5817 - val_loss: 0.6705\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 95ms/step - accuracy: 0.5753 - loss: 0.6746 - val_accuracy: 0.5818 - val_loss: 0.6706\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 98ms/step - accuracy: 0.5760 - loss: 0.6750 - val_accuracy: 0.5815 - val_loss: 0.6712\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 100ms/step - accuracy: 0.5765 - loss: 0.6743 - val_accuracy: 0.5841 - val_loss: 0.6704\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step\n",
      "\n",
      "Evaluation Metrics:\n",
      "Accuracy: 0.5841\n",
      "Precision: 0.5492\n",
      "Recall: 0.2166\n",
      "F1 Score: 0.3107\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, Dense, Dropout, Reshape, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Step 1: Apply TF-IDF Vectorization\n",
    "max_features = 10000  # Limit TF-IDF to top 10,000 features\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=max_features)\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(data['processed_full_content']).toarray()\n",
    "\n",
    "# Convert the labels\n",
    "y = data['label'].values  # Target labels\n",
    "\n",
    "# Step 2: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Define the CNN Model for TF-IDF Input\n",
    "def create_cnn_with_tfidf():\n",
    "    inputs = Input(shape=(max_features,))\n",
    "    x = Reshape((max_features, 1))(inputs)  # Reshape TF-IDF output to be compatible with Conv1D\n",
    "\n",
    "    # Convolutional layer\n",
    "    x = Conv1D(filters=128, kernel_size=5, activation='relu')(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    \n",
    "    # Fully connected layer\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)  # Dropout for regularization\n",
    "    outputs = Dense(1, activation='sigmoid')(x)  # Output layer for binary classification\n",
    "\n",
    "    # Create model\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Step 4: Train the Model\n",
    "model = create_cnn_with_tfidf()\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "# Step 5: Evaluate the Model\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
    "\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Networks + Count Vectorization (conversion to sequences) + Stratified 5-Fold CV + L2 Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 53ms/step - accuracy: 0.7806 - loss: 0.8735 - val_accuracy: 0.9351 - val_loss: 0.2590\n",
      "Epoch 2/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9343 - loss: 0.2636 - val_accuracy: 0.9462 - val_loss: 0.2264\n",
      "Epoch 3/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9468 - loss: 0.2325 - val_accuracy: 0.9520 - val_loss: 0.2136\n",
      "Epoch 4/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 28ms/step - accuracy: 0.9561 - loss: 0.2111 - val_accuracy: 0.9552 - val_loss: 0.2078\n",
      "Epoch 5/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 30ms/step - accuracy: 0.9635 - loss: 0.1976 - val_accuracy: 0.9542 - val_loss: 0.2055\n",
      "Epoch 6/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 30ms/step - accuracy: 0.9704 - loss: 0.1836 - val_accuracy: 0.9558 - val_loss: 0.2053\n",
      "Epoch 7/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 31ms/step - accuracy: 0.9752 - loss: 0.1733 - val_accuracy: 0.9555 - val_loss: 0.2054\n",
      "Epoch 8/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 32ms/step - accuracy: 0.9794 - loss: 0.1636 - val_accuracy: 0.9563 - val_loss: 0.2033\n",
      "Epoch 9/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 31ms/step - accuracy: 0.9829 - loss: 0.1557 - val_accuracy: 0.9568 - val_loss: 0.2024\n",
      "Epoch 10/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 30ms/step - accuracy: 0.9849 - loss: 0.1487 - val_accuracy: 0.9557 - val_loss: 0.2003\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 30ms/step - accuracy: 0.7800 - loss: 0.8662 - val_accuracy: 0.9376 - val_loss: 0.2429\n",
      "Epoch 2/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 29ms/step - accuracy: 0.9364 - loss: 0.2600 - val_accuracy: 0.9478 - val_loss: 0.2267\n",
      "Epoch 3/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9451 - loss: 0.2315 - val_accuracy: 0.9508 - val_loss: 0.2180\n",
      "Epoch 4/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9544 - loss: 0.2150 - val_accuracy: 0.9520 - val_loss: 0.2156\n",
      "Epoch 5/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9622 - loss: 0.1994 - val_accuracy: 0.9527 - val_loss: 0.2130\n",
      "Epoch 6/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 29ms/step - accuracy: 0.9683 - loss: 0.1856 - val_accuracy: 0.9507 - val_loss: 0.2175\n",
      "Epoch 7/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9738 - loss: 0.1739 - val_accuracy: 0.9513 - val_loss: 0.2147\n",
      "Epoch 8/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 29ms/step - accuracy: 0.9777 - loss: 0.1657 - val_accuracy: 0.9525 - val_loss: 0.2164\n",
      "Epoch 9/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 29ms/step - accuracy: 0.9819 - loss: 0.1574 - val_accuracy: 0.9522 - val_loss: 0.2139\n",
      "Epoch 10/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 29ms/step - accuracy: 0.9837 - loss: 0.1505 - val_accuracy: 0.9539 - val_loss: 0.2098\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 30ms/step - accuracy: 0.7648 - loss: 0.8915 - val_accuracy: 0.9279 - val_loss: 0.2711\n",
      "Epoch 2/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 31ms/step - accuracy: 0.9205 - loss: 0.2859 - val_accuracy: 0.9417 - val_loss: 0.2393\n",
      "Epoch 3/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 30ms/step - accuracy: 0.9398 - loss: 0.2490 - val_accuracy: 0.9450 - val_loss: 0.2300\n",
      "Epoch 4/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 30ms/step - accuracy: 0.9536 - loss: 0.2238 - val_accuracy: 0.9532 - val_loss: 0.2153\n",
      "Epoch 5/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 31ms/step - accuracy: 0.9631 - loss: 0.2009 - val_accuracy: 0.9541 - val_loss: 0.2158\n",
      "Epoch 6/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 31ms/step - accuracy: 0.9699 - loss: 0.1862 - val_accuracy: 0.9542 - val_loss: 0.2141\n",
      "Epoch 7/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 31ms/step - accuracy: 0.9756 - loss: 0.1739 - val_accuracy: 0.9563 - val_loss: 0.2074\n",
      "Epoch 8/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 31ms/step - accuracy: 0.9793 - loss: 0.1633 - val_accuracy: 0.9574 - val_loss: 0.2037\n",
      "Epoch 9/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 31ms/step - accuracy: 0.9822 - loss: 0.1560 - val_accuracy: 0.9565 - val_loss: 0.2027\n",
      "Epoch 10/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 31ms/step - accuracy: 0.9859 - loss: 0.1468 - val_accuracy: 0.9545 - val_loss: 0.2081\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 30ms/step - accuracy: 0.7806 - loss: 0.8789 - val_accuracy: 0.9021 - val_loss: 0.3043\n",
      "Epoch 2/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 29ms/step - accuracy: 0.9259 - loss: 0.2765 - val_accuracy: 0.9337 - val_loss: 0.2452\n",
      "Epoch 3/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 29ms/step - accuracy: 0.9461 - loss: 0.2293 - val_accuracy: 0.9372 - val_loss: 0.2396\n",
      "Epoch 4/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 30ms/step - accuracy: 0.9564 - loss: 0.2092 - val_accuracy: 0.9413 - val_loss: 0.2343\n",
      "Epoch 5/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9650 - loss: 0.1934 - val_accuracy: 0.9410 - val_loss: 0.2374\n",
      "Epoch 6/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 29ms/step - accuracy: 0.9705 - loss: 0.1819 - val_accuracy: 0.9476 - val_loss: 0.2278\n",
      "Epoch 7/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 29ms/step - accuracy: 0.9762 - loss: 0.1696 - val_accuracy: 0.9497 - val_loss: 0.2250\n",
      "Epoch 8/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 29ms/step - accuracy: 0.9807 - loss: 0.1607 - val_accuracy: 0.9513 - val_loss: 0.2214\n",
      "Epoch 9/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 30ms/step - accuracy: 0.9837 - loss: 0.1527 - val_accuracy: 0.9507 - val_loss: 0.2211\n",
      "Epoch 10/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 30ms/step - accuracy: 0.9866 - loss: 0.1450 - val_accuracy: 0.9498 - val_loss: 0.2262\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
      "Epoch 1/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 30ms/step - accuracy: 0.7816 - loss: 0.8918 - val_accuracy: 0.9313 - val_loss: 0.2708\n",
      "Epoch 2/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - accuracy: 0.9259 - loss: 0.2819 - val_accuracy: 0.9406 - val_loss: 0.2439\n",
      "Epoch 3/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - accuracy: 0.9421 - loss: 0.2467 - val_accuracy: 0.9448 - val_loss: 0.2333\n",
      "Epoch 4/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 440ms/step - accuracy: 0.9534 - loss: 0.2238 - val_accuracy: 0.9482 - val_loss: 0.2303\n",
      "Epoch 5/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 33ms/step - accuracy: 0.9638 - loss: 0.2050 - val_accuracy: 0.9460 - val_loss: 0.2337\n",
      "Epoch 6/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 23ms/step - accuracy: 0.9716 - loss: 0.1892 - val_accuracy: 0.9452 - val_loss: 0.2339\n",
      "Epoch 7/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 24ms/step - accuracy: 0.9782 - loss: 0.1760 - val_accuracy: 0.9451 - val_loss: 0.2352\n",
      "Epoch 8/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 31ms/step - accuracy: 0.9815 - loss: 0.1646 - val_accuracy: 0.9446 - val_loss: 0.2347\n",
      "Epoch 9/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 28ms/step - accuracy: 0.9850 - loss: 0.1569 - val_accuracy: 0.9448 - val_loss: 0.2332\n",
      "Epoch 10/10\n",
      "\u001b[1m605/605\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - accuracy: 0.9866 - loss: 0.1496 - val_accuracy: 0.9445 - val_loss: 0.2344\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "\n",
      "Cross-Validation Metrics:\n",
      "Average Accuracy: 0.9492\n",
      "Average Precision: 0.9329\n",
      "Average Recall: 0.9526\n",
      "Average F1 Score: 0.9426\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Step 1: Text Vectorization using CountVectorizer\n",
    "max_features = 10000  # Max vocabulary size for CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=max_features)\n",
    "X_counts = vectorizer.fit_transform(data['processed_full_content'])\n",
    "word_index = vectorizer.vocabulary_\n",
    "\n",
    "# Convert CountVectorizer output to sequences\n",
    "index_to_word = {i: word for word, i in word_index.items()}\n",
    "\n",
    "def counts_to_sequences(X_counts):\n",
    "    sequences = []\n",
    "    for i in range(X_counts.shape[0]):\n",
    "        indices = X_counts[i].nonzero()[1]\n",
    "        words = [index_to_word[idx] for idx in indices]\n",
    "        seq = [word_index[word] + 1 for word in words]  # +1 because 0 is reserved for padding\n",
    "        sequences.append(seq)\n",
    "    return sequences\n",
    "\n",
    "sequences = counts_to_sequences(X_counts)\n",
    "max_sequence_length = 300  # Adjust to your needs\n",
    "X = pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "y = data['label'].values  # Target labels\n",
    "\n",
    "# Define the Basic CNN Model with L2 Regularization\n",
    "def create_basic_cnn_with_l2():\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Embedding layer with random initialization\n",
    "    model.add(Embedding(input_dim=max_features + 1, output_dim=128))\n",
    "    \n",
    "    # Convolutional layer with L2 regularization\n",
    "    model.add(Conv1D(filters=128, kernel_size=5, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    \n",
    "    # Fully connected layer with L2 regularization\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "    model.add(Dropout(0.5))  # Add dropout for regularization\n",
    "    \n",
    "    # Output layer with L2 regularization\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.01)))  # Binary classification\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Step 4: Stratified 5-Fold Cross-Validation\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracy_scores = []\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    model = create_basic_cnn_with_l2()\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2, verbose=1)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
    "    \n",
    "    accuracy_scores.append(accuracy)\n",
    "    precision_scores.append(precision)\n",
    "    recall_scores.append(recall)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "# Step 5: Print Cross-Validation Results\n",
    "print(\"\\nCross-Validation Metrics:\")\n",
    "print(f\"Average Accuracy: {np.mean(accuracy_scores):.4f}\")\n",
    "print(f\"Average Precision: {np.mean(precision_scores):.4f}\")\n",
    "print(f\"Average Recall: {np.mean(recall_scores):.4f}\")\n",
    "print(f\"Average F1 Score: {np.mean(f1_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network + Custom-trained Word2Vec Embeddings + 5-Fold Cross Validation + L2 Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why do we use word embedding over other preprocessing techniques (eg. tf-idf, count vectorizer), for our task of fake news classification?\n",
    "\n",
    "\n",
    "##### 1. Word embeddings capture the semantic relationships between words in a dense, low-dimensional space.\n",
    "Fake news often uses subtle language, and word embeddings like GloVe can capture the semantic context of words, allowing the model to understand relationships between words that simple vectorizers would miss. This helps in detecting nuanced differences in language use between real and fake news.\n",
    "\n",
    "##### 2. Word embeddings produce dense, low-dimensional vectors (e.g., 100-300 dimensions) that capture rich word information.\n",
    "Pre-trained embeddings are built on large corpora like Wikipedia and news articles, giving our model external knowledge that’s useful for distinguishing between real news and fake news. This boosts the model's ability to generalize on unseen test data from our web scraping.\n",
    "\n",
    "##### 3. Efficient Representation of Semantics\n",
    "Words in fake news can appear in different contexts, but with similar underlying meanings (e.g., \"hoax\" and \"lie\"). GloVe embeddings represent these similar words in close proximity in the vector space, helping the model recognize fake news patterns more effectively than TF-IDF or Count Vectorizer.\n",
    "\n",
    "##### 4. Handling Synonyms and Rare Words:\n",
    "Fake news often uses alternative phrases or rare terminology. Pre-trained embeddings like GloVe can handle these rare words because they’ve seen a broad variety of language during training, making our model more robust against unusual vocabulary choices in fake news."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation \n",
    "We use Stratified K-Fold Cross-Validation with n_splits=5 to evaluate the model on different splits of the data. \n",
    "For each fold, we store the metrics (accuracy, precision, recall, and F1 score) and then calculate the average metrics across all folds for a robust evaluation.\n",
    "\n",
    "Cross-validation helps us understand the model’s performance more robustly by testing it on multiple splits of the data. This approach gives a more reliable estimate of model performance and helps reduce the risk of overfitting to any single train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 66ms/step - accuracy: 0.7846 - loss: 2.1489 - val_accuracy: 0.9476 - val_loss: 0.7870\n",
      "Epoch 2/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m980s\u001b[0m 5s/step - accuracy: 0.9481 - loss: 0.6881 - val_accuracy: 0.9602 - val_loss: 0.4520\n",
      "Epoch 3/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 65ms/step - accuracy: 0.9618 - loss: 0.4245 - val_accuracy: 0.9567 - val_loss: 0.3471\n",
      "Epoch 4/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 66ms/step - accuracy: 0.9679 - loss: 0.3096 - val_accuracy: 0.9634 - val_loss: 0.2663\n",
      "Epoch 5/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1009s\u001b[0m 5s/step - accuracy: 0.9717 - loss: 0.2421 - val_accuracy: 0.9578 - val_loss: 0.2367\n",
      "Epoch 6/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 66ms/step - accuracy: 0.9729 - loss: 0.2061 - val_accuracy: 0.9624 - val_loss: 0.2044\n",
      "Epoch 7/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 65ms/step - accuracy: 0.9749 - loss: 0.1792 - val_accuracy: 0.9683 - val_loss: 0.1791\n",
      "Epoch 8/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 66ms/step - accuracy: 0.9786 - loss: 0.1617 - val_accuracy: 0.9683 - val_loss: 0.1713\n",
      "Epoch 9/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m884s\u001b[0m 5s/step - accuracy: 0.9800 - loss: 0.1519 - val_accuracy: 0.9656 - val_loss: 0.1704\n",
      "Epoch 10/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 65ms/step - accuracy: 0.9797 - loss: 0.1468 - val_accuracy: 0.9661 - val_loss: 0.1665\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\n",
      "Fold 1 Results:\n",
      "Accuracy: 0.9661\n",
      "Precision: 0.9383\n",
      "Recall: 0.9875\n",
      "F1 Score: 0.9623\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 67ms/step - accuracy: 0.8080 - loss: 1.9747 - val_accuracy: 0.9518 - val_loss: 0.6186\n",
      "Epoch 2/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 67ms/step - accuracy: 0.9517 - loss: 0.5426 - val_accuracy: 0.9692 - val_loss: 0.3359\n",
      "Epoch 3/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m268s\u001b[0m 1s/step - accuracy: 0.9668 - loss: 0.3172 - val_accuracy: 0.9716 - val_loss: 0.2437\n",
      "Epoch 4/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 66ms/step - accuracy: 0.9725 - loss: 0.2362 - val_accuracy: 0.9743 - val_loss: 0.2006\n",
      "Epoch 5/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 66ms/step - accuracy: 0.9753 - loss: 0.1946 - val_accuracy: 0.9730 - val_loss: 0.1799\n",
      "Epoch 6/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 66ms/step - accuracy: 0.9772 - loss: 0.1721 - val_accuracy: 0.9769 - val_loss: 0.1624\n",
      "Epoch 7/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 67ms/step - accuracy: 0.9789 - loss: 0.1587 - val_accuracy: 0.9755 - val_loss: 0.1556\n",
      "Epoch 8/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 68ms/step - accuracy: 0.9811 - loss: 0.1469 - val_accuracy: 0.9793 - val_loss: 0.1486\n",
      "Epoch 9/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 70ms/step - accuracy: 0.9821 - loss: 0.1403 - val_accuracy: 0.9779 - val_loss: 0.1464\n",
      "Epoch 10/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 71ms/step - accuracy: 0.9829 - loss: 0.1365 - val_accuracy: 0.9780 - val_loss: 0.1432\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\n",
      "Fold 2 Results:\n",
      "Accuracy: 0.9780\n",
      "Precision: 0.9736\n",
      "Recall: 0.9762\n",
      "F1 Score: 0.9749\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 66ms/step - accuracy: 0.7893 - loss: 2.1697 - val_accuracy: 0.9511 - val_loss: 0.7090\n",
      "Epoch 2/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 66ms/step - accuracy: 0.9503 - loss: 0.6200 - val_accuracy: 0.9608 - val_loss: 0.3844\n",
      "Epoch 3/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 67ms/step - accuracy: 0.9636 - loss: 0.3559 - val_accuracy: 0.9675 - val_loss: 0.2669\n",
      "Epoch 4/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 66ms/step - accuracy: 0.9699 - loss: 0.2580 - val_accuracy: 0.9695 - val_loss: 0.2159\n",
      "Epoch 5/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 68ms/step - accuracy: 0.9735 - loss: 0.2094 - val_accuracy: 0.9714 - val_loss: 0.1885\n",
      "Epoch 6/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 67ms/step - accuracy: 0.9753 - loss: 0.1803 - val_accuracy: 0.9709 - val_loss: 0.1720\n",
      "Epoch 7/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 68ms/step - accuracy: 0.9772 - loss: 0.1659 - val_accuracy: 0.9718 - val_loss: 0.1638\n",
      "Epoch 8/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 67ms/step - accuracy: 0.9778 - loss: 0.1555 - val_accuracy: 0.9734 - val_loss: 0.1567\n",
      "Epoch 9/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 69ms/step - accuracy: 0.9802 - loss: 0.1480 - val_accuracy: 0.9731 - val_loss: 0.1535\n",
      "Epoch 10/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 71ms/step - accuracy: 0.9810 - loss: 0.1405 - val_accuracy: 0.9712 - val_loss: 0.1557\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\n",
      "Fold 3 Results:\n",
      "Accuracy: 0.9712\n",
      "Precision: 0.9566\n",
      "Recall: 0.9786\n",
      "F1 Score: 0.9675\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 78ms/step - accuracy: 0.8047 - loss: 2.0892 - val_accuracy: 0.9569 - val_loss: 0.7288\n",
      "Epoch 2/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 0.9531 - loss: 0.6373 - val_accuracy: 0.9648 - val_loss: 0.4079\n",
      "Epoch 3/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 84ms/step - accuracy: 0.9661 - loss: 0.3808 - val_accuracy: 0.9702 - val_loss: 0.2935\n",
      "Epoch 4/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 87ms/step - accuracy: 0.9705 - loss: 0.2812 - val_accuracy: 0.9726 - val_loss: 0.2316\n",
      "Epoch 5/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 86ms/step - accuracy: 0.9746 - loss: 0.2201 - val_accuracy: 0.9708 - val_loss: 0.2017\n",
      "Epoch 6/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 88ms/step - accuracy: 0.9769 - loss: 0.1887 - val_accuracy: 0.9737 - val_loss: 0.1776\n",
      "Epoch 7/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 89ms/step - accuracy: 0.9795 - loss: 0.1659 - val_accuracy: 0.9731 - val_loss: 0.1665\n",
      "Epoch 8/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 90ms/step - accuracy: 0.9791 - loss: 0.1542 - val_accuracy: 0.9717 - val_loss: 0.1614\n",
      "Epoch 9/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 89ms/step - accuracy: 0.9813 - loss: 0.1453 - val_accuracy: 0.9717 - val_loss: 0.1577\n",
      "Epoch 10/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 87ms/step - accuracy: 0.9833 - loss: 0.1390 - val_accuracy: 0.9726 - val_loss: 0.1537\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
      "\n",
      "Fold 4 Results:\n",
      "Accuracy: 0.9726\n",
      "Precision: 0.9751\n",
      "Recall: 0.9620\n",
      "F1 Score: 0.9685\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 85ms/step - accuracy: 0.7929 - loss: 2.2603 - val_accuracy: 0.9482 - val_loss: 0.8301\n",
      "Epoch 2/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 83ms/step - accuracy: 0.9488 - loss: 0.7190 - val_accuracy: 0.9626 - val_loss: 0.4521\n",
      "Epoch 3/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 82ms/step - accuracy: 0.9633 - loss: 0.4252 - val_accuracy: 0.9683 - val_loss: 0.3219\n",
      "Epoch 4/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 81ms/step - accuracy: 0.9689 - loss: 0.3122 - val_accuracy: 0.9713 - val_loss: 0.2558\n",
      "Epoch 5/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 80ms/step - accuracy: 0.9715 - loss: 0.2489 - val_accuracy: 0.9726 - val_loss: 0.2142\n",
      "Epoch 6/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 79ms/step - accuracy: 0.9748 - loss: 0.2076 - val_accuracy: 0.9731 - val_loss: 0.1882\n",
      "Epoch 7/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 80ms/step - accuracy: 0.9759 - loss: 0.1827 - val_accuracy: 0.9717 - val_loss: 0.1774\n",
      "Epoch 8/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 80ms/step - accuracy: 0.9780 - loss: 0.1662 - val_accuracy: 0.9743 - val_loss: 0.1639\n",
      "Epoch 9/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 79ms/step - accuracy: 0.9785 - loss: 0.1563 - val_accuracy: 0.9745 - val_loss: 0.1565\n",
      "Epoch 10/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 79ms/step - accuracy: 0.9807 - loss: 0.1481 - val_accuracy: 0.9735 - val_loss: 0.1544\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "\n",
      "Fold 5 Results:\n",
      "Accuracy: 0.9735\n",
      "Precision: 0.9801\n",
      "Recall: 0.9588\n",
      "F1 Score: 0.9693\n",
      "\n",
      "Average Metrics Across All Folds:\n",
      "Average Accuracy: 0.9723\n",
      "Average Precision: 0.9647\n",
      "Average Recall: 0.9726\n",
      "Average F1 Score: 0.9685\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, Input\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from gensim.models import Word2Vec\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import random\n",
    "\n",
    "# Set seeds\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Parameters\n",
    "max_words = 5000\n",
    "max_sequence_length = 300\n",
    "embedding_dim = 100\n",
    "\n",
    "def create_embedding_matrix(word2vec_model, tokenizer, vocab_size, embedding_dim):\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "    for word, i in tokenizer.word_index.items():\n",
    "        if i < vocab_size:\n",
    "            if word in word2vec_model.wv:\n",
    "                embedding_matrix[i] = word2vec_model.wv[word]\n",
    "            else:\n",
    "                embedding_matrix[i] = np.random.normal(size=(embedding_dim,))\n",
    "    return embedding_matrix\n",
    "\n",
    "def create_cnn_with_l2(vocab_size, embedding_dim, embedding_matrix):\n",
    "    input_layer = Input(shape=(max_sequence_length,))\n",
    "    embedding_layer = Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        weights=[embedding_matrix],\n",
    "        trainable=True\n",
    "    )(input_layer)\n",
    "    \n",
    "    x = Conv1D(filters=128, kernel_size=5, activation='relu', kernel_regularizer=l2(0.01))(embedding_layer)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    x = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    output_layer = Dense(1, activation='sigmoid', kernel_regularizer=l2(0.01))(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Implement cross-validation\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold_metrics = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kfold.split(data['processed_full_content'], data['label']), 1):\n",
    "    print(f\"\\nFold {fold}\")\n",
    "    \n",
    "    # Split data\n",
    "    train_texts = data['processed_full_content'].iloc[train_idx]\n",
    "    val_texts = data['processed_full_content'].iloc[val_idx]\n",
    "    train_labels = data['label'].iloc[train_idx]\n",
    "    val_labels = data['label'].iloc[val_idx]\n",
    "    \n",
    "    # Tokenization\n",
    "    tokenizer = Tokenizer(num_words=max_words)\n",
    "    tokenizer.fit_on_texts(train_texts)\n",
    "    \n",
    "    # Create sequences\n",
    "    X_train = pad_sequences(tokenizer.texts_to_sequences(train_texts), maxlen=max_sequence_length)\n",
    "    X_val = pad_sequences(tokenizer.texts_to_sequences(val_texts), maxlen=max_sequence_length)\n",
    "    \n",
    "    # Train Word2Vec on training data only\n",
    "    train_sentences = [text.split() for text in train_texts]\n",
    "    word2vec_model = Word2Vec(train_sentences, vector_size=embedding_dim, window=5, min_count=2, workers=4)\n",
    "    \n",
    "    # Create embedding matrix\n",
    "    vocab_size = min(max_words, len(tokenizer.word_index) + 1)\n",
    "    embedding_matrix = create_embedding_matrix(word2vec_model, tokenizer, vocab_size, embedding_dim)\n",
    "    \n",
    "    # Create and train model\n",
    "    model = create_cnn_with_l2(vocab_size, embedding_dim, embedding_matrix)\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train, train_labels,\n",
    "        epochs=10,\n",
    "        batch_size=256,\n",
    "        validation_data=(X_val, val_labels),\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = (model.predict(X_val) > 0.5).astype(int)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(val_labels, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(val_labels, y_pred, average='binary')\n",
    "    \n",
    "    fold_metrics.append({\n",
    "        'fold': fold,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nFold {fold} Results:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Calculate and display average metrics\n",
    "avg_metrics = {\n",
    "    'accuracy': np.mean([m['accuracy'] for m in fold_metrics]),\n",
    "    'precision': np.mean([m['precision'] for m in fold_metrics]),\n",
    "    'recall': np.mean([m['recall'] for m in fold_metrics]),\n",
    "    'f1': np.mean([m['f1'] for m in fold_metrics])\n",
    "}\n",
    "\n",
    "print(\"\\nAverage Metrics Across All Folds:\")\n",
    "print(f\"Average Accuracy: {avg_metrics['accuracy']:.4f}\")\n",
    "print(f\"Average Precision: {avg_metrics['precision']:.4f}\")\n",
    "print(f\"Average Recall: {avg_metrics['recall']:.4f}\")\n",
    "print(f\"Average F1 Score: {avg_metrics['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural network + GloVe word embeddings (100D) + 5-Fold Cross Validation + L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GloVe embeddings...\n",
      "Loaded 400000 word vectors.\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inflaton/anaconda3/envs/fake-news/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 69ms/step - accuracy: 0.7589 - loss: 2.5455 - val_accuracy: 0.9299 - val_loss: 0.6792\n",
      "Epoch 2/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 70ms/step - accuracy: 0.9388 - loss: 0.5804 - val_accuracy: 0.9527 - val_loss: 0.3940\n",
      "Epoch 3/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 70ms/step - accuracy: 0.9520 - loss: 0.3740 - val_accuracy: 0.9565 - val_loss: 0.3081\n",
      "Epoch 4/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 70ms/step - accuracy: 0.9555 - loss: 0.3049 - val_accuracy: 0.9569 - val_loss: 0.2742\n",
      "Epoch 5/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 70ms/step - accuracy: 0.9585 - loss: 0.2749 - val_accuracy: 0.9582 - val_loss: 0.2608\n",
      "Epoch 6/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 70ms/step - accuracy: 0.9584 - loss: 0.2639 - val_accuracy: 0.9589 - val_loss: 0.2562\n",
      "Epoch 7/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 68ms/step - accuracy: 0.9609 - loss: 0.2574 - val_accuracy: 0.9585 - val_loss: 0.2527\n",
      "Epoch 8/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 68ms/step - accuracy: 0.9598 - loss: 0.2556 - val_accuracy: 0.9585 - val_loss: 0.2523\n",
      "Epoch 9/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 69ms/step - accuracy: 0.9589 - loss: 0.2551 - val_accuracy: 0.9583 - val_loss: 0.2516\n",
      "Epoch 10/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 69ms/step - accuracy: 0.9598 - loss: 0.2541 - val_accuracy: 0.9593 - val_loss: 0.2514\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "\n",
      "Fold 1 Results:\n",
      "Accuracy: 0.9593\n",
      "Precision: 0.9428\n",
      "Recall: 0.9656\n",
      "F1-score: 0.9541\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inflaton/anaconda3/envs/fake-news/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 71ms/step - accuracy: 0.7521 - loss: 2.4965 - val_accuracy: 0.9402 - val_loss: 0.6234\n",
      "Epoch 2/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 69ms/step - accuracy: 0.9415 - loss: 0.5493 - val_accuracy: 0.9503 - val_loss: 0.3870\n",
      "Epoch 3/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 69ms/step - accuracy: 0.9545 - loss: 0.3636 - val_accuracy: 0.9620 - val_loss: 0.3019\n",
      "Epoch 4/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 69ms/step - accuracy: 0.9572 - loss: 0.2993 - val_accuracy: 0.9623 - val_loss: 0.2699\n",
      "Epoch 5/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 69ms/step - accuracy: 0.9601 - loss: 0.2696 - val_accuracy: 0.9623 - val_loss: 0.2582\n",
      "Epoch 6/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 68ms/step - accuracy: 0.9626 - loss: 0.2595 - val_accuracy: 0.9639 - val_loss: 0.2520\n",
      "Epoch 7/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 68ms/step - accuracy: 0.9609 - loss: 0.2544 - val_accuracy: 0.9641 - val_loss: 0.2486\n",
      "Epoch 8/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 69ms/step - accuracy: 0.9634 - loss: 0.2493 - val_accuracy: 0.9629 - val_loss: 0.2491\n",
      "Epoch 9/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 69ms/step - accuracy: 0.9630 - loss: 0.2493 - val_accuracy: 0.9650 - val_loss: 0.2462\n",
      "Epoch 10/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 69ms/step - accuracy: 0.9635 - loss: 0.2474 - val_accuracy: 0.9657 - val_loss: 0.2457\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "\n",
      "Fold 2 Results:\n",
      "Accuracy: 0.9657\n",
      "Precision: 0.9635\n",
      "Recall: 0.9579\n",
      "F1-score: 0.9607\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inflaton/anaconda3/envs/fake-news/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 70ms/step - accuracy: 0.7444 - loss: 2.4655 - val_accuracy: 0.9435 - val_loss: 0.5717\n",
      "Epoch 2/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 71ms/step - accuracy: 0.9403 - loss: 0.5127 - val_accuracy: 0.9549 - val_loss: 0.3501\n",
      "Epoch 3/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 73ms/step - accuracy: 0.9530 - loss: 0.3445 - val_accuracy: 0.9500 - val_loss: 0.2999\n",
      "Epoch 4/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - accuracy: 0.9553 - loss: 0.2912 - val_accuracy: 0.9584 - val_loss: 0.2651\n",
      "Epoch 5/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - accuracy: 0.9588 - loss: 0.2718 - val_accuracy: 0.9554 - val_loss: 0.2617\n",
      "Epoch 6/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 71ms/step - accuracy: 0.9583 - loss: 0.2617 - val_accuracy: 0.9590 - val_loss: 0.2532\n",
      "Epoch 7/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 73ms/step - accuracy: 0.9603 - loss: 0.2574 - val_accuracy: 0.9550 - val_loss: 0.2593\n",
      "Epoch 8/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - accuracy: 0.9587 - loss: 0.2569 - val_accuracy: 0.9585 - val_loss: 0.2538\n",
      "Epoch 9/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 73ms/step - accuracy: 0.9598 - loss: 0.2550 - val_accuracy: 0.9601 - val_loss: 0.2493\n",
      "Epoch 10/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - accuracy: 0.9617 - loss: 0.2541 - val_accuracy: 0.9573 - val_loss: 0.2528\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
      "\n",
      "Fold 3 Results:\n",
      "Accuracy: 0.9573\n",
      "Precision: 0.9684\n",
      "Recall: 0.9329\n",
      "F1-score: 0.9503\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inflaton/anaconda3/envs/fake-news/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 73ms/step - accuracy: 0.7573 - loss: 2.4107 - val_accuracy: 0.9435 - val_loss: 0.5787\n",
      "Epoch 2/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 74ms/step - accuracy: 0.9382 - loss: 0.5142 - val_accuracy: 0.9577 - val_loss: 0.3531\n",
      "Epoch 3/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - accuracy: 0.9507 - loss: 0.3443 - val_accuracy: 0.9606 - val_loss: 0.2867\n",
      "Epoch 4/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - accuracy: 0.9577 - loss: 0.2864 - val_accuracy: 0.9605 - val_loss: 0.2644\n",
      "Epoch 5/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 71ms/step - accuracy: 0.9587 - loss: 0.2680 - val_accuracy: 0.9610 - val_loss: 0.2544\n",
      "Epoch 6/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 70ms/step - accuracy: 0.9594 - loss: 0.2582 - val_accuracy: 0.9610 - val_loss: 0.2508\n",
      "Epoch 7/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 70ms/step - accuracy: 0.9617 - loss: 0.2533 - val_accuracy: 0.9611 - val_loss: 0.2483\n",
      "Epoch 8/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 71ms/step - accuracy: 0.9625 - loss: 0.2505 - val_accuracy: 0.9620 - val_loss: 0.2498\n",
      "Epoch 9/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 74ms/step - accuracy: 0.9630 - loss: 0.2494 - val_accuracy: 0.9618 - val_loss: 0.2491\n",
      "Epoch 10/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 73ms/step - accuracy: 0.9618 - loss: 0.2481 - val_accuracy: 0.9623 - val_loss: 0.2484\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "\n",
      "Fold 4 Results:\n",
      "Accuracy: 0.9623\n",
      "Precision: 0.9463\n",
      "Recall: 0.9688\n",
      "F1-score: 0.9574\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/inflaton/anaconda3/envs/fake-news/lib/python3.11/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 72ms/step - accuracy: 0.7690 - loss: 2.3907 - val_accuracy: 0.9413 - val_loss: 0.5437\n",
      "Epoch 2/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 73ms/step - accuracy: 0.9401 - loss: 0.4869 - val_accuracy: 0.9531 - val_loss: 0.3433\n",
      "Epoch 3/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - accuracy: 0.9502 - loss: 0.3382 - val_accuracy: 0.9592 - val_loss: 0.2848\n",
      "Epoch 4/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 75ms/step - accuracy: 0.9541 - loss: 0.2904 - val_accuracy: 0.9555 - val_loss: 0.2709\n",
      "Epoch 5/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 73ms/step - accuracy: 0.9563 - loss: 0.2730 - val_accuracy: 0.9604 - val_loss: 0.2559\n",
      "Epoch 6/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 74ms/step - accuracy: 0.9574 - loss: 0.2620 - val_accuracy: 0.9609 - val_loss: 0.2531\n",
      "Epoch 7/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 71ms/step - accuracy: 0.9592 - loss: 0.2590 - val_accuracy: 0.9601 - val_loss: 0.2528\n",
      "Epoch 8/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 73ms/step - accuracy: 0.9590 - loss: 0.2579 - val_accuracy: 0.9611 - val_loss: 0.2502\n",
      "Epoch 9/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 74ms/step - accuracy: 0.9604 - loss: 0.2557 - val_accuracy: 0.9628 - val_loss: 0.2484\n",
      "Epoch 10/10\n",
      "\u001b[1m190/190\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 76ms/step - accuracy: 0.9600 - loss: 0.2538 - val_accuracy: 0.9616 - val_loss: 0.2506\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n",
      "\n",
      "Fold 5 Results:\n",
      "Accuracy: 0.9616\n",
      "Precision: 0.9731\n",
      "Recall: 0.9380\n",
      "F1-score: 0.9553\n",
      "\n",
      "Average Metrics Across All Folds:\n",
      "Accuracy: 0.9613\n",
      "Precision: 0.9588\n",
      "Recall: 0.9526\n",
      "F1: 0.9556\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, Concatenate, Input\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Set seeds\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Load GloVe embeddings once (this doesn't cause data leakage)\n",
    "def load_glove_embeddings(path, embedding_dim=100):\n",
    "    print(\"Loading GloVe embeddings...\")\n",
    "    embeddings_index = {}\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = coefs\n",
    "    print(f\"Loaded {len(embeddings_index)} word vectors.\")\n",
    "    return embeddings_index\n",
    "\n",
    "def create_embedding_matrix(word_index, embeddings_index, vocab_size, embedding_dim):\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= vocab_size:\n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix\n",
    "\n",
    "def create_model(vocab_size, embedding_matrix, max_sequence_length):\n",
    "    input_layer = Input(shape=(max_sequence_length,))\n",
    "    embedding_layer = Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_matrix.shape[1],\n",
    "        weights=[embedding_matrix],\n",
    "        trainable=False,  # Set to False for pre-trained embeddings\n",
    "        input_length=max_sequence_length\n",
    "    )(input_layer)\n",
    "\n",
    "    convs = []\n",
    "    for kernel_size in [3, 4, 5]:\n",
    "        conv = Conv1D(\n",
    "            filters=64,\n",
    "            kernel_size=kernel_size,\n",
    "            activation='relu',\n",
    "            kernel_regularizer=l2(0.01)\n",
    "        )(embedding_layer)\n",
    "        pool = GlobalMaxPooling1D()(conv)\n",
    "        convs.append(pool)\n",
    "\n",
    "    merged = Concatenate()(convs)\n",
    "    dense = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(merged)\n",
    "    drop = Dropout(0.2)(dense)\n",
    "    output = Dense(1, activation='sigmoid', kernel_regularizer=l2(0.01))(drop)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def process_fold_data(train_texts, val_texts, tokenizer, max_sequence_length):\n",
    "    \"\"\"Process text data for a single fold\"\"\"\n",
    "    # Fit tokenizer on training data only\n",
    "    tokenizer.fit_on_texts(train_texts)\n",
    "    \n",
    "    # Convert texts to sequences\n",
    "    X_train = tokenizer.texts_to_sequences(train_texts)\n",
    "    X_val = tokenizer.texts_to_sequences(val_texts)\n",
    "    \n",
    "    # Pad sequences\n",
    "    X_train = pad_sequences(X_train, maxlen=max_sequence_length)\n",
    "    X_val = pad_sequences(X_val, maxlen=max_sequence_length)\n",
    "    \n",
    "    return X_train, X_val, tokenizer\n",
    "\n",
    "def main():\n",
    "    # Parameters\n",
    "    max_sequence_length = 300\n",
    "    vocab_size = 5000\n",
    "    embedding_dim = 100\n",
    "    \n",
    "    # Load GloVe embeddings\n",
    "    glove_path = './glove.6B.100d.txt'\n",
    "    embeddings_index = load_glove_embeddings(glove_path, embedding_dim)\n",
    "    \n",
    "    # Prepare for cross-validation\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    fold_metrics = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(data['processed_full_content'], data['label']), 1):\n",
    "        print(f\"\\nFold {fold}\")\n",
    "        \n",
    "        # Split data\n",
    "        train_texts = data['processed_full_content'].iloc[train_idx]\n",
    "        val_texts = data['processed_full_content'].iloc[val_idx]\n",
    "        y_train = data['label'].iloc[train_idx].values\n",
    "        y_val = data['label'].iloc[val_idx].values\n",
    "        \n",
    "        # Initialize new tokenizer for each fold\n",
    "        tokenizer = Tokenizer(num_words=vocab_size)\n",
    "        \n",
    "        # Process data for this fold\n",
    "        X_train, X_val, tokenizer = process_fold_data(\n",
    "            train_texts, val_texts, tokenizer, max_sequence_length\n",
    "        )\n",
    "        \n",
    "        # Create embedding matrix for this fold's vocabulary\n",
    "        embedding_matrix = create_embedding_matrix(\n",
    "            tokenizer.word_index, embeddings_index, vocab_size, embedding_dim\n",
    "        )\n",
    "        \n",
    "        # Compute class weights\n",
    "        class_weights = compute_class_weight('balanced', \n",
    "                                          classes=np.unique(y_train), \n",
    "                                          y=y_train)\n",
    "        class_weights_dict = dict(enumerate(class_weights))\n",
    "        \n",
    "        # Create and train model\n",
    "        model = create_model(vocab_size, embedding_matrix, max_sequence_length)\n",
    "        \n",
    "        # Train the model\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            epochs=10,\n",
    "            batch_size=256,\n",
    "            validation_data=(X_val, y_val),\n",
    "            class_weight=class_weights_dict,\n",
    "            verbose=1\n",
    "        )\n",
    "        \n",
    "        # Evaluate\n",
    "        y_pred = (model.predict(X_val) > 0.5).astype(int)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(y_val, y_pred)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_val, y_pred, average='binary')\n",
    "        \n",
    "        fold_metrics.append({\n",
    "            'fold': fold,\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1\n",
    "        })\n",
    "        \n",
    "        print(f\"\\nFold {fold} Results:\")\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"Precision: {precision:.4f}\")\n",
    "        print(f\"Recall: {recall:.4f}\")\n",
    "        print(f\"F1-score: {f1:.4f}\")\n",
    "    \n",
    "    # Calculate and print average metrics\n",
    "    avg_metrics = {\n",
    "        'accuracy': np.mean([m['accuracy'] for m in fold_metrics]),\n",
    "        'precision': np.mean([m['precision'] for m in fold_metrics]),\n",
    "        'recall': np.mean([m['recall'] for m in fold_metrics]),\n",
    "        'f1': np.mean([m['f1'] for m in fold_metrics])\n",
    "    }\n",
    "    \n",
    "    print(\"\\nAverage Metrics Across All Folds:\")\n",
    "    for metric, value in avg_metrics.items():\n",
    "        print(f\"{metric.capitalize()}: {value:.4f}\")\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural network + Custom-trained word2vec word embeddings + 5-Fold Cross Validation + L2 Regularization + GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing filters=64, dropout_rate=0.2\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.8743 - loss: 1.1206 - val_accuracy: 0.9584 - val_loss: 0.3045\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9613 - loss: 0.2693 - val_accuracy: 0.9654 - val_loss: 0.1955\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9684 - loss: 0.1877 - val_accuracy: 0.9662 - val_loss: 0.1728\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9720 - loss: 0.1653 - val_accuracy: 0.9679 - val_loss: 0.1634\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9742 - loss: 0.1523 - val_accuracy: 0.9687 - val_loss: 0.1567\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9782 - loss: 0.1398 - val_accuracy: 0.9722 - val_loss: 0.1492\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9826 - loss: 0.1310 - val_accuracy: 0.9710 - val_loss: 0.1487\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9834 - loss: 0.1262 - val_accuracy: 0.9669 - val_loss: 0.1589\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9856 - loss: 0.1188 - val_accuracy: 0.9638 - val_loss: 0.1624\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9877 - loss: 0.1132 - val_accuracy: 0.9659 - val_loss: 0.1546\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Fold 1 F1-score: 0.9619\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.8782 - loss: 1.1396 - val_accuracy: 0.9648 - val_loss: 0.3153\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9638 - loss: 0.2752 - val_accuracy: 0.9678 - val_loss: 0.1934\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9701 - loss: 0.1824 - val_accuracy: 0.9682 - val_loss: 0.1740\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9742 - loss: 0.1588 - val_accuracy: 0.9733 - val_loss: 0.1558\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9768 - loss: 0.1452 - val_accuracy: 0.9726 - val_loss: 0.1511\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9809 - loss: 0.1343 - val_accuracy: 0.9735 - val_loss: 0.1442\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9848 - loss: 0.1258 - val_accuracy: 0.9750 - val_loss: 0.1408\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9861 - loss: 0.1191 - val_accuracy: 0.9745 - val_loss: 0.1383\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9885 - loss: 0.1134 - val_accuracy: 0.9751 - val_loss: 0.1362\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9901 - loss: 0.1076 - val_accuracy: 0.9732 - val_loss: 0.1373\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Fold 2 F1-score: 0.9696\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.8584 - loss: 1.2357 - val_accuracy: 0.9622 - val_loss: 0.3420\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9624 - loss: 0.3011 - val_accuracy: 0.9678 - val_loss: 0.2089\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9695 - loss: 0.1964 - val_accuracy: 0.9664 - val_loss: 0.1802\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9719 - loss: 0.1674 - val_accuracy: 0.9693 - val_loss: 0.1658\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9752 - loss: 0.1528 - val_accuracy: 0.9707 - val_loss: 0.1592\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9794 - loss: 0.1422 - val_accuracy: 0.9708 - val_loss: 0.1520\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9817 - loss: 0.1325 - val_accuracy: 0.9706 - val_loss: 0.1491\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9823 - loss: 0.1270 - val_accuracy: 0.9718 - val_loss: 0.1476\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9861 - loss: 0.1201 - val_accuracy: 0.9722 - val_loss: 0.1450\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9873 - loss: 0.1135 - val_accuracy: 0.9723 - val_loss: 0.1426\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Fold 3 F1-score: 0.9685\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.8709 - loss: 1.2041 - val_accuracy: 0.9599 - val_loss: 0.3493\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9618 - loss: 0.3039 - val_accuracy: 0.9690 - val_loss: 0.2078\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9688 - loss: 0.1975 - val_accuracy: 0.9690 - val_loss: 0.1737\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9740 - loss: 0.1621 - val_accuracy: 0.9707 - val_loss: 0.1615\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9777 - loss: 0.1465 - val_accuracy: 0.9712 - val_loss: 0.1552\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9807 - loss: 0.1357 - val_accuracy: 0.9694 - val_loss: 0.1529\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9835 - loss: 0.1256 - val_accuracy: 0.9699 - val_loss: 0.1514\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m436s\u001b[0m 576ms/step - accuracy: 0.9858 - loss: 0.1183 - val_accuracy: 0.9731 - val_loss: 0.1424\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 18ms/step - accuracy: 0.9879 - loss: 0.1130 - val_accuracy: 0.9716 - val_loss: 0.1420\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 18ms/step - accuracy: 0.9892 - loss: 0.1090 - val_accuracy: 0.9726 - val_loss: 0.1389\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Fold 4 F1-score: 0.9685\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.8797 - loss: 1.0232 - val_accuracy: 0.9584 - val_loss: 0.2561\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9615 - loss: 0.2344 - val_accuracy: 0.9664 - val_loss: 0.1800\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 439ms/step - accuracy: 0.9678 - loss: 0.1774 - val_accuracy: 0.9677 - val_loss: 0.1659\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9723 - loss: 0.1592 - val_accuracy: 0.9685 - val_loss: 0.1624\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9746 - loss: 0.1498 - val_accuracy: 0.9708 - val_loss: 0.1534\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 337ms/step - accuracy: 0.9789 - loss: 0.1371 - val_accuracy: 0.9693 - val_loss: 0.1564\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 23ms/step - accuracy: 0.9813 - loss: 0.1305 - val_accuracy: 0.9668 - val_loss: 0.1590\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.9842 - loss: 0.1232 - val_accuracy: 0.9677 - val_loss: 0.1567\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m568s\u001b[0m 751ms/step - accuracy: 0.9858 - loss: 0.1181 - val_accuracy: 0.9676 - val_loss: 0.1552\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9876 - loss: 0.1116 - val_accuracy: 0.9689 - val_loss: 0.1497\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Fold 5 F1-score: 0.9636\n",
      "Average F1-score: 0.9664\n",
      "\n",
      "Testing filters=64, dropout_rate=0.3\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.8773 - loss: 1.0564 - val_accuracy: 0.9596 - val_loss: 0.2645\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9622 - loss: 0.2414 - val_accuracy: 0.9650 - val_loss: 0.1861\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.9685 - loss: 0.1814 - val_accuracy: 0.9663 - val_loss: 0.1724\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m640s\u001b[0m 846ms/step - accuracy: 0.9718 - loss: 0.1653 - val_accuracy: 0.9686 - val_loss: 0.1655\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9752 - loss: 0.1515 - val_accuracy: 0.9705 - val_loss: 0.1544\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9788 - loss: 0.1413 - val_accuracy: 0.9695 - val_loss: 0.1561\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9810 - loss: 0.1349 - val_accuracy: 0.9696 - val_loss: 0.1521\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9837 - loss: 0.1265 - val_accuracy: 0.9685 - val_loss: 0.1565\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m840s\u001b[0m 1s/step - accuracy: 0.9854 - loss: 0.1202 - val_accuracy: 0.9669 - val_loss: 0.1583\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9869 - loss: 0.1155 - val_accuracy: 0.9688 - val_loss: 0.1519\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Fold 1 F1-score: 0.9651\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.8722 - loss: 1.0990 - val_accuracy: 0.9631 - val_loss: 0.2947\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9620 - loss: 0.2641 - val_accuracy: 0.9724 - val_loss: 0.1904\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 18ms/step - accuracy: 0.9677 - loss: 0.1874 - val_accuracy: 0.9750 - val_loss: 0.1615\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.9741 - loss: 0.1602 - val_accuracy: 0.9752 - val_loss: 0.1529\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 23ms/step - accuracy: 0.9780 - loss: 0.1473 - val_accuracy: 0.9759 - val_loss: 0.1460\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m350s\u001b[0m 463ms/step - accuracy: 0.9806 - loss: 0.1380 - val_accuracy: 0.9776 - val_loss: 0.1407\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9830 - loss: 0.1296 - val_accuracy: 0.9777 - val_loss: 0.1374\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9846 - loss: 0.1231 - val_accuracy: 0.9778 - val_loss: 0.1343\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 425ms/step - accuracy: 0.9867 - loss: 0.1178 - val_accuracy: 0.9783 - val_loss: 0.1343\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9878 - loss: 0.1131 - val_accuracy: 0.9774 - val_loss: 0.1323\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Fold 2 F1-score: 0.9741\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.8848 - loss: 1.0383 - val_accuracy: 0.9616 - val_loss: 0.2580\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.9635 - loss: 0.2340 - val_accuracy: 0.9674 - val_loss: 0.1830\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m944s\u001b[0m 1s/step - accuracy: 0.9688 - loss: 0.1799 - val_accuracy: 0.9690 - val_loss: 0.1674\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9727 - loss: 0.1614 - val_accuracy: 0.9688 - val_loss: 0.1629\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9772 - loss: 0.1485 - val_accuracy: 0.9704 - val_loss: 0.1571\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9806 - loss: 0.1377 - val_accuracy: 0.9731 - val_loss: 0.1466\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9832 - loss: 0.1291 - val_accuracy: 0.9721 - val_loss: 0.1475\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 18ms/step - accuracy: 0.9847 - loss: 0.1217 - val_accuracy: 0.9733 - val_loss: 0.1424\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9867 - loss: 0.1161 - val_accuracy: 0.9728 - val_loss: 0.1418\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.9893 - loss: 0.1109 - val_accuracy: 0.9719 - val_loss: 0.1416\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Fold 3 F1-score: 0.9678\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.8514 - loss: 1.1425 - val_accuracy: 0.9635 - val_loss: 0.2890\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9597 - loss: 0.2702 - val_accuracy: 0.9684 - val_loss: 0.1951\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 223ms/step - accuracy: 0.9694 - loss: 0.1933 - val_accuracy: 0.9670 - val_loss: 0.1781\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9725 - loss: 0.1669 - val_accuracy: 0.9705 - val_loss: 0.1615\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9759 - loss: 0.1508 - val_accuracy: 0.9731 - val_loss: 0.1545\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m570s\u001b[0m 754ms/step - accuracy: 0.9795 - loss: 0.1401 - val_accuracy: 0.9710 - val_loss: 0.1534\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 18ms/step - accuracy: 0.9819 - loss: 0.1328 - val_accuracy: 0.9719 - val_loss: 0.1472\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9834 - loss: 0.1259 - val_accuracy: 0.9721 - val_loss: 0.1428\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9865 - loss: 0.1182 - val_accuracy: 0.9729 - val_loss: 0.1409\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9865 - loss: 0.1137 - val_accuracy: 0.9730 - val_loss: 0.1397\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Fold 4 F1-score: 0.9691\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 17ms/step - accuracy: 0.8708 - loss: 1.1624 - val_accuracy: 0.9611 - val_loss: 0.3087\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9608 - loss: 0.2812 - val_accuracy: 0.9673 - val_loss: 0.1969\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9663 - loss: 0.1969 - val_accuracy: 0.9669 - val_loss: 0.1739\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9709 - loss: 0.1711 - val_accuracy: 0.9676 - val_loss: 0.1644\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9737 - loss: 0.1556 - val_accuracy: 0.9708 - val_loss: 0.1568\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9770 - loss: 0.1427 - val_accuracy: 0.9708 - val_loss: 0.1530\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9803 - loss: 0.1352 - val_accuracy: 0.9730 - val_loss: 0.1468\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9824 - loss: 0.1277 - val_accuracy: 0.9725 - val_loss: 0.1473\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9849 - loss: 0.1206 - val_accuracy: 0.9726 - val_loss: 0.1441\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9864 - loss: 0.1154 - val_accuracy: 0.9741 - val_loss: 0.1398\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Fold 5 F1-score: 0.9700\n",
      "Average F1-score: 0.9692\n",
      "\n",
      "Testing filters=64, dropout_rate=0.4\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m552s\u001b[0m 730ms/step - accuracy: 0.8348 - loss: 1.3283 - val_accuracy: 0.9578 - val_loss: 0.3420\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9570 - loss: 0.3125 - val_accuracy: 0.9656 - val_loss: 0.2159\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9671 - loss: 0.2093 - val_accuracy: 0.9678 - val_loss: 0.1824\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m940s\u001b[0m 1s/step - accuracy: 0.9702 - loss: 0.1784 - val_accuracy: 0.9684 - val_loss: 0.1663\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9747 - loss: 0.1596 - val_accuracy: 0.9667 - val_loss: 0.1669\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9770 - loss: 0.1484 - val_accuracy: 0.9660 - val_loss: 0.1670\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9798 - loss: 0.1397 - val_accuracy: 0.9602 - val_loss: 0.1797\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9811 - loss: 0.1331 - val_accuracy: 0.9684 - val_loss: 0.1604\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9839 - loss: 0.1254 - val_accuracy: 0.9580 - val_loss: 0.1807\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9858 - loss: 0.1191 - val_accuracy: 0.9642 - val_loss: 0.1653\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Fold 1 F1-score: 0.9602\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.8675 - loss: 1.2509 - val_accuracy: 0.9604 - val_loss: 0.3282\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9605 - loss: 0.2876 - val_accuracy: 0.9683 - val_loss: 0.1992\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9675 - loss: 0.1921 - val_accuracy: 0.9675 - val_loss: 0.1790\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 18ms/step - accuracy: 0.9715 - loss: 0.1664 - val_accuracy: 0.9739 - val_loss: 0.1597\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9754 - loss: 0.1537 - val_accuracy: 0.9746 - val_loss: 0.1532\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9794 - loss: 0.1429 - val_accuracy: 0.9768 - val_loss: 0.1458\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9816 - loss: 0.1332 - val_accuracy: 0.9772 - val_loss: 0.1413\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9843 - loss: 0.1256 - val_accuracy: 0.9763 - val_loss: 0.1387\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9863 - loss: 0.1203 - val_accuracy: 0.9764 - val_loss: 0.1387\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 17ms/step - accuracy: 0.9884 - loss: 0.1146 - val_accuracy: 0.9764 - val_loss: 0.1363\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Fold 2 F1-score: 0.9731\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.8501 - loss: 1.2082 - val_accuracy: 0.9592 - val_loss: 0.2984\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.9598 - loss: 0.2728 - val_accuracy: 0.9644 - val_loss: 0.1971\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.9671 - loss: 0.1912 - val_accuracy: 0.9670 - val_loss: 0.1711\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.9704 - loss: 0.1676 - val_accuracy: 0.9683 - val_loss: 0.1602\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 23ms/step - accuracy: 0.9745 - loss: 0.1525 - val_accuracy: 0.9689 - val_loss: 0.1568\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.9791 - loss: 0.1424 - val_accuracy: 0.9703 - val_loss: 0.1513\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.9815 - loss: 0.1335 - val_accuracy: 0.9706 - val_loss: 0.1498\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9835 - loss: 0.1260 - val_accuracy: 0.9728 - val_loss: 0.1449\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9863 - loss: 0.1178 - val_accuracy: 0.9730 - val_loss: 0.1439\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 23ms/step - accuracy: 0.9882 - loss: 0.1128 - val_accuracy: 0.9728 - val_loss: 0.1431\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Fold 3 F1-score: 0.9686\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.8646 - loss: 1.1750 - val_accuracy: 0.9598 - val_loss: 0.3064\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.9599 - loss: 0.2771 - val_accuracy: 0.9675 - val_loss: 0.1988\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9667 - loss: 0.1952 - val_accuracy: 0.9693 - val_loss: 0.1736\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.9712 - loss: 0.1692 - val_accuracy: 0.9699 - val_loss: 0.1667\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.9760 - loss: 0.1546 - val_accuracy: 0.9693 - val_loss: 0.1615\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.9780 - loss: 0.1444 - val_accuracy: 0.9698 - val_loss: 0.1576\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.9818 - loss: 0.1334 - val_accuracy: 0.9698 - val_loss: 0.1532\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.9831 - loss: 0.1270 - val_accuracy: 0.9716 - val_loss: 0.1489\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.9856 - loss: 0.1212 - val_accuracy: 0.9717 - val_loss: 0.1469\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.9871 - loss: 0.1165 - val_accuracy: 0.9726 - val_loss: 0.1419\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Fold 4 F1-score: 0.9686\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.8711 - loss: 1.1378 - val_accuracy: 0.9594 - val_loss: 0.2788\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9573 - loss: 0.2574 - val_accuracy: 0.9662 - val_loss: 0.1878\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.9655 - loss: 0.1870 - val_accuracy: 0.9683 - val_loss: 0.1695\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.9696 - loss: 0.1689 - val_accuracy: 0.9683 - val_loss: 0.1644\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9744 - loss: 0.1545 - val_accuracy: 0.9700 - val_loss: 0.1548\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.9780 - loss: 0.1434 - val_accuracy: 0.9667 - val_loss: 0.1605\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.9803 - loss: 0.1373 - val_accuracy: 0.9681 - val_loss: 0.1599\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.9824 - loss: 0.1293 - val_accuracy: 0.9621 - val_loss: 0.1714\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.9835 - loss: 0.1246 - val_accuracy: 0.9646 - val_loss: 0.1629\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.9862 - loss: 0.1184 - val_accuracy: 0.9661 - val_loss: 0.1598\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Fold 5 F1-score: 0.9601\n",
      "Average F1-score: 0.9661\n",
      "\n",
      "Testing filters=64, dropout_rate=0.5\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 20ms/step - accuracy: 0.8483 - loss: 1.2288 - val_accuracy: 0.9607 - val_loss: 0.3058\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.9582 - loss: 0.2780 - val_accuracy: 0.9648 - val_loss: 0.1983\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.9661 - loss: 0.1964 - val_accuracy: 0.9668 - val_loss: 0.1782\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.9704 - loss: 0.1714 - val_accuracy: 0.9663 - val_loss: 0.1729\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9743 - loss: 0.1587 - val_accuracy: 0.9678 - val_loss: 0.1675\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.9769 - loss: 0.1487 - val_accuracy: 0.9640 - val_loss: 0.1725\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.9794 - loss: 0.1416 - val_accuracy: 0.9567 - val_loss: 0.1873\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.9804 - loss: 0.1344 - val_accuracy: 0.9594 - val_loss: 0.1801\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.9830 - loss: 0.1274 - val_accuracy: 0.9693 - val_loss: 0.1535\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.9866 - loss: 0.1205 - val_accuracy: 0.9703 - val_loss: 0.1537\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Fold 1 F1-score: 0.9667\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.8459 - loss: 1.3824 - val_accuracy: 0.9616 - val_loss: 0.3572\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.9578 - loss: 0.3190 - val_accuracy: 0.9704 - val_loss: 0.2025\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.9670 - loss: 0.2016 - val_accuracy: 0.9720 - val_loss: 0.1697\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 19ms/step - accuracy: 0.9712 - loss: 0.1688 - val_accuracy: 0.9742 - val_loss: 0.1564\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9746 - loss: 0.1547 - val_accuracy: 0.9745 - val_loss: 0.1522\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9776 - loss: 0.1457 - val_accuracy: 0.9755 - val_loss: 0.1470\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9815 - loss: 0.1369 - val_accuracy: 0.9769 - val_loss: 0.1422\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9818 - loss: 0.1308 - val_accuracy: 0.9756 - val_loss: 0.1395\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9840 - loss: 0.1253 - val_accuracy: 0.9760 - val_loss: 0.1386\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9870 - loss: 0.1174 - val_accuracy: 0.9751 - val_loss: 0.1411\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Fold 2 F1-score: 0.9718\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.8348 - loss: 1.4505 - val_accuracy: 0.9585 - val_loss: 0.3915\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9577 - loss: 0.3478 - val_accuracy: 0.9678 - val_loss: 0.2240\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 18ms/step - accuracy: 0.9659 - loss: 0.2198 - val_accuracy: 0.9693 - val_loss: 0.1773\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9701 - loss: 0.1765 - val_accuracy: 0.9686 - val_loss: 0.1657\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9723 - loss: 0.1632 - val_accuracy: 0.9682 - val_loss: 0.1644\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 20ms/step - accuracy: 0.9769 - loss: 0.1504 - val_accuracy: 0.9730 - val_loss: 0.1529\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 18ms/step - accuracy: 0.9803 - loss: 0.1398 - val_accuracy: 0.9721 - val_loss: 0.1490\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 18ms/step - accuracy: 0.9828 - loss: 0.1317 - val_accuracy: 0.9727 - val_loss: 0.1463\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 18ms/step - accuracy: 0.9842 - loss: 0.1267 - val_accuracy: 0.9736 - val_loss: 0.1444\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 18ms/step - accuracy: 0.9872 - loss: 0.1197 - val_accuracy: 0.9717 - val_loss: 0.1432\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Fold 3 F1-score: 0.9675\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.8482 - loss: 1.3197 - val_accuracy: 0.9623 - val_loss: 0.3502\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9590 - loss: 0.3130 - val_accuracy: 0.9696 - val_loss: 0.2043\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9669 - loss: 0.2006 - val_accuracy: 0.9671 - val_loss: 0.1785\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 19ms/step - accuracy: 0.9709 - loss: 0.1690 - val_accuracy: 0.9673 - val_loss: 0.1692\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9752 - loss: 0.1559 - val_accuracy: 0.9687 - val_loss: 0.1622\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9784 - loss: 0.1435 - val_accuracy: 0.9696 - val_loss: 0.1583\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9808 - loss: 0.1367 - val_accuracy: 0.9713 - val_loss: 0.1506\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9842 - loss: 0.1274 - val_accuracy: 0.9731 - val_loss: 0.1452\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9866 - loss: 0.1201 - val_accuracy: 0.9745 - val_loss: 0.1403\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9879 - loss: 0.1167 - val_accuracy: 0.9739 - val_loss: 0.1413\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Fold 4 F1-score: 0.9700\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.8622 - loss: 1.2657 - val_accuracy: 0.9545 - val_loss: 0.3380\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9558 - loss: 0.3006 - val_accuracy: 0.9655 - val_loss: 0.2047\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9638 - loss: 0.2048 - val_accuracy: 0.9669 - val_loss: 0.1786\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9687 - loss: 0.1773 - val_accuracy: 0.9683 - val_loss: 0.1684\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9731 - loss: 0.1642 - val_accuracy: 0.9652 - val_loss: 0.1715\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9752 - loss: 0.1539 - val_accuracy: 0.9705 - val_loss: 0.1589\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9774 - loss: 0.1435 - val_accuracy: 0.9705 - val_loss: 0.1544\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9810 - loss: 0.1352 - val_accuracy: 0.9656 - val_loss: 0.1651\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9816 - loss: 0.1314 - val_accuracy: 0.9696 - val_loss: 0.1537\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 18ms/step - accuracy: 0.9837 - loss: 0.1263 - val_accuracy: 0.9719 - val_loss: 0.1485\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Fold 5 F1-score: 0.9673\n",
      "Average F1-score: 0.9686\n",
      "\n",
      "Testing filters=128, dropout_rate=0.2\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.8899 - loss: 1.3452 - val_accuracy: 0.9627 - val_loss: 0.3355\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - accuracy: 0.9621 - loss: 0.2940 - val_accuracy: 0.9659 - val_loss: 0.2026\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9674 - loss: 0.1950 - val_accuracy: 0.9656 - val_loss: 0.1764\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9720 - loss: 0.1694 - val_accuracy: 0.9682 - val_loss: 0.1646\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9751 - loss: 0.1541 - val_accuracy: 0.9703 - val_loss: 0.1564\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9795 - loss: 0.1401 - val_accuracy: 0.9722 - val_loss: 0.1485\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9819 - loss: 0.1322 - val_accuracy: 0.9697 - val_loss: 0.1545\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9841 - loss: 0.1268 - val_accuracy: 0.9692 - val_loss: 0.1567\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9850 - loss: 0.1194 - val_accuracy: 0.9685 - val_loss: 0.1536\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9887 - loss: 0.1133 - val_accuracy: 0.9650 - val_loss: 0.1578\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Fold 1 F1-score: 0.9610\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 21ms/step - accuracy: 0.8837 - loss: 1.4721 - val_accuracy: 0.9683 - val_loss: 0.3744\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 311ms/step - accuracy: 0.9633 - loss: 0.3294 - val_accuracy: 0.9706 - val_loss: 0.2180\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.9697 - loss: 0.2039 - val_accuracy: 0.9713 - val_loss: 0.1781\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.9732 - loss: 0.1690 - val_accuracy: 0.9749 - val_loss: 0.1603\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.9778 - loss: 0.1502 - val_accuracy: 0.9744 - val_loss: 0.1525\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.9796 - loss: 0.1399 - val_accuracy: 0.9755 - val_loss: 0.1448\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 22ms/step - accuracy: 0.9815 - loss: 0.1314 - val_accuracy: 0.9752 - val_loss: 0.1442\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 22ms/step - accuracy: 0.9843 - loss: 0.1245 - val_accuracy: 0.9758 - val_loss: 0.1397\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.9862 - loss: 0.1174 - val_accuracy: 0.9742 - val_loss: 0.1404\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 21ms/step - accuracy: 0.9882 - loss: 0.1117 - val_accuracy: 0.9765 - val_loss: 0.1340\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Fold 2 F1-score: 0.9733\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - accuracy: 0.8916 - loss: 1.2895 - val_accuracy: 0.9659 - val_loss: 0.2754\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.9633 - loss: 0.2491 - val_accuracy: 0.9640 - val_loss: 0.1952\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 30ms/step - accuracy: 0.9690 - loss: 0.1803 - val_accuracy: 0.9648 - val_loss: 0.1794\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 32ms/step - accuracy: 0.9727 - loss: 0.1613 - val_accuracy: 0.9673 - val_loss: 0.1661\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 35ms/step - accuracy: 0.9760 - loss: 0.1492 - val_accuracy: 0.9689 - val_loss: 0.1579\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 36ms/step - accuracy: 0.9802 - loss: 0.1367 - val_accuracy: 0.9716 - val_loss: 0.1494\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 41ms/step - accuracy: 0.9834 - loss: 0.1283 - val_accuracy: 0.9717 - val_loss: 0.1448\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 33ms/step - accuracy: 0.9851 - loss: 0.1224 - val_accuracy: 0.9720 - val_loss: 0.1438\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 30ms/step - accuracy: 0.9871 - loss: 0.1163 - val_accuracy: 0.9721 - val_loss: 0.1426\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 29ms/step - accuracy: 0.9887 - loss: 0.1101 - val_accuracy: 0.9740 - val_loss: 0.1385\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
      "Fold 3 F1-score: 0.9702\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 27ms/step - accuracy: 0.9005 - loss: 1.2524 - val_accuracy: 0.9631 - val_loss: 0.2773\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - accuracy: 0.9639 - loss: 0.2497 - val_accuracy: 0.9640 - val_loss: 0.1964\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 29ms/step - accuracy: 0.9699 - loss: 0.1816 - val_accuracy: 0.9664 - val_loss: 0.1744\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - accuracy: 0.9728 - loss: 0.1615 - val_accuracy: 0.9707 - val_loss: 0.1601\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9775 - loss: 0.1467 - val_accuracy: 0.9712 - val_loss: 0.1562\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9799 - loss: 0.1368 - val_accuracy: 0.9716 - val_loss: 0.1511\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9831 - loss: 0.1274 - val_accuracy: 0.9716 - val_loss: 0.1448\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9846 - loss: 0.1209 - val_accuracy: 0.9733 - val_loss: 0.1411\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - accuracy: 0.9866 - loss: 0.1142 - val_accuracy: 0.9730 - val_loss: 0.1408\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 26ms/step - accuracy: 0.9891 - loss: 0.1074 - val_accuracy: 0.9737 - val_loss: 0.1361\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Fold 4 F1-score: 0.9698\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - accuracy: 0.8801 - loss: 1.3458 - val_accuracy: 0.9580 - val_loss: 0.3107\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9617 - loss: 0.2731 - val_accuracy: 0.9645 - val_loss: 0.1983\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9657 - loss: 0.1917 - val_accuracy: 0.9669 - val_loss: 0.1708\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9709 - loss: 0.1661 - val_accuracy: 0.9668 - val_loss: 0.1662\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9751 - loss: 0.1522 - val_accuracy: 0.9720 - val_loss: 0.1536\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9785 - loss: 0.1401 - val_accuracy: 0.9707 - val_loss: 0.1552\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9805 - loss: 0.1337 - val_accuracy: 0.9718 - val_loss: 0.1472\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - accuracy: 0.9833 - loss: 0.1258 - val_accuracy: 0.9704 - val_loss: 0.1504\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 26ms/step - accuracy: 0.9847 - loss: 0.1200 - val_accuracy: 0.9716 - val_loss: 0.1456\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9867 - loss: 0.1164 - val_accuracy: 0.9712 - val_loss: 0.1435\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Fold 5 F1-score: 0.9666\n",
      "Average F1-score: 0.9682\n",
      "\n",
      "Testing filters=128, dropout_rate=0.3\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.8862 - loss: 1.3940 - val_accuracy: 0.9599 - val_loss: 0.3142\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9624 - loss: 0.2784 - val_accuracy: 0.9633 - val_loss: 0.2009\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9656 - loss: 0.1957 - val_accuracy: 0.9674 - val_loss: 0.1782\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9712 - loss: 0.1698 - val_accuracy: 0.9703 - val_loss: 0.1633\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9743 - loss: 0.1568 - val_accuracy: 0.9727 - val_loss: 0.1535\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9779 - loss: 0.1431 - val_accuracy: 0.9737 - val_loss: 0.1457\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - accuracy: 0.9814 - loss: 0.1322 - val_accuracy: 0.9719 - val_loss: 0.1510\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9841 - loss: 0.1242 - val_accuracy: 0.9723 - val_loss: 0.1460\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9864 - loss: 0.1187 - val_accuracy: 0.9693 - val_loss: 0.1508\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9886 - loss: 0.1128 - val_accuracy: 0.9708 - val_loss: 0.1473\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Fold 1 F1-score: 0.9672\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.8734 - loss: 1.4608 - val_accuracy: 0.9673 - val_loss: 0.3614\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9621 - loss: 0.3195 - val_accuracy: 0.9701 - val_loss: 0.2164\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9683 - loss: 0.2086 - val_accuracy: 0.9701 - val_loss: 0.1809\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9720 - loss: 0.1711 - val_accuracy: 0.9735 - val_loss: 0.1624\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9761 - loss: 0.1543 - val_accuracy: 0.9769 - val_loss: 0.1501\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - accuracy: 0.9805 - loss: 0.1410 - val_accuracy: 0.9753 - val_loss: 0.1461\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9826 - loss: 0.1335 - val_accuracy: 0.9774 - val_loss: 0.1398\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9842 - loss: 0.1259 - val_accuracy: 0.9766 - val_loss: 0.1374\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9862 - loss: 0.1193 - val_accuracy: 0.9764 - val_loss: 0.1346\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9880 - loss: 0.1141 - val_accuracy: 0.9767 - val_loss: 0.1335\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Fold 2 F1-score: 0.9734\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.8748 - loss: 1.4199 - val_accuracy: 0.9640 - val_loss: 0.3337\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9629 - loss: 0.2997 - val_accuracy: 0.9669 - val_loss: 0.2114\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 26ms/step - accuracy: 0.9689 - loss: 0.1997 - val_accuracy: 0.9633 - val_loss: 0.1836\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9716 - loss: 0.1693 - val_accuracy: 0.9665 - val_loss: 0.1714\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9752 - loss: 0.1555 - val_accuracy: 0.9696 - val_loss: 0.1583\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9788 - loss: 0.1416 - val_accuracy: 0.9720 - val_loss: 0.1470\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9803 - loss: 0.1331 - val_accuracy: 0.9735 - val_loss: 0.1430\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 27ms/step - accuracy: 0.9835 - loss: 0.1247 - val_accuracy: 0.9725 - val_loss: 0.1424\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9854 - loss: 0.1181 - val_accuracy: 0.9731 - val_loss: 0.1405\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 26ms/step - accuracy: 0.9870 - loss: 0.1137 - val_accuracy: 0.9730 - val_loss: 0.1392\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
      "Fold 3 F1-score: 0.9688\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.8856 - loss: 1.2405 - val_accuracy: 0.9640 - val_loss: 0.2766\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9631 - loss: 0.2531 - val_accuracy: 0.9653 - val_loss: 0.1946\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9696 - loss: 0.1820 - val_accuracy: 0.9707 - val_loss: 0.1675\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9719 - loss: 0.1628 - val_accuracy: 0.9701 - val_loss: 0.1618\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9768 - loss: 0.1471 - val_accuracy: 0.9727 - val_loss: 0.1505\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9800 - loss: 0.1353 - val_accuracy: 0.9725 - val_loss: 0.1458\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9834 - loss: 0.1272 - val_accuracy: 0.9719 - val_loss: 0.1432\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9853 - loss: 0.1198 - val_accuracy: 0.9714 - val_loss: 0.1424\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9860 - loss: 0.1150 - val_accuracy: 0.9740 - val_loss: 0.1380\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9892 - loss: 0.1089 - val_accuracy: 0.9732 - val_loss: 0.1385\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Fold 4 F1-score: 0.9693\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - accuracy: 0.8860 - loss: 1.3692 - val_accuracy: 0.9559 - val_loss: 0.3234\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9591 - loss: 0.2769 - val_accuracy: 0.9640 - val_loss: 0.1977\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9663 - loss: 0.1905 - val_accuracy: 0.9673 - val_loss: 0.1725\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9706 - loss: 0.1699 - val_accuracy: 0.9683 - val_loss: 0.1645\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9737 - loss: 0.1560 - val_accuracy: 0.9719 - val_loss: 0.1539\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9773 - loss: 0.1425 - val_accuracy: 0.9683 - val_loss: 0.1582\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9808 - loss: 0.1340 - val_accuracy: 0.9696 - val_loss: 0.1553\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9823 - loss: 0.1283 - val_accuracy: 0.9702 - val_loss: 0.1524\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - accuracy: 0.9841 - loss: 0.1216 - val_accuracy: 0.9702 - val_loss: 0.1471\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9858 - loss: 0.1157 - val_accuracy: 0.9704 - val_loss: 0.1458\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Fold 5 F1-score: 0.9654\n",
      "Average F1-score: 0.9688\n",
      "\n",
      "Testing filters=128, dropout_rate=0.4\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.8767 - loss: 1.3687 - val_accuracy: 0.9626 - val_loss: 0.2972\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9611 - loss: 0.2670 - val_accuracy: 0.9629 - val_loss: 0.2011\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9677 - loss: 0.1919 - val_accuracy: 0.9666 - val_loss: 0.1770\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 26ms/step - accuracy: 0.9709 - loss: 0.1718 - val_accuracy: 0.9659 - val_loss: 0.1698\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9750 - loss: 0.1596 - val_accuracy: 0.9711 - val_loss: 0.1581\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9781 - loss: 0.1458 - val_accuracy: 0.9724 - val_loss: 0.1523\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9805 - loss: 0.1377 - val_accuracy: 0.9702 - val_loss: 0.1564\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - accuracy: 0.9819 - loss: 0.1314 - val_accuracy: 0.9684 - val_loss: 0.1596\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9844 - loss: 0.1242 - val_accuracy: 0.9636 - val_loss: 0.1672\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9856 - loss: 0.1201 - val_accuracy: 0.9573 - val_loss: 0.1789\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Fold 1 F1-score: 0.9530\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 29ms/step - accuracy: 0.8699 - loss: 1.4769 - val_accuracy: 0.9646 - val_loss: 0.3506\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 38ms/step - accuracy: 0.9606 - loss: 0.3133 - val_accuracy: 0.9683 - val_loss: 0.2087\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 45ms/step - accuracy: 0.9684 - loss: 0.2027 - val_accuracy: 0.9583 - val_loss: 0.1982\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 28ms/step - accuracy: 0.9712 - loss: 0.1726 - val_accuracy: 0.9735 - val_loss: 0.1629\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - accuracy: 0.9773 - loss: 0.1531 - val_accuracy: 0.9761 - val_loss: 0.1486\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9795 - loss: 0.1420 - val_accuracy: 0.9764 - val_loss: 0.1426\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9817 - loss: 0.1346 - val_accuracy: 0.9748 - val_loss: 0.1461\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 26ms/step - accuracy: 0.9828 - loss: 0.1293 - val_accuracy: 0.9777 - val_loss: 0.1385\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - accuracy: 0.9870 - loss: 0.1216 - val_accuracy: 0.9762 - val_loss: 0.1382\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - accuracy: 0.9893 - loss: 0.1157 - val_accuracy: 0.9747 - val_loss: 0.1407\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step\n",
      "Fold 2 F1-score: 0.9714\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - accuracy: 0.8725 - loss: 1.4259 - val_accuracy: 0.9631 - val_loss: 0.3316\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 26ms/step - accuracy: 0.9608 - loss: 0.2938 - val_accuracy: 0.9667 - val_loss: 0.2056\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9664 - loss: 0.1986 - val_accuracy: 0.9669 - val_loss: 0.1808\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9704 - loss: 0.1731 - val_accuracy: 0.9692 - val_loss: 0.1668\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - accuracy: 0.9748 - loss: 0.1563 - val_accuracy: 0.9727 - val_loss: 0.1548\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9771 - loss: 0.1464 - val_accuracy: 0.9743 - val_loss: 0.1492\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - accuracy: 0.9807 - loss: 0.1382 - val_accuracy: 0.9733 - val_loss: 0.1459\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9819 - loss: 0.1309 - val_accuracy: 0.9737 - val_loss: 0.1435\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9840 - loss: 0.1238 - val_accuracy: 0.9730 - val_loss: 0.1432\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - accuracy: 0.9856 - loss: 0.1193 - val_accuracy: 0.9716 - val_loss: 0.1412\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Fold 3 F1-score: 0.9672\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.8723 - loss: 1.5057 - val_accuracy: 0.9633 - val_loss: 0.3321\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9621 - loss: 0.2945 - val_accuracy: 0.9651 - val_loss: 0.2071\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9684 - loss: 0.1971 - val_accuracy: 0.9698 - val_loss: 0.1734\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9717 - loss: 0.1699 - val_accuracy: 0.9723 - val_loss: 0.1636\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.9750 - loss: 0.1559 - val_accuracy: 0.9702 - val_loss: 0.1591\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9792 - loss: 0.1430 - val_accuracy: 0.9723 - val_loss: 0.1504\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9809 - loss: 0.1339 - val_accuracy: 0.9710 - val_loss: 0.1529\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9840 - loss: 0.1256 - val_accuracy: 0.9739 - val_loss: 0.1448\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9866 - loss: 0.1194 - val_accuracy: 0.9749 - val_loss: 0.1421\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9883 - loss: 0.1127 - val_accuracy: 0.9759 - val_loss: 0.1383\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Fold 4 F1-score: 0.9725\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.8656 - loss: 1.4935 - val_accuracy: 0.9614 - val_loss: 0.3440\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 26ms/step - accuracy: 0.9594 - loss: 0.3111 - val_accuracy: 0.9646 - val_loss: 0.2127\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9647 - loss: 0.2065 - val_accuracy: 0.9689 - val_loss: 0.1759\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9696 - loss: 0.1741 - val_accuracy: 0.9675 - val_loss: 0.1667\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9750 - loss: 0.1574 - val_accuracy: 0.9709 - val_loss: 0.1563\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9772 - loss: 0.1465 - val_accuracy: 0.9717 - val_loss: 0.1510\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9797 - loss: 0.1389 - val_accuracy: 0.9683 - val_loss: 0.1564\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9823 - loss: 0.1308 - val_accuracy: 0.9671 - val_loss: 0.1575\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9826 - loss: 0.1259 - val_accuracy: 0.9697 - val_loss: 0.1506\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9874 - loss: 0.1190 - val_accuracy: 0.9663 - val_loss: 0.1563\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Fold 5 F1-score: 0.9603\n",
      "Average F1-score: 0.9649\n",
      "\n",
      "Testing filters=128, dropout_rate=0.5\n",
      "\n",
      "Fold 1\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.8756 - loss: 1.3189 - val_accuracy: 0.9623 - val_loss: 0.2847\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 30ms/step - accuracy: 0.9611 - loss: 0.2628 - val_accuracy: 0.9634 - val_loss: 0.1998\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9657 - loss: 0.1959 - val_accuracy: 0.9663 - val_loss: 0.1768\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9714 - loss: 0.1714 - val_accuracy: 0.9674 - val_loss: 0.1658\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9749 - loss: 0.1559 - val_accuracy: 0.9717 - val_loss: 0.1566\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9782 - loss: 0.1456 - val_accuracy: 0.9669 - val_loss: 0.1654\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9810 - loss: 0.1388 - val_accuracy: 0.9605 - val_loss: 0.1789\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9819 - loss: 0.1330 - val_accuracy: 0.9663 - val_loss: 0.1624\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9844 - loss: 0.1262 - val_accuracy: 0.9679 - val_loss: 0.1576\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9870 - loss: 0.1190 - val_accuracy: 0.9680 - val_loss: 0.1528\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Fold 1 F1-score: 0.9641\n",
      "\n",
      "Fold 2\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - accuracy: 0.8716 - loss: 1.5264 - val_accuracy: 0.9667 - val_loss: 0.3244\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9613 - loss: 0.2966 - val_accuracy: 0.9690 - val_loss: 0.2010\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9686 - loss: 0.1986 - val_accuracy: 0.9704 - val_loss: 0.1724\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9709 - loss: 0.1725 - val_accuracy: 0.9724 - val_loss: 0.1626\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9730 - loss: 0.1606 - val_accuracy: 0.9768 - val_loss: 0.1496\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9789 - loss: 0.1460 - val_accuracy: 0.9766 - val_loss: 0.1450\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9812 - loss: 0.1370 - val_accuracy: 0.9776 - val_loss: 0.1405\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9835 - loss: 0.1305 - val_accuracy: 0.9745 - val_loss: 0.1436\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9850 - loss: 0.1250 - val_accuracy: 0.9769 - val_loss: 0.1376\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9880 - loss: 0.1179 - val_accuracy: 0.9770 - val_loss: 0.1345\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Fold 2 F1-score: 0.9738\n",
      "\n",
      "Fold 3\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - accuracy: 0.8648 - loss: 1.4890 - val_accuracy: 0.9629 - val_loss: 0.3232\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9605 - loss: 0.2913 - val_accuracy: 0.9674 - val_loss: 0.2002\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 38ms/step - accuracy: 0.9677 - loss: 0.1983 - val_accuracy: 0.9632 - val_loss: 0.1869\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 29ms/step - accuracy: 0.9710 - loss: 0.1708 - val_accuracy: 0.9688 - val_loss: 0.1648\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 23ms/step - accuracy: 0.9752 - loss: 0.1575 - val_accuracy: 0.9712 - val_loss: 0.1588\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9772 - loss: 0.1484 - val_accuracy: 0.9724 - val_loss: 0.1499\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9801 - loss: 0.1382 - val_accuracy: 0.9730 - val_loss: 0.1441\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9828 - loss: 0.1301 - val_accuracy: 0.9735 - val_loss: 0.1434\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9846 - loss: 0.1230 - val_accuracy: 0.9730 - val_loss: 0.1452\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9862 - loss: 0.1199 - val_accuracy: 0.9726 - val_loss: 0.1423\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Fold 3 F1-score: 0.9684\n",
      "\n",
      "Fold 4\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 25ms/step - accuracy: 0.8624 - loss: 1.4354 - val_accuracy: 0.9640 - val_loss: 0.3127\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9600 - loss: 0.2928 - val_accuracy: 0.9677 - val_loss: 0.2005\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9680 - loss: 0.1988 - val_accuracy: 0.9687 - val_loss: 0.1753\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - accuracy: 0.9713 - loss: 0.1746 - val_accuracy: 0.9707 - val_loss: 0.1689\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9738 - loss: 0.1641 - val_accuracy: 0.9703 - val_loss: 0.1614\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9789 - loss: 0.1478 - val_accuracy: 0.9714 - val_loss: 0.1555\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9815 - loss: 0.1390 - val_accuracy: 0.9708 - val_loss: 0.1548\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9830 - loss: 0.1338 - val_accuracy: 0.9731 - val_loss: 0.1464\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 24ms/step - accuracy: 0.9840 - loss: 0.1269 - val_accuracy: 0.9721 - val_loss: 0.1471\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9864 - loss: 0.1205 - val_accuracy: 0.9737 - val_loss: 0.1446\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Fold 4 F1-score: 0.9702\n",
      "\n",
      "Fold 5\n",
      "Epoch 1/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.8702 - loss: 1.4125 - val_accuracy: 0.9621 - val_loss: 0.3153\n",
      "Epoch 2/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9587 - loss: 0.2951 - val_accuracy: 0.9667 - val_loss: 0.2008\n",
      "Epoch 3/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9648 - loss: 0.2059 - val_accuracy: 0.9679 - val_loss: 0.1774\n",
      "Epoch 4/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9697 - loss: 0.1794 - val_accuracy: 0.9702 - val_loss: 0.1622\n",
      "Epoch 5/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9743 - loss: 0.1622 - val_accuracy: 0.9651 - val_loss: 0.1719\n",
      "Epoch 6/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9771 - loss: 0.1508 - val_accuracy: 0.9696 - val_loss: 0.1569\n",
      "Epoch 7/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.9794 - loss: 0.1430 - val_accuracy: 0.9669 - val_loss: 0.1637\n",
      "Epoch 8/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9817 - loss: 0.1347 - val_accuracy: 0.9704 - val_loss: 0.1483\n",
      "Epoch 9/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9836 - loss: 0.1276 - val_accuracy: 0.9721 - val_loss: 0.1446\n",
      "Epoch 10/10\n",
      "\u001b[1m757/757\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9846 - loss: 0.1228 - val_accuracy: 0.9707 - val_loss: 0.1470\n",
      "\u001b[1m379/379\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Fold 5 F1-score: 0.9658\n",
      "Average F1-score: 0.9684\n",
      "\n",
      "Grid Search Results:\n",
      "Filters: 64, Dropout: 0.2, F1-score: 0.9664\n",
      "Filters: 64, Dropout: 0.3, F1-score: 0.9692\n",
      "Filters: 64, Dropout: 0.4, F1-score: 0.9661\n",
      "Filters: 64, Dropout: 0.5, F1-score: 0.9686\n",
      "Filters: 128, Dropout: 0.2, F1-score: 0.9682\n",
      "Filters: 128, Dropout: 0.3, F1-score: 0.9688\n",
      "Filters: 128, Dropout: 0.4, F1-score: 0.9649\n",
      "Filters: 128, Dropout: 0.5, F1-score: 0.9684\n",
      "\n",
      "Best Parameters:\n",
      "Filters: 64\n",
      "Dropout Rate: 0.3\n",
      "Best F1-Score: 0.9692\n",
      "\n",
      "Results Summary:\n",
      "   filters  dropout_rate  avg_f1_score  \\\n",
      "1       64           0.3      0.969211   \n",
      "5      128           0.3      0.968818   \n",
      "3       64           0.5      0.968650   \n",
      "7      128           0.5      0.968443   \n",
      "4      128           0.2      0.968160   \n",
      "0       64           0.2      0.966426   \n",
      "2       64           0.4      0.966095   \n",
      "6      128           0.4      0.964880   \n",
      "\n",
      "                                         fold_scores  \n",
      "1  [0.9650699527471509, 0.9741452789089876, 0.967...  \n",
      "5  [0.9671841591521799, 0.9733509733509733, 0.968...  \n",
      "3  [0.9666635713622435, 0.9717874215015465, 0.967...  \n",
      "7  [0.9640901920757168, 0.9737983034872761, 0.968...  \n",
      "4  [0.9610246014926749, 0.9732529666603881, 0.970...  \n",
      "0  [0.9619364375461936, 0.9696117051209905, 0.968...  \n",
      "2  [0.960176584199393, 0.9730598355232064, 0.9685...  \n",
      "6  [0.9529529529529529, 0.9713590415574691, 0.967...  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout, Input\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from gensim.models import Word2Vec\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "def train_word2vec_and_create_embeddings(train_texts, word_index, max_words, embedding_dim=100):\n",
    "    \"\"\"Train Word2Vec on training data only and create embedding matrix\"\"\"\n",
    "    # Train Word2Vec on training data only\n",
    "    train_sentences = [text.split() for text in train_texts]\n",
    "    word2vec_model = Word2Vec(sentences=train_sentences, \n",
    "                            vector_size=embedding_dim, \n",
    "                            window=5, \n",
    "                            min_count=2, \n",
    "                            workers=4)\n",
    "    \n",
    "    # Create embedding matrix with correct dimensions\n",
    "    vocab_size = min(max_words, len(word_index) + 1)\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "    \n",
    "    for word, i in word_index.items():\n",
    "        if i < vocab_size:  # Only include words within max_words limit\n",
    "            if word in word2vec_model.wv:\n",
    "                embedding_matrix[i] = word2vec_model.wv[word]\n",
    "            else:\n",
    "                embedding_matrix[i] = np.random.normal(size=(embedding_dim,))\n",
    "            \n",
    "    return embedding_matrix\n",
    "\n",
    "def create_model(max_sequence_length, vocab_size, embedding_dim, embedding_matrix, \n",
    "                filters, dropout_rate):\n",
    "    input_layer = Input(shape=(max_sequence_length,))\n",
    "    embedding_layer = Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        weights=[embedding_matrix],\n",
    "        trainable=True\n",
    "    )(input_layer)\n",
    "\n",
    "    x = Conv1D(\n",
    "        filters=filters,\n",
    "        kernel_size=5,\n",
    "        activation='relu',\n",
    "        kernel_regularizer=l2(0.01)\n",
    "    )(embedding_layer)\n",
    "    \n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    x = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    output_layer = Dense(1, activation='sigmoid', kernel_regularizer=l2(0.01))(x)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def main():\n",
    "    # Define parameter grid\n",
    "    param_grid = {\n",
    "        'filters': [64, 128],\n",
    "        'dropout_rate': [0.2, 0.3, 0.4, 0.5]\n",
    "    }\n",
    "\n",
    "    # Initialize variables to track results\n",
    "    results = []\n",
    "    best_score = 0\n",
    "    best_params = None\n",
    "\n",
    "    # Constants\n",
    "    max_words = 10000\n",
    "    max_sequence_length = 300\n",
    "    embedding_dim = 100\n",
    "\n",
    "    # Perform grid search with cross-validation\n",
    "    for filters in param_grid['filters']:\n",
    "        for dropout_rate in param_grid['dropout_rate']:\n",
    "            print(f\"\\nTesting filters={filters}, dropout_rate={dropout_rate}\")\n",
    "            \n",
    "            # Initialize cross-validation\n",
    "            kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "            fold_scores = []\n",
    "            \n",
    "            # Perform k-fold cross-validation\n",
    "            for fold, (train_idx, val_idx) in enumerate(kfold.split(data['processed_full_content'], data['label']), 1):\n",
    "                print(f\"\\nFold {fold}\")\n",
    "                \n",
    "                # Split data\n",
    "                train_texts = data['processed_full_content'].iloc[train_idx]\n",
    "                val_texts = data['processed_full_content'].iloc[val_idx]\n",
    "                y_train = data['label'].iloc[train_idx]\n",
    "                y_val = data['label'].iloc[val_idx]\n",
    "                \n",
    "                # Fit tokenizer on training data only\n",
    "                tokenizer = Tokenizer(num_words=max_words)\n",
    "                tokenizer.fit_on_texts(train_texts)\n",
    "                \n",
    "                # Convert texts to sequences\n",
    "                X_train = pad_sequences(tokenizer.texts_to_sequences(train_texts), \n",
    "                                      maxlen=max_sequence_length)\n",
    "                X_val = pad_sequences(tokenizer.texts_to_sequences(val_texts), \n",
    "                                    maxlen=max_sequence_length)\n",
    "                \n",
    "                # Get vocab size for this fold\n",
    "                vocab_size = min(max_words, len(tokenizer.word_index) + 1)\n",
    "                \n",
    "                # Create embedding matrix using training data only\n",
    "                embedding_matrix = train_word2vec_and_create_embeddings(\n",
    "                    train_texts, \n",
    "                    tokenizer.word_index,\n",
    "                    max_words,\n",
    "                    embedding_dim\n",
    "                )\n",
    "                \n",
    "                # Create and train model\n",
    "                model = create_model(\n",
    "                    max_sequence_length=max_sequence_length,\n",
    "                    vocab_size=vocab_size,\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    embedding_matrix=embedding_matrix,\n",
    "                    filters=filters,\n",
    "                    dropout_rate=dropout_rate\n",
    "                )\n",
    "                \n",
    "                # Train model\n",
    "                history = model.fit(\n",
    "                    X_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=64,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    verbose=1\n",
    "                )\n",
    "                \n",
    "                # Evaluate using F1-score\n",
    "                y_pred = (model.predict(X_val) > 0.5).astype(int)\n",
    "                fold_score = f1_score(y_val, y_pred)\n",
    "                fold_scores.append(fold_score)\n",
    "                \n",
    "                print(f\"Fold {fold} F1-score: {fold_score:.4f}\")\n",
    "            \n",
    "            # Calculate average score for this parameter combination\n",
    "            avg_score = np.mean(fold_scores)\n",
    "            print(f\"Average F1-score: {avg_score:.4f}\")\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                'filters': filters,\n",
    "                'dropout_rate': dropout_rate,\n",
    "                'avg_f1_score': avg_score,\n",
    "                'fold_scores': fold_scores\n",
    "            })\n",
    "            \n",
    "            # Update best parameters if necessary\n",
    "            if avg_score > best_score:\n",
    "                best_score = avg_score\n",
    "                best_params = {'filters': filters, 'dropout_rate': dropout_rate}\n",
    "\n",
    "    # Print final results\n",
    "    print(\"\\nGrid Search Results:\")\n",
    "    for result in results:\n",
    "        print(f\"Filters: {result['filters']}, Dropout: {result['dropout_rate']}, \"\n",
    "              f\"F1-score: {result['avg_f1_score']:.4f}\")\n",
    "\n",
    "    print(\"\\nBest Parameters:\")\n",
    "    print(f\"Filters: {best_params['filters']}\")\n",
    "    print(f\"Dropout Rate: {best_params['dropout_rate']}\")\n",
    "    print(f\"Best F1-Score: {best_score:.4f}\")\n",
    "\n",
    "    # Save results to DataFrame for easy analysis\n",
    "    import pandas as pd\n",
    "    results_df = pd.DataFrame(results)\n",
    "    print(\"\\nResults Summary:\")\n",
    "    print(results_df.sort_values('avg_f1_score', ascending=False))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fake-news",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
