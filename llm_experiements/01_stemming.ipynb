{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working dir: /home/inflaton/code/CrediNews\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "if \"workding_dir\" not in locals():\n",
    "    workding_dir = str(Path.cwd().parent)\n",
    "os.chdir(workding_dir)\n",
    "sys.path.append(workding_dir)\n",
    "print(\"working dir:\", workding_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From Detection to Credibility: A Machine Learning Framework for Assessing News Source Reliability\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Statistical functions\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# For concurrency (running functions in parallel)\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# For caching (to speed up repeated function calls)\n",
    "from functools import lru_cache\n",
    "\n",
    "# For progress tracking\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Plotting and Visualisation\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Language Detection packages\n",
    "# `langdetect` for detecting language\n",
    "from langdetect import detect as langdetect_detect, DetectorFactory\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "\n",
    "# `langid` for an alternative language detection method\n",
    "from langid import classify as langid_classify\n",
    "\n",
    "# Text Preprocessing and NLP\n",
    "# Stopwords (common words to ignore) from NLTK\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Tokenizing sentences/words\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Part-of-speech tagging\n",
    "from nltk import pos_tag\n",
    "\n",
    "# Lemmatization (converting words to their base form)\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "# Regular expressions for text pattern matching\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation (Loading CSV)\n",
    "\n",
    "Load the 3 Fake News `csv` files into pandas DataFrames\n",
    "- `part1.csv` is loaded into `data_raw1` DataFrame.\n",
    "- `part2.csv` is loaded into `data_raw2` DataFrame.\n",
    "- `part3.csv` is loaded into `data_raw3` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw1 = pd.read_csv(\"part1.csv\")\n",
    "data_raw2 = pd.read_csv(\"part2.csv\")\n",
    "data_raw3 = pd.read_csv(\"part3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24044 entries, 0 to 24043\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  24044 non-null  int64 \n",
      " 1   title       23894 non-null  object\n",
      " 2   text        24033 non-null  object\n",
      " 3   label       24044 non-null  int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 751.5+ KB\n",
      "Dataframe 1 Shape: (24044, 4)\n"
     ]
    }
   ],
   "source": [
    "data_raw1.info()\n",
    "print(\"Dataframe 1 Shape:\", data_raw1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24044 entries, 0 to 24043\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  24044 non-null  int64 \n",
      " 1   title       23849 non-null  object\n",
      " 2   text        24030 non-null  object\n",
      " 3   label       24044 non-null  int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 751.5+ KB\n",
      "Dataframe 2 Shape: (24044, 4)\n"
     ]
    }
   ],
   "source": [
    "data_raw2.info()\n",
    "print(\"Dataframe 2 Shape:\", data_raw2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24046 entries, 0 to 24045\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  24046 non-null  int64 \n",
      " 1   title       23833 non-null  object\n",
      " 2   text        24032 non-null  object\n",
      " 3   label       24046 non-null  int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 751.6+ KB\n",
      "Dataframe 3 Shape: (24046, 4)\n"
     ]
    }
   ],
   "source": [
    "data_raw3.info()\n",
    "print(\"Dataframe 3 Shape:\", data_raw3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LAW ENFORCEMENT ON HIGH ALERT Following Threat...</td>\n",
       "      <td>No comment is expected from Barack Obama Membe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Did they post their votes for Hillary already?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...</td>\n",
       "      <td>Now, most of the demonstrators gathered last ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Bobby Jindal, raised Hindu, uses story of Chri...</td>\n",
       "      <td>A dozen politically active pastors came here f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>SATAN 2: Russia unvelis an image of its terrif...</td>\n",
       "      <td>The RS-28 Sarmat missile, dubbed Satan 2, will...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0           0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
       "1           1                                                NaN   \n",
       "2           2  UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...   \n",
       "3           3  Bobby Jindal, raised Hindu, uses story of Chri...   \n",
       "4           4  SATAN 2: Russia unvelis an image of its terrif...   \n",
       "\n",
       "                                                text  label  \n",
       "0  No comment is expected from Barack Obama Membe...      1  \n",
       "1     Did they post their votes for Hillary already?      1  \n",
       "2   Now, most of the demonstrators gathered last ...      1  \n",
       "3  A dozen politically active pastors came here f...      0  \n",
       "4  The RS-28 Sarmat missile, dubbed Satan 2, will...      1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24044</td>\n",
       "      <td>Massachusetts governor would sign transgender ...</td>\n",
       "      <td>BOSTON (Reuters) - Massachusetts Governor Char...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24045</td>\n",
       "      <td>Weakened Militarily, ISIS Still Has Power to S...</td>\n",
       "      <td>In the past few weeks, the Islamic State has s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24046</td>\n",
       "      <td>SARAH JESSICA PARKER FEARS She’ll Be Attacked ...</td>\n",
       "      <td>With absolutely NOTHING to back it up, Sarah J...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24047</td>\n",
       "      <td>Rosenstein may need to recuse himself from Rus...</td>\n",
       "      <td>WASHINGTON (Reuters) - U.S. Deputy Attorney Ge...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24048</td>\n",
       "      <td>Cop Arrested for Using Police Status to Rape L...</td>\n",
       "      <td>Home / Badge Abuse / Cop Arrested for Using Po...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0       24044  Massachusetts governor would sign transgender ...   \n",
       "1       24045  Weakened Militarily, ISIS Still Has Power to S...   \n",
       "2       24046  SARAH JESSICA PARKER FEARS She’ll Be Attacked ...   \n",
       "3       24047  Rosenstein may need to recuse himself from Rus...   \n",
       "4       24048  Cop Arrested for Using Police Status to Rape L...   \n",
       "\n",
       "                                                text  label  \n",
       "0  BOSTON (Reuters) - Massachusetts Governor Char...      0  \n",
       "1  In the past few weeks, the Islamic State has s...      0  \n",
       "2  With absolutely NOTHING to back it up, Sarah J...      1  \n",
       "3  WASHINGTON (Reuters) - U.S. Deputy Attorney Ge...      0  \n",
       "4  Home / Badge Abuse / Cop Arrested for Using Po...      1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48088</td>\n",
       "      <td>Blue State Blues: The White House Loves the Ru...</td>\n",
       "      <td>The Trump White House seems quietly to be enjo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48089</td>\n",
       "      <td>Harassment Crisis Builds at Fox News, Despite ...</td>\n",
       "      <td>When the anchor Gretchen Carlson filed a bombs...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48090</td>\n",
       "      <td>Former Ku Klux Klan leader Duke runs for U.S. ...</td>\n",
       "      <td>BATON ROUGE, La. (Reuters) - David Duke, a for...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48091</td>\n",
       "      <td>NYTIMES: Sessions’ and Bannon’s Department of ...</td>\n",
       "      <td>Emily Bazelon writes in the New York Times on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48092</td>\n",
       "      <td>UPDATE: WIKILEAKS CLINTON Document Dump Back On!</td>\n",
       "      <td>Hillary Clinton strategist Bob Beckel called f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              title  \\\n",
       "0       48088  Blue State Blues: The White House Loves the Ru...   \n",
       "1       48089  Harassment Crisis Builds at Fox News, Despite ...   \n",
       "2       48090  Former Ku Klux Klan leader Duke runs for U.S. ...   \n",
       "3       48091  NYTIMES: Sessions’ and Bannon’s Department of ...   \n",
       "4       48092   UPDATE: WIKILEAKS CLINTON Document Dump Back On!   \n",
       "\n",
       "                                                text  label  \n",
       "0  The Trump White House seems quietly to be enjo...      0  \n",
       "1  When the anchor Gretchen Carlson filed a bombs...      0  \n",
       "2  BATON ROUGE, La. (Reuters) - David Duke, a for...      0  \n",
       "3  Emily Bazelon writes in the New York Times on ...      0  \n",
       "4  Hillary Clinton strategist Bob Beckel called f...      1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine all 3 dataframes into 1\n",
    "Here we combine all 3 dataframes (`data_raw1`, `data_raw2`, `data_raw3`) into 1 dataframe (`data_raw`) by concatenating along rows.\n",
    "\n",
    "We also reset the `index` and drop the old `index` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72134 entries, 0 to 72133\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  72134 non-null  int64 \n",
      " 1   title       71576 non-null  object\n",
      " 2   text        72095 non-null  object\n",
      " 3   label       72134 non-null  int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 2.2+ MB\n",
      "Dataframe Shape:  (72134, 4)\n"
     ]
    }
   ],
   "source": [
    "# Combining all 3 dataframes into 1\n",
    "data_raw = pd.concat([data_raw1, data_raw2, data_raw3], axis=0)\n",
    "\n",
    "# Reset index and drop old index column\n",
    "data_raw = data_raw.reset_index(drop=True)\n",
    "\n",
    "data_raw.info()\n",
    "print(\"Dataframe Shape: \", data_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LAW ENFORCEMENT ON HIGH ALERT Following Threat...</td>\n",
       "      <td>No comment is expected from Barack Obama Membe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Did they post their votes for Hillary already?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...</td>\n",
       "      <td>Now, most of the demonstrators gathered last ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Bobby Jindal, raised Hindu, uses story of Chri...</td>\n",
       "      <td>A dozen politically active pastors came here f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>SATAN 2: Russia unvelis an image of its terrif...</td>\n",
       "      <td>The RS-28 Sarmat missile, dubbed Satan 2, will...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72129</th>\n",
       "      <td>72129</td>\n",
       "      <td>Russians steal research on Trump in hack of U....</td>\n",
       "      <td>WASHINGTON (Reuters) - Hackers believed to be ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72130</th>\n",
       "      <td>72130</td>\n",
       "      <td>WATCH: Giuliani Demands That Democrats Apolog...</td>\n",
       "      <td>You know, because in fantasyland Republicans n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72131</th>\n",
       "      <td>72131</td>\n",
       "      <td>Migrants Refuse To Leave Train At Refugee Camp...</td>\n",
       "      <td>Migrants Refuse To Leave Train At Refugee Camp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72132</th>\n",
       "      <td>72132</td>\n",
       "      <td>Trump tussle gives unpopular Mexican leader mu...</td>\n",
       "      <td>MEXICO CITY (Reuters) - Donald Trump’s combati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72133</th>\n",
       "      <td>72133</td>\n",
       "      <td>Goldman Sachs Endorses Hillary Clinton For Pre...</td>\n",
       "      <td>Goldman Sachs Endorses Hillary Clinton For Pre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72134 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                              title  \\\n",
       "0               0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
       "1               1                                                NaN   \n",
       "2               2  UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...   \n",
       "3               3  Bobby Jindal, raised Hindu, uses story of Chri...   \n",
       "4               4  SATAN 2: Russia unvelis an image of its terrif...   \n",
       "...           ...                                                ...   \n",
       "72129       72129  Russians steal research on Trump in hack of U....   \n",
       "72130       72130   WATCH: Giuliani Demands That Democrats Apolog...   \n",
       "72131       72131  Migrants Refuse To Leave Train At Refugee Camp...   \n",
       "72132       72132  Trump tussle gives unpopular Mexican leader mu...   \n",
       "72133       72133  Goldman Sachs Endorses Hillary Clinton For Pre...   \n",
       "\n",
       "                                                    text  label  \n",
       "0      No comment is expected from Barack Obama Membe...      1  \n",
       "1         Did they post their votes for Hillary already?      1  \n",
       "2       Now, most of the demonstrators gathered last ...      1  \n",
       "3      A dozen politically active pastors came here f...      0  \n",
       "4      The RS-28 Sarmat missile, dubbed Satan 2, will...      1  \n",
       "...                                                  ...    ...  \n",
       "72129  WASHINGTON (Reuters) - Hackers believed to be ...      0  \n",
       "72130  You know, because in fantasyland Republicans n...      1  \n",
       "72131  Migrants Refuse To Leave Train At Refugee Camp...      0  \n",
       "72132  MEXICO CITY (Reuters) - Donald Trump’s combati...      0  \n",
       "72133  Goldman Sachs Endorses Hillary Clinton For Pre...      1  \n",
       "\n",
       "[72134 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n",
    "Here we select the relevant features for fake news classification.\n",
    "- `title`, `text`, `label`.\n",
    "- Create a new DataFrame (`data`) by selecting the specifc columns mentioned above from the original DataFrame `data_raw`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "                                               title  \\\n",
      "0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
      "1                                                NaN   \n",
      "2  UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...   \n",
      "3  Bobby Jindal, raised Hindu, uses story of Chri...   \n",
      "4  SATAN 2: Russia unvelis an image of its terrif...   \n",
      "\n",
      "                                                text  label  \n",
      "0  No comment is expected from Barack Obama Membe...      1  \n",
      "1     Did they post their votes for Hillary already?      1  \n",
      "2   Now, most of the demonstrators gathered last ...      1  \n",
      "3  A dozen politically active pastors came here f...      0  \n",
      "4  The RS-28 Sarmat missile, dubbed Satan 2, will...      1  \n",
      "\n",
      "The old shape is:  (72134, 3)\n"
     ]
    }
   ],
   "source": [
    "data = data_raw[\n",
    "    [\n",
    "        \"title\",\n",
    "        \"text\",\n",
    "        \"label\",\n",
    "    ]\n",
    "]\n",
    "print(type(data))\n",
    "print(data.head())\n",
    "\n",
    "# Shape before dropping duplicates\n",
    "print(\"\\nThe old shape is: \", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "## Remove Duplicate Rows\n",
    "- Drop duplicate rows from the dataframe (`data`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new shape is:  (63678, 3)\n"
     ]
    }
   ],
   "source": [
    "data = data.drop_duplicates()\n",
    "\n",
    "# Display the new dataframe shape\n",
    "print(\"The new shape is: \", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Outliers\n",
    "\n",
    "### `text`\n",
    "\n",
    "The `text` column of `data`, which is of string type, may contain values with unusually long lengths, indicating the presence of outliers. We will identify the outliers using [Z-score method].\n",
    "\n",
    "1. Create a new column `text_length` in the DataFrame `data` by calculating the length of each review. (Set the value as 0 if the correponding `text` column has NaN values.)\n",
    "\n",
    "2. Check the statistics of `text_length` using `describe()` method.\n",
    "\n",
    "3. Calculate the mean and standard deviation of the `text_length` column.\n",
    "\n",
    "4. Set the Z-score threshold for identifying outliers to 3.\n",
    "\n",
    "5. Identify outliers of the `text_length` column and set the corresponding `text` to np.nan.\n",
    "\n",
    "6. Drop the `text_length` column from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
      "1                                                NaN   \n",
      "2  UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...   \n",
      "\n",
      "                                                text  label  text_length  \n",
      "0  No comment is expected from Barack Obama Membe...      1         5049  \n",
      "1     Did they post their votes for Hillary already?      1           46  \n",
      "2   Now, most of the demonstrators gathered last ...      1          216  \n",
      "count     63678.000000\n",
      "mean       3276.735607\n",
      "std        3636.233225\n",
      "min           0.000000\n",
      "25%        1428.000000\n",
      "50%        2456.000000\n",
      "75%        4095.000000\n",
      "max      142961.000000\n",
      "Name: text_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data[\"text_length\"] = data[\"text\"].apply(lambda x: len(x) if pd.notna(x) else 0)\n",
    "print(data.head(3))\n",
    "\n",
    "TL = data[\"text_length\"]\n",
    "stats_TL = TL.describe()\n",
    "print(stats_TL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAW ENFORCEMENT ON HIGH ALERT Following Threat...</td>\n",
       "      <td>No comment is expected from Barack Obama Membe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Did they post their votes for Hillary already?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...</td>\n",
       "      <td>Now, most of the demonstrators gathered last ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bobby Jindal, raised Hindu, uses story of Chri...</td>\n",
       "      <td>A dozen politically active pastors came here f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SATAN 2: Russia unvelis an image of its terrif...</td>\n",
       "      <td>The RS-28 Sarmat missile, dubbed Satan 2, will...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
       "1                                                NaN   \n",
       "2  UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...   \n",
       "3  Bobby Jindal, raised Hindu, uses story of Chri...   \n",
       "4  SATAN 2: Russia unvelis an image of its terrif...   \n",
       "\n",
       "                                                text  label  \n",
       "0  No comment is expected from Barack Obama Membe...      1  \n",
       "1     Did they post their votes for Hillary already?      1  \n",
       "2   Now, most of the demonstrators gathered last ...      1  \n",
       "3  A dozen politically active pastors came here f...      0  \n",
       "4  The RS-28 Sarmat missile, dubbed Satan 2, will...      1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_TL = TL.mean()\n",
    "# print(mean_TL)\n",
    "\n",
    "sd_TL = TL.std()\n",
    "# print(sd_TL)\n",
    "\n",
    "threshold = 3\n",
    "\n",
    "z_score = zscore(TL)\n",
    "# print(z_score)\n",
    "\n",
    "# Remove 'text' of lengths that are greater than 3 standard deviations above the mean\n",
    "data.loc[abs(z_score) > threshold, \"text\"] = np.nan\n",
    "# print(data.head(3))\n",
    "\n",
    "data = data.drop(\"text_length\", axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `title`\n",
    "\n",
    "Similarly, the `title` column of `data` (of type `str`) may also contain values with unusually long lengths, indicating the presence of outliers.\n",
    "\n",
    "1. Create a new column `title_length` in the DataFrame `data` by calculating the length of each price value. (Set the value as 0 if the correponding `title` column has NaN values.)\n",
    "\n",
    "2. Check the statistics of `title_length` using `describe()` method and display its unique values.\n",
    "\n",
    "3. Identify the outlier values by inspecting the content in `title` corresponding to the abnormal value in `title_length` and set the corresponding value of `title` to np.nan.\n",
    "\n",
    "4. Drop the `title_length` column from the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               title  \\\n",
      "0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
      "1                                                NaN   \n",
      "2  UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...   \n",
      "\n",
      "                                                text  label  title_length  \n",
      "0  No comment is expected from Barack Obama Membe...      1           130  \n",
      "1     Did they post their votes for Hillary already?      1             0  \n",
      "2   Now, most of the demonstrators gathered last ...      1           137  \n",
      "count    63678.000000\n",
      "mean        74.567888\n",
      "std         23.620014\n",
      "min          0.000000\n",
      "25%         61.000000\n",
      "50%         72.000000\n",
      "75%         86.000000\n",
      "max        456.000000\n",
      "Name: title_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data[\"title_length\"] = data[\"title\"].apply(lambda x: len(x) if pd.notna(x) else 0)\n",
    "print(data.head(3))\n",
    "\n",
    "TL = data[\"title_length\"]\n",
    "stats_TL = TL.describe()\n",
    "print(stats_TL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAW ENFORCEMENT ON HIGH ALERT Following Threat...</td>\n",
       "      <td>No comment is expected from Barack Obama Membe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Did they post their votes for Hillary already?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...</td>\n",
       "      <td>Now, most of the demonstrators gathered last ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bobby Jindal, raised Hindu, uses story of Chri...</td>\n",
       "      <td>A dozen politically active pastors came here f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SATAN 2: Russia unvelis an image of its terrif...</td>\n",
       "      <td>The RS-28 Sarmat missile, dubbed Satan 2, will...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  LAW ENFORCEMENT ON HIGH ALERT Following Threat...   \n",
       "1                                                NaN   \n",
       "2  UNBELIEVABLE! OBAMA’S ATTORNEY GENERAL SAYS MO...   \n",
       "3  Bobby Jindal, raised Hindu, uses story of Chri...   \n",
       "4  SATAN 2: Russia unvelis an image of its terrif...   \n",
       "\n",
       "                                                text  label  \n",
       "0  No comment is expected from Barack Obama Membe...      1  \n",
       "1     Did they post their votes for Hillary already?      1  \n",
       "2   Now, most of the demonstrators gathered last ...      1  \n",
       "3  A dozen politically active pastors came here f...      0  \n",
       "4  The RS-28 Sarmat missile, dubbed Satan 2, will...      1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_TL = TL.mean()\n",
    "# print(mean_TL)\n",
    "\n",
    "sd_TL = TL.std()\n",
    "# print(sd_TL)\n",
    "\n",
    "threshold = 3\n",
    "\n",
    "z_score = zscore(TL)\n",
    "# print(z_score)\n",
    "\n",
    "# Remove 'title' of lengths that are greater than 3 standard deviations above the mean\n",
    "data.loc[abs(z_score) > threshold, \"title\"] = np.nan\n",
    "# print(data.head(3))\n",
    "\n",
    "data = data.drop(\"title_length\", axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title    1344\n",
       "text      877\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "### Create new column `full_review`\n",
    "Since there are some rows with empty `text` and `title`, we will concatenate both columns (`text` and `title`) to form a new column `full_content`.\n",
    "1. Replace `NaN` values in `text` and `title` with an empty string.\n",
    "\n",
    "2. Combine `text` and `title` into `full_content`.\n",
    "\n",
    "3. Strip any leading/trailing whitespaces in `full_content`.\n",
    "\n",
    "4. Drop `text` and `title` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                       full_content\n",
      "0      1  No comment is expected from Barack Obama Membe...\n",
      "1      1     Did they post their votes for Hillary already?\n",
      "2      1  Now, most of the demonstrators gathered last n...\n",
      "3      0  A dozen politically active pastors came here f...\n",
      "4      1  The RS-28 Sarmat missile, dubbed Satan 2, will...\n",
      "\n",
      "The old shape is: (63678, 2)\n"
     ]
    }
   ],
   "source": [
    "# 1) Fill NaN values in 'text' and 'title' with an empty string\n",
    "data[\"title\"] = data[\"title\"].fillna(\"\")\n",
    "data[\"text\"] = data[\"text\"].fillna(\"\")\n",
    "\n",
    "# 2) Combine 'text' and 'title' into 'content'\n",
    "data[\"full_content\"] = data[\"text\"] + \" \" + data[\"title\"]\n",
    "\n",
    "# 3) Strip any leading/trailing whitespace\n",
    "data[\"full_content\"] = data[\"full_content\"].str.strip()\n",
    "\n",
    "# 4) Drop `text` and `title` columns\n",
    "data = data.drop(columns=[\"text\", \"title\"])\n",
    "\n",
    "# Check if the 'full_review' column was added and if 'text' and 'title' columns has been dropped\n",
    "print(data.head())\n",
    "print(\"\\nThe old shape is:\", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Missing Values\n",
    "1. Drop rows where `full_review` are empty strings and reset the index.\n",
    "\n",
    "2. Check if there are no more null values in `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new shape is: (63648, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label           0\n",
       "full_content    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Drop rows where `full_review` are empty strings and reset the index\n",
    "data = data[data[\"full_content\"] != \"\"].reset_index(drop=True)\n",
    "print(\"The new shape is:\", data.shape)\n",
    "\n",
    "# 2) Check if there are no more null values in `data`\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create new column `language`\n",
    "We found that there are rows where `full_review` are in different languages (e.g., French, Russian, etc.) other than English. We decided to use 2 different language detector libraries (`langdetect`, `langid`) on the `full_review` column and combined the predictions of all 2 libraries and selecting the most frequent predicted language.\n",
    "\n",
    "**Reason**: `langdetect` might perform well on longer texts while `langid` is more reliable on short texts, using multiple detectors reduces the likelihood of misclassification and mitigates individual detector errors, leading to more accurate overall predictions. Also, even if one detector fails or throws an error, the other can still provide predictions, therefore improving the robustness of the language detection.\n",
    "\n",
    "1. Set a seed for `langdetect` to ensure reproducibility.\n",
    "\n",
    "2. Preprocess the text in `full_review`:\n",
    "    - a\\) Function to remove non-alphabetic characters and normalise whitespaces in  `full_review`.\n",
    "    - b\\) Function to determine if the text is non-language (e.g., numbers, symbols only).\n",
    "\n",
    "3. Two functions for language detection:\n",
    "    - a\\) Using `langdetect`.\n",
    "    - b\\) Using `langid`.\n",
    "\n",
    "4. Function for calculating majority vote for each language.\n",
    "\n",
    "5. Function for parallel processing for efficiency.\n",
    "\n",
    "6. Caching function for repeated inputs\n",
    "\n",
    "7. Function for choosing language based on combined majority voting.\n",
    "\n",
    "8. Applying the combined function on `full_review` column.\n",
    "\n",
    "9. Display the resulting `data` DataFrame.\n",
    "\n",
    "### <span style=\"color:red\">The code below will take approximately 15 minutes to run!</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Language Detection: 100%|██████████| 63648/63648 [05:59<00:00, 177.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>full_content</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No comment is expected from Barack Obama Membe...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Did they post their votes for Hillary already?</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Now, most of the demonstrators gathered last n...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>A dozen politically active pastors came here f...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>The RS-28 Sarmat missile, dubbed Satan 2, will...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63643</th>\n",
       "      <td>1</td>\n",
       "      <td>An email released by WikiLeaks on Sunday appea...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63644</th>\n",
       "      <td>0</td>\n",
       "      <td>WASHINGTON (Reuters) - Hackers believed to be ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63645</th>\n",
       "      <td>1</td>\n",
       "      <td>You know, because in fantasyland Republicans n...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63646</th>\n",
       "      <td>0</td>\n",
       "      <td>Migrants Refuse To Leave Train At Refugee Camp...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63647</th>\n",
       "      <td>0</td>\n",
       "      <td>MEXICO CITY (Reuters) - Donald Trump’s combati...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63648 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                       full_content language\n",
       "0          1  No comment is expected from Barack Obama Membe...       en\n",
       "1          1     Did they post their votes for Hillary already?       en\n",
       "2          1  Now, most of the demonstrators gathered last n...       en\n",
       "3          0  A dozen politically active pastors came here f...       en\n",
       "4          1  The RS-28 Sarmat missile, dubbed Satan 2, will...       en\n",
       "...      ...                                                ...      ...\n",
       "63643      1  An email released by WikiLeaks on Sunday appea...       en\n",
       "63644      0  WASHINGTON (Reuters) - Hackers believed to be ...       en\n",
       "63645      1  You know, because in fantasyland Republicans n...       en\n",
       "63646      0  Migrants Refuse To Leave Train At Refugee Camp...       en\n",
       "63647      0  MEXICO CITY (Reuters) - Donald Trump’s combati...       en\n",
       "\n",
       "[63648 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Set a seed for langdetect to ensure reproducibility\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "\n",
    "# 2a) Simplified preprocessing: only remove non-alphabetic characters\n",
    "def preprocess_text_simple(text):\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)  # Remove non-alphabetic characters\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # Normalize whitespace\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "# 2b) Check if the text is non-language (e.g., numbers, symbols only)\n",
    "def is_non_language_text(text):\n",
    "    if re.match(r\"^[^a-zA-Z]*$\", text):  # Check if text has no alphabetic characters\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# 3a) Function to get langdetect prediction\n",
    "def get_langdetect_prediction(text):\n",
    "    try:\n",
    "        # Directly use text without preprocessing for efficiency\n",
    "        if len(text) < 10 or is_non_language_text(text):\n",
    "            return \"unknown\"\n",
    "        lang = langdetect_detect(text)\n",
    "        return lang\n",
    "    except LangDetectException:\n",
    "        return \"unknown\"\n",
    "\n",
    "\n",
    "# 3b) Function to get langid prediction\n",
    "def get_langid_prediction(text):\n",
    "    try:\n",
    "        lang, _ = langid_classify(text)\n",
    "        if len(text) < 10 or is_non_language_text(text):\n",
    "            return \"unknown\"\n",
    "        return lang\n",
    "    except Exception:\n",
    "        return \"unknown\"\n",
    "\n",
    "\n",
    "# 4) Function to calculate majority vote for each language\n",
    "def calculate_majority_vote(predictions):\n",
    "    vote_counts = {}\n",
    "    for lang in predictions:\n",
    "        if lang in vote_counts:\n",
    "            vote_counts[lang] += 1\n",
    "        else:\n",
    "            vote_counts[lang] = 1\n",
    "    return vote_counts\n",
    "\n",
    "\n",
    "# 5) Parallel processing for efficiency with limited workers\n",
    "def parallel_detection(text):\n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        results = list(\n",
    "            executor.map(\n",
    "                lambda func: func(text),\n",
    "                [get_langdetect_prediction, get_langid_prediction],\n",
    "            )\n",
    "        )\n",
    "    return results\n",
    "\n",
    "\n",
    "# 6) Caching function for repeated inputs\n",
    "@lru_cache(maxsize=500)\n",
    "def get_cached_language(text):\n",
    "    return combined_language_detection(text)\n",
    "\n",
    "\n",
    "# 7) Combined majority voting language detection function\n",
    "def combined_language_detection(text):\n",
    "    # Check if the text is non-language (e.g., numbers, symbols only)\n",
    "    if is_non_language_text(text):\n",
    "        return \"unknown\"\n",
    "\n",
    "    # Run the detectors in parallel for efficiency\n",
    "    predictions = parallel_detection(text)\n",
    "\n",
    "    # Calculate majority vote for each language based on predictions\n",
    "    vote_counts = calculate_majority_vote(predictions)\n",
    "\n",
    "    # Determine the language with the highest majority vote\n",
    "    final_language = max(vote_counts, key=vote_counts.get)\n",
    "\n",
    "    # If \"unknown\" is the most common or if all detectors fail, return \"unknown\"\n",
    "    if final_language == \"unknown\" or vote_counts[final_language] <= 1:\n",
    "        return \"unknown\"\n",
    "\n",
    "    return final_language\n",
    "\n",
    "\n",
    "# 8) Apply the cached function to each text in the DataFrame with a progress bar\n",
    "data[\"language\"] = [\n",
    "    get_cached_language(text)\n",
    "    for text in tqdm(data[\"full_content\"], desc=\"Language Detection\")\n",
    "]\n",
    "\n",
    "# 9) Display the DataFrame with detected languages\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language\n",
       "en         62932\n",
       "unknown      259\n",
       "es           140\n",
       "ru           113\n",
       "de            91\n",
       "fr            65\n",
       "ar            19\n",
       "pt             7\n",
       "tr             7\n",
       "it             4\n",
       "hr             3\n",
       "nl             3\n",
       "no             2\n",
       "el             2\n",
       "pl             1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See distribution of languages\n",
    "data[\"language\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our end goal is to determine the credibility of popular American news outlet websites, which uses the English language, we will drop rows where the language is NOT in English (`en`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>full_content</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No comment is expected from Barack Obama Membe...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Did they post their votes for Hillary already?</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Now, most of the demonstrators gathered last n...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>A dozen politically active pastors came here f...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>The RS-28 Sarmat missile, dubbed Satan 2, will...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62927</th>\n",
       "      <td>1</td>\n",
       "      <td>An email released by WikiLeaks on Sunday appea...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62928</th>\n",
       "      <td>0</td>\n",
       "      <td>WASHINGTON (Reuters) - Hackers believed to be ...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62929</th>\n",
       "      <td>1</td>\n",
       "      <td>You know, because in fantasyland Republicans n...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62930</th>\n",
       "      <td>0</td>\n",
       "      <td>Migrants Refuse To Leave Train At Refugee Camp...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62931</th>\n",
       "      <td>0</td>\n",
       "      <td>MEXICO CITY (Reuters) - Donald Trump’s combati...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62932 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                       full_content language\n",
       "0          1  No comment is expected from Barack Obama Membe...       en\n",
       "1          1     Did they post their votes for Hillary already?       en\n",
       "2          1  Now, most of the demonstrators gathered last n...       en\n",
       "3          0  A dozen politically active pastors came here f...       en\n",
       "4          1  The RS-28 Sarmat missile, dubbed Satan 2, will...       en\n",
       "...      ...                                                ...      ...\n",
       "62927      1  An email released by WikiLeaks on Sunday appea...       en\n",
       "62928      0  WASHINGTON (Reuters) - Hackers believed to be ...       en\n",
       "62929      1  You know, because in fantasyland Republicans n...       en\n",
       "62930      0  Migrants Refuse To Leave Train At Refugee Camp...       en\n",
       "62931      0  MEXICO CITY (Reuters) - Donald Trump’s combati...       en\n",
       "\n",
       "[62932 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows where language is NOT in english and reset the index\n",
    "data = data[data[\"language\"] == \"en\"].reset_index(drop=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will drop the `language` column since all values of `language` are `en` and all `full_review` are in the English language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62932 entries, 0 to 62931\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   label         62932 non-null  int64 \n",
      " 1   full_content  62932 non-null  object\n",
      " 2   language      62932 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 1.4+ MB\n",
      "The new shape is: (62932, 2)\n"
     ]
    }
   ],
   "source": [
    "data.info()\n",
    "data.drop(columns=[\"language\"], inplace=True)\n",
    "print(\"The new shape is:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>full_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No comment is expected from Barack Obama Membe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Did they post their votes for Hillary already?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Now, most of the demonstrators gathered last n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>A dozen politically active pastors came here f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>The RS-28 Sarmat missile, dubbed Satan 2, will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62927</th>\n",
       "      <td>1</td>\n",
       "      <td>An email released by WikiLeaks on Sunday appea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62928</th>\n",
       "      <td>0</td>\n",
       "      <td>WASHINGTON (Reuters) - Hackers believed to be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62929</th>\n",
       "      <td>1</td>\n",
       "      <td>You know, because in fantasyland Republicans n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62930</th>\n",
       "      <td>0</td>\n",
       "      <td>Migrants Refuse To Leave Train At Refugee Camp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62931</th>\n",
       "      <td>0</td>\n",
       "      <td>MEXICO CITY (Reuters) - Donald Trump’s combati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62932 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                       full_content\n",
       "0          1  No comment is expected from Barack Obama Membe...\n",
       "1          1     Did they post their votes for Hillary already?\n",
       "2          1  Now, most of the demonstrators gathered last n...\n",
       "3          0  A dozen politically active pastors came here f...\n",
       "4          1  The RS-28 Sarmat missile, dubbed Satan 2, will...\n",
       "...      ...                                                ...\n",
       "62927      1  An email released by WikiLeaks on Sunday appea...\n",
       "62928      0  WASHINGTON (Reuters) - Hackers believed to be ...\n",
       "62929      1  You know, because in fantasyland Republicans n...\n",
       "62930      0  Migrants Refuse To Leave Train At Refugee Camp...\n",
       "62931      0  MEXICO CITY (Reuters) - Donald Trump’s combati...\n",
       "\n",
       "[62932 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing for NLP\n",
    "\n",
    "Here we will define a function `process_full_review` that takes a textual value as input and applies the following processing steps in sequence:\n",
    "\n",
    "1. Convert the input text to lowercase using the `lower()` function.\n",
    "\n",
    "2. Tokenize the lowercase text using the `word_tokenize` function from the NLTK library.\n",
    "\n",
    "3. Create a list (`alphabetic_tokens`) containing only alphanetic tokens using a list comprehension with a regular expression match.\n",
    "\n",
    "4. Remove stopwords\n",
    "-   Obtain a set of English stopwords using the `stopwords.words('english')` method.\n",
    "-   Define a list of `allowed_words` that should not be removed.\n",
    "-   Remove the stopwords (excluding those that should not be removed).\n",
    "\n",
    "5. Apply stemming to each token.\n",
    "\n",
    "6. Join the stemmed tokens into a single processed text using the `join` method and return the processed text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/inflaton/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/inflaton/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/inflaton/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package wordnet to /home/inflaton/nltk_data...\n",
      "[nltk_data] Downloading collection 'all'\n",
      "[nltk_data]    | \n",
      "[nltk_data]    | Downloading package abc to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
      "[nltk_data]    | Downloading package alpino to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
      "[nltk_data]    |       to-date!\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers/averaged_perceptron_tagger_eng.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
      "[nltk_data]    | Downloading package averaged_perceptron_tagger_rus to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers/averaged_perceptron_tagger_rus.zip.\n",
      "[nltk_data]    | Downloading package basque_grammars to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
      "[nltk_data]    | Downloading package bcp47 to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    | Downloading package biocreative_ppi to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
      "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
      "[nltk_data]    | Downloading package book_grammars to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
      "[nltk_data]    | Downloading package brown to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
      "[nltk_data]    | Downloading package brown_tei to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
      "[nltk_data]    | Downloading package cess_cat to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
      "[nltk_data]    | Downloading package cess_esp to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
      "[nltk_data]    | Downloading package chat80 to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
      "[nltk_data]    | Downloading package city_database to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
      "[nltk_data]    | Downloading package cmudict to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
      "[nltk_data]    | Downloading package comparative_sentences to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
      "[nltk_data]    | Downloading package comtrans to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    | Downloading package conll2000 to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
      "[nltk_data]    | Downloading package conll2002 to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
      "[nltk_data]    | Downloading package conll2007 to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    | Downloading package crubadan to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
      "[nltk_data]    | Downloading package dependency_treebank to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
      "[nltk_data]    | Downloading package dolch to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
      "[nltk_data]    | Downloading package europarl_raw to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
      "[nltk_data]    | Downloading package extended_omw to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    | Downloading package floresta to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
      "[nltk_data]    | Downloading package framenet_v15 to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
      "[nltk_data]    | Downloading package framenet_v17 to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
      "[nltk_data]    | Downloading package gazetteers to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
      "[nltk_data]    | Downloading package genesis to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
      "[nltk_data]    | Downloading package gutenberg to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
      "[nltk_data]    | Downloading package ieer to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
      "[nltk_data]    | Downloading package inaugural to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
      "[nltk_data]    | Downloading package indian to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
      "[nltk_data]    | Downloading package jeita to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    | Downloading package kimmo to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
      "[nltk_data]    | Downloading package knbc to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    | Downloading package large_grammars to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
      "[nltk_data]    | Downloading package lin_thesaurus to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
      "[nltk_data]    | Downloading package mac_morpho to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
      "[nltk_data]    | Downloading package machado to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    | Downloading package masc_tagged to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data]    | Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker_tab.zip.\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
      "[nltk_data]    | Downloading package maxent_treebank_pos_tagger_tab to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping\n",
      "[nltk_data]    |       taggers/maxent_treebank_pos_tagger_tab.zip.\n",
      "[nltk_data]    | Downloading package moses_sample to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
      "[nltk_data]    | Downloading package movie_reviews to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
      "[nltk_data]    | Downloading package mte_teip5 to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
      "[nltk_data]    | Downloading package mwa_ppdb to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
      "[nltk_data]    | Downloading package names to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/names.zip.\n",
      "[nltk_data]    | Downloading package nombank.1.0 to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
      "[nltk_data]    | Downloading package nps_chat to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
      "[nltk_data]    | Downloading package omw to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    | Downloading package omw-1.4 to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    | Downloading package opinion_lexicon to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
      "[nltk_data]    | Downloading package panlex_swadesh to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    | Downloading package paradigms to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
      "[nltk_data]    | Downloading package pe08 to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
      "[nltk_data]    | Downloading package perluniprops to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
      "[nltk_data]    | Downloading package pil to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
      "[nltk_data]    | Downloading package pl196x to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
      "[nltk_data]    | Downloading package porter_test to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
      "[nltk_data]    | Downloading package ppattach to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
      "[nltk_data]    | Downloading package problem_reports to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_1 to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
      "[nltk_data]    | Downloading package product_reviews_2 to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
      "[nltk_data]    | Downloading package propbank to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    | Downloading package pros_cons to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
      "[nltk_data]    | Downloading package ptb to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
      "[nltk_data]    | Downloading package punkt to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Package punkt is already up-to-date!\n",
      "[nltk_data]    | Downloading package punkt_tab to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping tokenizers/punkt_tab.zip.\n",
      "[nltk_data]    | Downloading package qc to /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
      "[nltk_data]    | Downloading package reuters to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    | Downloading package rslp to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
      "[nltk_data]    | Downloading package rte to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
      "[nltk_data]    | Downloading package sample_grammars to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
      "[nltk_data]    | Downloading package semcor to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    | Downloading package senseval to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
      "[nltk_data]    | Downloading package sentence_polarity to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
      "[nltk_data]    | Downloading package sentiwordnet to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
      "[nltk_data]    | Downloading package shakespeare to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
      "[nltk_data]    | Downloading package sinica_treebank to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
      "[nltk_data]    | Downloading package smultron to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
      "[nltk_data]    | Downloading package snowball_data to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    | Downloading package spanish_grammars to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
      "[nltk_data]    | Downloading package state_union to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
      "[nltk_data]    | Downloading package stopwords to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Package stopwords is already up-to-date!\n",
      "[nltk_data]    | Downloading package subjectivity to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
      "[nltk_data]    | Downloading package swadesh to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
      "[nltk_data]    | Downloading package switchboard to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
      "[nltk_data]    | Downloading package tagsets to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
      "[nltk_data]    | Downloading package tagsets_json to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping help/tagsets_json.zip.\n",
      "[nltk_data]    | Downloading package timit to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
      "[nltk_data]    | Downloading package toolbox to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
      "[nltk_data]    | Downloading package treebank to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
      "[nltk_data]    | Downloading package twitter_samples to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
      "[nltk_data]    | Downloading package udhr to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
      "[nltk_data]    | Downloading package udhr2 to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
      "[nltk_data]    | Downloading package unicode_samples to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
      "[nltk_data]    | Downloading package universal_tagset to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
      "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    | Downloading package vader_lexicon to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    | Downloading package verbnet to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
      "[nltk_data]    | Downloading package verbnet3 to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
      "[nltk_data]    | Downloading package webtext to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
      "[nltk_data]    | Downloading package wmt15_eval to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
      "[nltk_data]    | Downloading package word2vec_sample to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
      "[nltk_data]    | Downloading package wordnet to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Package wordnet is already up-to-date!\n",
      "[nltk_data]    | Downloading package wordnet2021 to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet2022 to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
      "[nltk_data]    | Downloading package wordnet31 to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    | Downloading package wordnet_ic to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
      "[nltk_data]    | Downloading package words to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/words.zip.\n",
      "[nltk_data]    | Downloading package ycoe to\n",
      "[nltk_data]    |     /home/inflaton/nltk_data...\n",
      "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
      "[nltk_data]    | \n",
      "[nltk_data]  Done downloading collection all\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure require NLTK data is downloaded\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to process text\n",
    "import string\n",
    "from nltk.stem import *\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "\n",
    "def process_full_review(text):\n",
    "    # Convert to lowercase and tokenize\n",
    "    text = text.lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in string.punctuation]\n",
    "    stemmer = PorterStemmer()\n",
    "    # List of stopwords\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    allowed_words = [\n",
    "        \"no\",\n",
    "        \"not\",\n",
    "        \"don't\",\n",
    "        \"dont\",\n",
    "        \"don\",\n",
    "        \"but\",\n",
    "        \"however\",\n",
    "        \"never\",\n",
    "        \"wasn't\",\n",
    "        \"wasnt\",\n",
    "        \"shouldn't\",\n",
    "        \"shouldnt\",\n",
    "        \"mustn't\",\n",
    "        \"musnt\",\n",
    "    ]\n",
    "\n",
    "    stemmed = [\n",
    "        stemmer.stem(word)\n",
    "        for word in tokens\n",
    "        if word not in stop_words or word in allowed_words\n",
    "    ]\n",
    "    return \" \".join(stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing News Articles: 100%|██████████| 62932/62932 [02:58<00:00, 352.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>full_content</th>\n",
       "      <th>processed_full_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>No comment is expected from Barack Obama Membe...</td>\n",
       "      <td>no comment expect barack obama member fyf911 f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Did they post their votes for Hillary already?</td>\n",
       "      <td>post vote hillari alreadi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Now, most of the demonstrators gathered last n...</td>\n",
       "      <td>demonstr gather last night exercis constitut p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>A dozen politically active pastors came here f...</td>\n",
       "      <td>dozen polit activ pastor came privat dinner fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>The RS-28 Sarmat missile, dubbed Satan 2, will...</td>\n",
       "      <td>rs-28 sarmat missil dub satan 2 replac ss-18 f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62927</th>\n",
       "      <td>1</td>\n",
       "      <td>An email released by WikiLeaks on Sunday appea...</td>\n",
       "      <td>email releas wikileak sunday appear show forme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62928</th>\n",
       "      <td>0</td>\n",
       "      <td>WASHINGTON (Reuters) - Hackers believed to be ...</td>\n",
       "      <td>washington reuter hacker believ work russian g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62929</th>\n",
       "      <td>1</td>\n",
       "      <td>You know, because in fantasyland Republicans n...</td>\n",
       "      <td>know fantasyland republican never question cit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62930</th>\n",
       "      <td>0</td>\n",
       "      <td>Migrants Refuse To Leave Train At Refugee Camp...</td>\n",
       "      <td>migrant refus leav train refuge camp hungari t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62931</th>\n",
       "      <td>0</td>\n",
       "      <td>MEXICO CITY (Reuters) - Donald Trump’s combati...</td>\n",
       "      <td>mexico citi reuter donald trump ’ comb style b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62932 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                       full_content  \\\n",
       "0          1  No comment is expected from Barack Obama Membe...   \n",
       "1          1     Did they post their votes for Hillary already?   \n",
       "2          1  Now, most of the demonstrators gathered last n...   \n",
       "3          0  A dozen politically active pastors came here f...   \n",
       "4          1  The RS-28 Sarmat missile, dubbed Satan 2, will...   \n",
       "...      ...                                                ...   \n",
       "62927      1  An email released by WikiLeaks on Sunday appea...   \n",
       "62928      0  WASHINGTON (Reuters) - Hackers believed to be ...   \n",
       "62929      1  You know, because in fantasyland Republicans n...   \n",
       "62930      0  Migrants Refuse To Leave Train At Refugee Camp...   \n",
       "62931      0  MEXICO CITY (Reuters) - Donald Trump’s combati...   \n",
       "\n",
       "                                  processed_full_content  \n",
       "0      no comment expect barack obama member fyf911 f...  \n",
       "1                              post vote hillari alreadi  \n",
       "2      demonstr gather last night exercis constitut p...  \n",
       "3      dozen polit activ pastor came privat dinner fr...  \n",
       "4      rs-28 sarmat missil dub satan 2 replac ss-18 f...  \n",
       "...                                                  ...  \n",
       "62927  email releas wikileak sunday appear show forme...  \n",
       "62928  washington reuter hacker believ work russian g...  \n",
       "62929  know fantasyland republican never question cit...  \n",
       "62930  migrant refus leav train refuge camp hungari t...  \n",
       "62931  mexico citi reuter donald trump ’ comb style b...  \n",
       "\n",
       "[62932 rows x 3 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Enable tqdm for pandas (progress bar)\n",
    "tqdm.pandas(desc=\"Processing News Articles\")\n",
    "\n",
    "# Apply process_full_review function with tqdm progress bar and expand the results into separate columns.\n",
    "processed_columns = [\"processed_full_content\"]\n",
    "data[processed_columns] = data[\"full_content\"].progress_apply(\n",
    "    lambda x: pd.Series(process_full_review(x))\n",
    ")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create a new `csv` file called `processed_data.csv` where we store the new processed dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"processed_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8747120044490347\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9013    0.8733    0.8871      7093\n",
      "           1     0.8427    0.8766    0.8593      5494\n",
      "\n",
      "    accuracy                         0.8747     12587\n",
      "   macro avg     0.8720    0.8749    0.8732     12587\n",
      "weighted avg     0.8757    0.8747    0.8750     12587\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "count_vectorizer = CountVectorizer(max_features=1000)\n",
    "count_matrix = count_vectorizer.fit_transform(data[\"processed_full_content\"])\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    count_matrix, data[\"label\"], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train Naive Bayes model\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "nb_predictions = nb_model.predict(X_test)\n",
    "\n",
    "# Print accuracy and classification report\n",
    "print(accuracy_score(y_test, nb_predictions))\n",
    "print(classification_report(y_test, nb_predictions, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.9299277031858266\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9230    0.9553    0.9389      7093\n",
      "           1     0.9396    0.8972    0.9179      5494\n",
      "\n",
      "    accuracy                         0.9299     12587\n",
      "   macro avg     0.9313    0.9262    0.9284     12587\n",
      "weighted avg     0.9303    0.9299    0.9297     12587\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, rf_predictions))\n",
    "print(\n",
    "    \"Random Forest Classification Report:\\n\",\n",
    "    classification_report(y_test, rf_predictions, digits=4),\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fake-news",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
